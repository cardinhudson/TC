import streamlit as st
import pandas as pd
import altair as alt
import os
import numpy as np
import re
import shutil
from datetime import datetime, timedelta

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Forecast - Previs√µes TC",
    page_icon="üîÆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS para customiza√ß√£o
st.markdown("""
    <style>
        /* Reduzir t√≠tulos em 20% */
        h1 {
            /* Reduzido de 3rem para 2.4rem (20%) */
            font-size: 2.4rem !important;
        }
        h2 {
            /* Reduzido de 2rem para 1.6rem (20%) */
            font-size: 1.6rem !important;
        }
        h3 {
            /* Reduzido de 1.6rem para 1.28rem (20%) */
            font-size: 1.28rem !important;
        }
    </style>
""", unsafe_allow_html=True)

# T√≠tulo
st.title("üîÆ Forecast - Previs√µes TC")
st.subheader("An√°lise preditiva e previs√µes de custos e volumes")

st.markdown("---")

# Fun√ß√£o auxiliar para listar anos dispon√≠veis
def listar_anos_disponiveis():
    """Lista todos os anos dispon√≠veis nas pastas de dados"""
    pasta_dados = "dados"
    anos_disponiveis = []
    
    if os.path.exists(pasta_dados):
        for item in os.listdir(pasta_dados):
            caminho_item = os.path.join(pasta_dados, item)
            if os.path.isdir(caminho_item) and item.isdigit():
                anos_disponiveis.append(int(item))
    
    return sorted(anos_disponiveis, reverse=True)  # Mais recente primeiro

# Fun√ß√£o auxiliar para encontrar arquivo parquet na ordem de prioridade
def encontrar_arquivo_parquet(nome_arquivo, ano_selecionado=None):
    """
    Busca arquivo parquet na seguinte ordem de prioridade:
    1. Se ano_selecionado for None ou "Todos": Hist√≥rico consolidado (dados/historico_consolidado/)
    2. Se ano_selecionado for especificado: Pasta do ano (dados/{ANO}/)
    3. Pasta do ano mais recente (dados/{ANO}/)
    4. Raiz do projeto (compatibilidade)
    """
    # Se ano espec√≠fico foi selecionado, buscar na pasta do ano
    if ano_selecionado is not None and ano_selecionado != "Todos":
        caminho_ano = os.path.join("dados", str(ano_selecionado), nome_arquivo)
        if os.path.exists(caminho_ano):
            return caminho_ano
    
    # 1. Tentar hist√≥rico consolidado (para "Todos" ou quando n√£o especificado)
    caminho_historico = os.path.join("dados", "historico_consolidado", nome_arquivo.replace(".parquet", "_historico.parquet"))
    if os.path.exists(caminho_historico):
        return caminho_historico
    
    # 2. Tentar pasta do ano mais recente
    pasta_dados = "dados"
    if os.path.exists(pasta_dados):
        anos_disponiveis = []
        for item in os.listdir(pasta_dados):
            caminho_item = os.path.join(pasta_dados, item)
            if os.path.isdir(caminho_item) and item.isdigit():
                anos_disponiveis.append(int(item))
        
        if anos_disponiveis:
            ano_mais_recente = max(anos_disponiveis)
            caminho_ano = os.path.join(pasta_dados, str(ano_mais_recente), nome_arquivo)
            if os.path.exists(caminho_ano):
                return caminho_ano
    
    # 3. Tentar raiz (compatibilidade)
    if os.path.exists(nome_arquivo):
        return nome_arquivo
    
    return None

# Filtros na sidebar - ANTES de carregar dados
st.sidebar.markdown("---")
st.sidebar.markdown("**üìÖ Sele√ß√£o de Ano**")

# Listar anos dispon√≠veis
anos_disponiveis = listar_anos_disponiveis()
opcoes_ano = ["Todos"] + [str(ano) for ano in anos_disponiveis]

# Seletor de ano
ano_selecionado = st.sidebar.selectbox(
    "Selecione o ano:",
    options=opcoes_ano,
    index=0,  # "Todos" por padr√£o
    help="Selecione 'Todos' para ver dados consolidados ou um ano espec√≠fico"
)

st.sidebar.markdown("---")

# Modo de visualiza√ß√£o fixo: apenas Custo Total
tipo_visualizacao = "Custo Total"
st.sidebar.markdown("---")

# Bot√£o para limpar cache (√∫til ap√≥s mudan√ßas no c√≥digo)
if st.sidebar.button("üóëÔ∏è Limpar Cache", help="Limpa o cache do Streamlit para for√ßar rec√°lculo"):
    st.cache_data.clear()
    st.sidebar.success("‚úÖ Cache limpo! Recarregue a p√°gina.")
st.sidebar.markdown("---")

# Fun√ß√£o para carregar dados com cache
@st.cache_data(
    ttl=3600,
    max_entries=10,  # Aumentar para cachear diferentes anos
    show_spinner=True
)
def load_data(ano_selecionado_param):
    """Carrega os dados do arquivo parquet"""
    try:
        # Converter "Todos" para None
        ano_para_busca = None if ano_selecionado_param == "Todos" else ano_selecionado_param
        
        # Buscar arquivo na ordem de prioridade
        arquivo_parquet = encontrar_arquivo_parquet("df_final.parquet", ano_para_busca)

        if arquivo_parquet is None:
            st.error(f"‚ùå Arquivo n√£o encontrado: df_final.parquet")
            st.info("üí° Verifique se o arquivo existe em:")
            st.info("   - dados/historico_consolidado/df_final_historico.parquet")
            st.info("   - dados/{ANO}/df_final.parquet")
            st.info("   - df_final.parquet (raiz)")
            st.stop()

        # Carregar dados
        df = pd.read_parquet(arquivo_parquet)

        # Se carregou do hist√≥rico consolidado e um ano espec√≠fico foi selecionado, filtrar
        if ano_selecionado_param != "Todos" and "Ano" in df.columns:
            df = df[df['Ano'] == int(ano_selecionado_param)].copy()

        # Otimizar tipos de dados
        for col in df.columns:
            if df[col].dtype == 'object':
                unique_ratio = df[col].nunique() / len(df)
                if unique_ratio < 0.5:
                    df[col] = df[col].astype('category')

        # Converter floats para tipos menores
        for col in df.select_dtypes(include=['float64']).columns:
            df[col] = pd.to_numeric(df[col], downcast='float')

        # Converter ints para tipos menores
        for col in df.select_dtypes(include=['int64']).columns:
            df[col] = pd.to_numeric(df[col], downcast='integer')

        return df
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar dados: {str(e)}")
        st.stop()


# Fun√ß√£o para carregar dados de volume com cache
@st.cache_data(
    ttl=3600,
    max_entries=10,  # Aumentar para cachear diferentes anos
    show_spinner=True
)
def load_volume_data(ano_selecionado_param):
    """Carrega os dados de volume do arquivo parquet"""
    try:
        # Converter "Todos" para None
        ano_para_busca = None if ano_selecionado_param == "Todos" else ano_selecionado_param
        
        # Buscar arquivo na ordem de prioridade
        arquivo_parquet = encontrar_arquivo_parquet("df_vol.parquet", ano_para_busca)

        if arquivo_parquet is None:
            return None

        df = pd.read_parquet(arquivo_parquet)

        # Se carregou do hist√≥rico consolidado e um ano espec√≠fico foi selecionado, filtrar
        if ano_selecionado_param != "Todos" and "Ano" in df.columns:
            df = df[df['Ano'] == int(ano_selecionado_param)].copy()

        # Otimizar tipos de dados
        for col in df.columns:
            if df[col].dtype == 'object':
                unique_ratio = df[col].nunique() / len(df)
                if unique_ratio < 0.5:
                    df[col] = df[col].astype('category')

        # Converter floats para tipos menores
        for col in df.select_dtypes(include=['float64']).columns:
            df[col] = pd.to_numeric(df[col], downcast='float')

        # Converter ints para tipos menores
        for col in df.select_dtypes(include=['int64']).columns:
            df[col] = pd.to_numeric(df[col], downcast='integer')

        return df
    except Exception:
        return None

@st.cache_data(ttl=3600, show_spinner=False)
def load_volume_historico_data():
    """Carrega os dados de volume hist√≥rico consolidado do arquivo parquet"""
    try:
        # Buscar arquivo na pasta dados/historico_consolidado
        caminho_base = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        caminho_historico = os.path.join(caminho_base, "dados", "historico_consolidado", "df_vol_historico.parquet")
        
        if os.path.exists(caminho_historico):
            df = pd.read_parquet(caminho_historico)
            
            # Otimizar tipos de dados
            for col in df.columns:
                if df[col].dtype == 'object':
                    try:
                        unique_ratio = df[col].nunique() / len(df)
                        if unique_ratio < 0.5:
                            df[col] = df[col].astype('category')
                    except:
                        pass
            
            # Converter floats para tipos menores
            for col in df.select_dtypes(include=['float64']).columns:
                df[col] = pd.to_numeric(df[col], downcast='float')
            
            # Converter ints para tipos menores
            for col in df.select_dtypes(include=['int64']).columns:
                df[col] = pd.to_numeric(df[col], downcast='integer')
            
            return df
        else:
            return None
    except Exception:
        return None


# Carregar dados com o ano selecionado
try:
    df_total = load_data(ano_selecionado)
    st.sidebar.success("‚úÖ Dados carregados com sucesso")
    if ano_selecionado == "Todos":
        st.sidebar.info(f"üìä {len(df_total):,} registros (Todos os anos)")
    else:
        st.sidebar.info(f"üìä {len(df_total):,} registros (Ano {ano_selecionado})")
except Exception as e:
    st.error(f"‚ùå Erro: {str(e)}")
    st.stop()

# Filtros na sidebar
st.sidebar.markdown("---")
st.sidebar.markdown("**üîç Filtros**")

# Fun√ß√£o auxiliar para obter op√ß√µes de filtro
@st.cache_data(ttl=1800, max_entries=5)
def get_filter_options(df, column_name):
    """Obt√©m op√ß√µes de filtro com cache"""
    if column_name in df.columns:
        opcoes = sorted(
            df[column_name].dropna().astype(str).unique().tolist()
        )
        return ["Todos"] + opcoes
    return ["Todos"]

# Bot√£o de atualizar dados na sidebar (ap√≥s definir todas as fun√ß√µes com cache)
st.sidebar.markdown("---")
if st.sidebar.button("üîÑ Atualizar Dados", use_container_width=True):
    # Limpar cache de todas as fun√ß√µes (verificar se existem)
    try:
        load_data.clear()
        load_volume_data.clear()
        get_filter_options.clear()
        aplicar_filtros.clear()
    except:
        pass
    
    # Fun√ß√µes que podem n√£o existir se houver colunas faltando
    try:
        calcular_medias_forecast.clear()
        calcular_volumes_cpu.clear()
        calcular_forecast_completo.clear()
        processar_tabela_forecast.clear()
    except:
        pass
    
    st.rerun()


# Ordem dos meses para ordena√ß√£o cronol√≥gica
ORDEM_MESES = [
    'janeiro', 'fevereiro', 'mar√ßo', 'abril', 'maio', 'junho',
    'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro'
]


# Fun√ß√£o para aplicar filtros com cache
@st.cache_data(ttl=3600, max_entries=50, show_spinner=False)
def aplicar_filtros(df_total_cache, oficina_selecionadas_cache, veiculo_selecionados_cache, 
                     usi_selecionada_cache, periodo_selecionado_cache):
    """Aplica filtros ao DataFrame com cache"""
    df_filtrado = df_total_cache.copy()
    
    # Filtro 1: Oficina
    if 'Oficina' in df_filtrado.columns:
        if oficina_selecionadas_cache and "Todos" not in oficina_selecionadas_cache:
            df_filtrado = df_filtrado[
                df_filtrado['Oficina'].astype(str).isin(oficina_selecionadas_cache)
            ].copy()
    
    # Filtro 2: Ve√≠culo
    if 'Ve√≠culo' in df_filtrado.columns:
        if veiculo_selecionados_cache and "Todos" not in veiculo_selecionados_cache:
            df_filtrado = df_filtrado[
                df_filtrado['Ve√≠culo'].astype(str).isin(veiculo_selecionados_cache)
            ].copy()
    
    # Filtro 3: USI
    if 'USI' in df_filtrado.columns:
        if usi_selecionada_cache and "Todos" not in usi_selecionada_cache:
            df_filtrado = df_filtrado[
                df_filtrado['USI'].astype(str).isin(usi_selecionada_cache)
            ].copy()
    
    # Filtro 4: Per√≠odo
    if 'Per√≠odo' in df_filtrado.columns:
        if periodo_selecionado_cache and periodo_selecionado_cache != "Todos":
            df_filtrado = df_filtrado[
                df_filtrado['Per√≠odo'].astype(str) == str(periodo_selecionado_cache)
            ].copy()
    
    return df_filtrado

# Filtro 1: Oficina
oficina_selecionadas = ["Todos"]
if 'Oficina' in df_total.columns:
    oficina_opcoes = get_filter_options(df_total, 'Oficina')
    oficina_selecionadas = st.sidebar.multiselect(
        "Selecione a Oficina:", oficina_opcoes, default=["Todos"]
    )

# Filtro 2: Ve√≠culo
veiculo_selecionados = ["Todos"]
if 'Ve√≠culo' in df_total.columns:
    # Usar df_total para op√ß√µes, mas depois filtrar
    veiculo_opcoes = get_filter_options(df_total, 'Ve√≠culo')
    veiculo_selecionados = st.sidebar.multiselect(
        "Selecione o Ve√≠culo:", veiculo_opcoes, default=["Todos"]
    )

# Filtro 3: USI
usi_selecionada = ["TC Ext"]
if 'USI' in df_total.columns:
    usi_opcoes = get_filter_options(df_total, 'USI')
    default_usi = ["TC Ext"] if "TC Ext" in usi_opcoes else ["Todos"]
    usi_selecionada = st.sidebar.multiselect(
        "Selecione a USI:", usi_opcoes, default=default_usi
    )

# Filtro 4: Per√≠odo
periodo_selecionado = "Todos"
if 'Per√≠odo' in df_total.columns:
    periodo_opcoes_raw = get_filter_options(df_total, 'Per√≠odo')
    
    # Ordenar meses cronologicamente
    periodo_opcoes = ["Todos"]
    meses_ordenados = []
    outros_periodos = []
    
    for periodo in periodo_opcoes_raw[1:]:  # Pular "Todos"
        periodo_lower = str(periodo).lower()
        if periodo_lower in ORDEM_MESES:
            meses_ordenados.append(periodo)
        else:
            outros_periodos.append(periodo)
    
    # Ordenar meses pela ordem cronol√≥gica
    meses_ordenados.sort(
        key=lambda x: ORDEM_MESES.index(str(x).lower())
        if str(x).lower() in ORDEM_MESES else 999
    )
    
    # Combinar: Todos + meses ordenados + outros per√≠odos
    periodo_opcoes = periodo_opcoes + meses_ordenados + outros_periodos
    
    periodo_selecionado = st.sidebar.selectbox(
        "Selecione o Per√≠odo:", periodo_opcoes
    )

# Aplicar todos os filtros com cache
df_filtrado = aplicar_filtros(
    df_total,
    tuple(oficina_selecionadas) if oficina_selecionadas else tuple(),
    tuple(veiculo_selecionados) if veiculo_selecionados else tuple(),
    tuple(usi_selecionada) if usi_selecionada else tuple(),
    periodo_selecionado
)

# Resumo na sidebar
st.sidebar.markdown("---")
st.sidebar.markdown("**üìä Resumo**")
st.sidebar.write(f"**Linhas:** {df_filtrado.shape[0]:,}")

# Calcular totais se as colunas existirem
if 'Valor' in df_filtrado.columns:
    # Converter para num√©rico caso seja categ√≥rico
    valor_series = pd.to_numeric(df_filtrado['Valor'], errors='coerce')
    valor_total = valor_series.sum()
    st.sidebar.write(f"**Total Valor:** R$ {valor_total:,.2f}")
if 'Total' in df_filtrado.columns:
    # Converter para num√©rico caso seja categ√≥rico
    total_series = pd.to_numeric(df_filtrado['Total'], errors='coerce')
    total_sum = total_series.sum()
    st.sidebar.write(f"**Total:** R$ {total_sum:,.2f}")

# √Årea principal - Forecast
st.markdown("## üìà Forecast - Previs√£o de Custo Total")

# ====================================================================
# üîÆ CONFIGURA√á√ÉO DO FORECAST - PRIMEIRO (antes dos sliders)
# ====================================================================
st.markdown("### üîÆ Configura√ß√£o do Forecast")

# Lista de meses do ano (necess√°ria para a configura√ß√£o)
meses_ano = ['Janeiro', 'Fevereiro', 'Mar√ßo', 'Abril', 'Maio', 'Junho',
             'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro']

# Verificar se temos dados com m√∫ltiplos anos
tem_anos = 'Ano' in df_filtrado.columns and df_filtrado['Ano'].nunique() > 1

# Determinar o ano dos dados
if tem_anos and 'Ano' in df_filtrado.columns:
    anos_disponiveis = sorted(df_filtrado['Ano'].dropna().unique())
    ano_maximo = int(df_filtrado['Ano'].max())
else:
    from datetime import datetime
    anos_disponiveis = [datetime.now().year]
    ano_maximo = datetime.now().year

# Fun√ß√£o auxiliar para ordenar per√≠odos (definir antes de usar)
def ordenar_periodo_para_select(periodo_str):
    """Ordena per√≠odos para o selectbox"""
    periodo_str = str(periodo_str).strip()
    # Se tiver ano (ex: "Novembro 2025")
    if ' ' in periodo_str:
        partes = periodo_str.split(' ', 1)
        mes_nome = partes[0]
        ano = int(partes[1]) if partes[1].isdigit() else 0
        # Normalizar nome do m√™s (capitalizar)
        mes_nome_capitalizado = mes_nome.capitalize()
        mes_idx = meses_ano.index(mes_nome_capitalizado) if mes_nome_capitalizado in meses_ano else 0
        return (ano, mes_idx)
    else:
        # Apenas m√™s - normalizar (capitalizar)
        mes_nome_capitalizado = periodo_str.capitalize()
        mes_idx = meses_ano.index(mes_nome_capitalizado) if mes_nome_capitalizado in meses_ano else 0
        return (0, mes_idx)

# Criar lista de per√≠odos dispon√≠veis com ano (baseado nos dados reais)
periodos_disponiveis = []
if 'Per√≠odo' in df_filtrado.columns:
    # Pegar per√≠odos √∫nicos dos dados
    periodos_unicos = df_filtrado['Per√≠odo'].dropna().unique()
    
    # Verificar se os per√≠odos j√° t√™m ano ou n√£o
    periodos_com_ano = any(' ' in str(p) and str(p).split(' ', 1)[1].isdigit() for p in periodos_unicos)
    
    # Se n√£o tiver ano nos per√≠odos mas temos m√∫ltiplos anos, adicionar ano
    if not periodos_com_ano and tem_anos:
        # Criar per√≠odos com ano baseado no ano dos dados
        periodos_com_ano_lista = []
        for periodo in periodos_unicos:
            periodo_str = str(periodo).strip()
            # Capitalizar primeira letra
            periodo_capitalizado = periodo_str.capitalize() if periodo_str else periodo_str
            # Adicionar ano m√°ximo (ano dos dados)
            periodo_com_ano = f"{periodo_capitalizado} {ano_maximo}"
            periodos_com_ano_lista.append(periodo_com_ano)
        periodos_disponiveis = sorted(periodos_com_ano_lista, key=lambda x: ordenar_periodo_para_select(x))
    else:
        # Se j√° tem ano ou n√£o tem m√∫ltiplos anos, usar como est√°
        periodos_disponiveis = sorted(periodos_unicos, key=lambda x: ordenar_periodo_para_select(x))
else:
    # Fallback: criar per√≠odos baseado nos meses e anos dispon√≠veis
    for ano in anos_disponiveis:
        for mes in meses_ano:
            if tem_anos:
                periodo = f"{mes} {ano}"
            else:
                periodo = mes
            periodos_disponiveis.append(periodo)

# Layout em 2 colunas para os controles principais
col_config1, col_config2 = st.columns(2)

with col_config1:
    # 1. Selecionar √∫ltimo per√≠odo com dados reais (com ano)
    from datetime import datetime
    mes_atual_sistema = datetime.now().month
    mes_atual_nome = meses_ano[mes_atual_sistema - 1] if mes_atual_sistema <= 12 else meses_ano[11]
    
    # Determinar per√≠odo padr√£o
    if tem_anos:
        periodo_padrao = f"{mes_atual_nome} {ano_maximo}"
        # Se o per√≠odo padr√£o n√£o estiver na lista, usar o √∫ltimo dispon√≠vel
        if periodo_padrao not in periodos_disponiveis and periodos_disponiveis:
            periodo_padrao = periodos_disponiveis[-1]
    else:
        periodo_padrao = mes_atual_nome
        if periodo_padrao not in periodos_disponiveis and periodos_disponiveis:
            periodo_padrao = periodos_disponiveis[-1]
    
    # Encontrar √≠ndice do per√≠odo padr√£o
    try:
        indice_padrao = periodos_disponiveis.index(periodo_padrao)
    except ValueError:
        indice_padrao = len(periodos_disponiveis) - 1 if periodos_disponiveis else 0
    
    ultimo_periodo_dados = st.selectbox(
        "üìÖ √öltimo per√≠odo com dados reais:",
        options=periodos_disponiveis,
        index=indice_padrao if indice_padrao < len(periodos_disponiveis) else 0,
        help="Selecione o √∫ltimo per√≠odo (m√™s e ano) que possui dados hist√≥ricos reais"
    )
    
    # Extrair m√™s do per√≠odo selecionado
    if ' ' in str(ultimo_periodo_dados):
        ultimo_mes_dados = str(ultimo_periodo_dados).split(' ', 1)[0]
    else:
        ultimo_mes_dados = str(ultimo_periodo_dados)
    
    # Normalizar para capitalizar (ex: "setembro" -> "Setembro")
    ultimo_mes_dados = ultimo_mes_dados.capitalize()
    
    indice_ultimo_mes = meses_ano.index(ultimo_mes_dados) if ultimo_mes_dados in meses_ano else 0
    
    # 2. Quantos meses prever
    meses_disponiveis_para_prever = len(meses_ano) - (indice_ultimo_mes + 1)
    if meses_disponiveis_para_prever <= 0:
        meses_disponiveis_para_prever = 12  # Se j√° passou dezembro, permitir prever o pr√≥ximo ano
    
    num_meses_prever = st.number_input(
        "üîÆ Quantos meses prever:",
        min_value=1,
        max_value=12,
        value=min(meses_disponiveis_para_prever, 6),
        step=1,
        help="N√∫mero de meses futuros para prever"
    )

with col_config2:
    # 3. Quantos meses usar para calcular a m√©dia
    meses_historicos_disponiveis = meses_ano[:indice_ultimo_mes + 1]
    
    # üîß NOVA L√ìGICA: Contar quantos meses at√© o √∫ltimo per√≠odo t√™m valores (Total != 0)
    # Isso limita o filtro apenas aos meses que realmente t√™m dados (inclui valores negativos, exclui apenas zeros)
    meses_com_valor = len(meses_historicos_disponiveis)  # Valor padr√£o
    if meses_historicos_disponiveis and not df_filtrado.empty and 'Per√≠odo' in df_filtrado.columns and 'Total' in df_filtrado.columns:
        # Extrair ano do √∫ltimo per√≠odo
        ano_referencia_contagem = None
        if ' ' in str(ultimo_periodo_dados):
            partes_periodo = str(ultimo_periodo_dados).split(' ', 1)
            if len(partes_periodo) > 1 and partes_periodo[1].isdigit():
                ano_referencia_contagem = partes_periodo[1]
        if ano_referencia_contagem is None:
            ano_referencia_contagem = str(ano_maximo) if 'ano_maximo' in locals() else str(datetime.now().year)
        
        # Criar lista de per√≠odos at√© o √∫ltimo m√™s selecionado
        periodos_ate_ultimo = []
        for mes in meses_historicos_disponiveis:
            # Adicionar per√≠odo com ano
            periodo_com_ano = f"{mes} {ano_referencia_contagem}".lower()
            periodos_ate_ultimo.append(periodo_com_ano)
            # Tamb√©m adicionar apenas o m√™s (para compatibilidade com dados antigos)
            periodos_ate_ultimo.append(mes.lower())
        
        # Normalizar per√≠odos do DataFrame para compara√ß√£o
        df_filtrado_copy = df_filtrado.copy()
        df_filtrado_copy['Per√≠odo_Normalizado'] = df_filtrado_copy['Per√≠odo'].astype(str).str.strip().str.lower()
        
        # Filtrar df_filtrado para per√≠odos at√© o √∫ltimo m√™s
        mask_periodos_ate_ultimo = df_filtrado_copy['Per√≠odo_Normalizado'].isin(periodos_ate_ultimo)
        df_periodos_ate_ultimo = df_filtrado_copy[mask_periodos_ate_ultimo].copy()
        
        # Contar per√≠odos √∫nicos que t√™m pelo menos uma linha com Total != 0 (inclui valores negativos, exclui apenas zeros)
        if not df_periodos_ate_ultimo.empty:
            # Verificar se h√° pelo menos uma linha com Total != 0 para cada per√≠odo
            # Agrupar por Per√≠odo_Normalizado e verificar se h√° algum Total != 0
            periodos_unicos = df_periodos_ate_ultimo['Per√≠odo_Normalizado'].unique()
            periodos_com_valor_lista = []
            for periodo in periodos_unicos:
                df_periodo = df_periodos_ate_ultimo[df_periodos_ate_ultimo['Per√≠odo_Normalizado'] == periodo]
                # Verificar se h√° pelo menos uma linha com Total != 0
                if (df_periodo['Total'] != 0).any():
                    periodos_com_valor_lista.append(periodo)
            meses_com_valor = len(periodos_com_valor_lista)
            
            # Se n√£o encontrou nenhum per√≠odo com valor, usar o n√∫mero de meses hist√≥ricos dispon√≠veis
            if meses_com_valor == 0:
                meses_com_valor = len(meses_historicos_disponiveis)
    
    # Limitar max_value aos meses que t√™m valores
    max_meses_media = max(1, meses_com_valor)  # Garantir pelo menos 1
    
    # üîß CORRE√á√ÉO: Ajustar valor inicial baseado no session_state ou no max dispon√≠vel
    # Se houver valor salvo, usar ele, mas limitar ao novo max_meses_media
    valor_inicial_media = min(max_meses_media, 6)  # Valor padr√£o
    if 'config_forecast_aplicada' in st.session_state and st.session_state.config_forecast_aplicada.get('num_meses_media') is not None:
        valor_salvo = st.session_state.config_forecast_aplicada['num_meses_media']
        # Ajustar valor salvo se ele exceder o novo m√°ximo (quando √∫ltimo per√≠odo mudar)
        valor_inicial_media = min(valor_salvo, max_meses_media)
    
    # üîß CORRE√á√ÉO CR√çTICA: Usar key baseada no ultimo_periodo_dados para for√ßar atualiza√ß√£o quando mudar
    # Isso garante que o widget seja recriado com os novos max_value e value quando o √∫ltimo per√≠odo mudar
    key_num_meses_media = f"num_meses_media_{ultimo_periodo_dados}"
    
    # Verificar se o √∫ltimo per√≠odo mudou e ajustar o valor no session_state
    if key_num_meses_media not in st.session_state:
        st.session_state[key_num_meses_media] = valor_inicial_media
    else:
        # Se o √∫ltimo per√≠odo mudou (key diferente), ajustar o valor ao novo m√°ximo
        valor_atual = st.session_state.get(key_num_meses_media, valor_inicial_media)
        if valor_atual > max_meses_media:
            st.session_state[key_num_meses_media] = max_meses_media
        else:
            st.session_state[key_num_meses_media] = valor_atual
    
    num_meses_media = st.number_input(
        "üìà Quantos meses usar para a m√©dia:",
        min_value=1,
        max_value=max_meses_media,
        value=st.session_state[key_num_meses_media],
        step=1,
        key=key_num_meses_media,
        help=f"N√∫mero de meses hist√≥ricos para calcular a m√©dia (m√°ximo: {max_meses_media} meses com valores at√© {ultimo_periodo_dados})"
    )
    
    # 4. Selecionar quais meses excluir do c√°lculo da m√©dia
    #    (exibir com ano para evitar confus√£o em cen√°rios multi-ano)
    if meses_historicos_disponiveis:
        # Determinar ano de refer√™ncia a partir do √∫ltimo per√≠odo selecionado
        ano_referencia = None
        if ' ' in str(ultimo_periodo_dados):
            partes_periodo = str(ultimo_periodo_dados).split(' ', 1)
            if len(partes_periodo) > 1 and partes_periodo[1].isdigit():
                ano_referencia = partes_periodo[1]
        if ano_referencia is None:
            # Fallback: usar ano_maximo (ano dos dados carregados)
            ano_referencia = str(ano_maximo) if 'ano_maximo' in locals() else str(datetime.now().year)

        # Criar op√ß√µes com ano para o multiselect
        opcoes_excluir = [f"{mes} {ano_referencia}" for mes in meses_historicos_disponiveis]

        selecao_excluir = st.multiselect(
            "üö´ Excluir meses do c√°lculo da m√©dia:",
            options=opcoes_excluir,
            default=[],
            help="Selecione meses (com ano) que foram fora da curva e devem ser exclu√≠dos do c√°lculo da m√©dia"
        )

        # Converter sele√ß√£o de "M√™s Ano" de volta apenas para o nome do m√™s
        meses_excluir_media = []
        for opcao in selecao_excluir:
            opcao_str = str(opcao).strip()
            mes_nome = opcao_str.split(' ', 1)[0] if ' ' in opcao_str else opcao_str
            meses_excluir_media.append(mes_nome)
    else:
        meses_excluir_media = []

# Extrair ano do √∫ltimo per√≠odo selecionado
if ' ' in str(ultimo_periodo_dados):
    ultimo_ano_dados = int(str(ultimo_periodo_dados).split(' ', 1)[1])
else:
    # Se n√£o tiver ano no per√≠odo, usar o ano m√°ximo dos dados
    if tem_anos and 'Ano' in df_filtrado.columns:
        ultimo_ano_dados = int(df_filtrado['Ano'].max())
    else:
        ultimo_ano_dados = datetime.now().year

# Calcular quais per√≠odos ser√£o previstos (com ano)
periodos_restantes = []
meses_restantes = []

for i in range(num_meses_prever):
    indice_mes = indice_ultimo_mes + 1 + i
    ano_futuro = ultimo_ano_dados
    
    # Se passar de dezembro, avan√ßar para o pr√≥ximo ano
    if indice_mes >= 12:
        ano_futuro += (indice_mes // 12)
        indice_mes = indice_mes % 12
    
    mes_nome = meses_ano[indice_mes]
    meses_restantes.append(mes_nome)
    
    # Criar per√≠odo com ano se necess√°rio
    if tem_anos:
        periodo_futuro = f"{mes_nome} {ano_futuro}"
    else:
        periodo_futuro = mes_nome
    
    periodos_restantes.append(periodo_futuro)

# Calcular quais per√≠odos ser√£o usados para a m√©dia (com ano)
periodos_para_media = []
meses_para_media = []

if meses_historicos_disponiveis:
    meses_considerados = meses_historicos_disponiveis.copy()
    
    # Remover meses exclu√≠dos
    for mes_excluir in meses_excluir_media:
        if mes_excluir in meses_considerados:
            meses_considerados.remove(mes_excluir)
    
    # Pegar os √∫ltimos N meses (ap√≥s excluir)
    if meses_considerados:
        meses_para_media = meses_considerados[-num_meses_media:] if len(meses_considerados) >= num_meses_media else meses_considerados
        
        # Criar per√≠odos com ano se necess√°rio
        if tem_anos:
            for mes in meses_para_media:
                periodo_com_ano = f"{mes} {ultimo_ano_dados}"
                periodos_para_media.append(periodo_com_ano)
        else:
            periodos_para_media = meses_para_media.copy()
    else:
        meses_para_media = []
        periodos_para_media = []
else:
    meses_para_media = []
    periodos_para_media = []

# Mostrar resumo da configura√ß√£o
col_resumo1, col_resumo2 = st.columns(2)
with col_resumo1:
    if periodos_restantes:
        st.success(f"üìä **Per√≠odos a prever:** {', '.join(periodos_restantes)}")
    else:
        st.warning("‚ö†Ô∏è Nenhum per√≠odo selecionado para prever")

with col_resumo2:
    if periodos_para_media:
        st.success(f"‚úÖ **Per√≠odos para m√©dia:** {', '.join(periodos_para_media)} ({len(periodos_para_media)} per√≠odos)")
    else:
        st.error("‚ùå Nenhum per√≠odo dispon√≠vel para calcular a m√©dia!")

if meses_excluir_media:
    st.info(f"‚ÑπÔ∏è **Meses exclu√≠dos da m√©dia:** {', '.join(meses_excluir_media)}")

st.markdown("---")

# Inicializar vari√°vel para armazenar configura√ß√µes tempor√°rias de sensibilidade e infla√ß√£o
# (ser√° preenchida nos blocos condicionais abaixo)
config_sensibilidade_temp = {
    'sensibilidade_fixo': None,
    'sensibilidade_variavel': None,
    'inflacao_global': None,
    'sensibilidades_type06': None,
    'inflacao_type06': None
}

# Sliders de sensibilidade
st.markdown("### üéöÔ∏è Sensibilidade √† Varia√ß√£o de Volume")

# Verificar se Type 06 existe nos dados
if 'Type 06' in df_filtrado.columns:
    # Obter valores √∫nicos de Type 06
    type06_valores = sorted(df_filtrado['Type 06'].dropna().unique().tolist())
    
    if len(type06_valores) > 0:
        st.markdown("""
        Ajuste a sensibilidade para cada categoria de **Type 06**:
        - **0.0**: Nenhuma varia√ß√£o (custo fixo independente do volume)
        - **1.0**: Varia√ß√£o total (custo varia 100% com o volume)
        - **0.5**: Varia√ß√£o parcial (custo varia 50% com o volume)
        """)
        
        # Op√ß√£o de configura√ß√£o: Global ou Detalhada
        modo_config = st.radio(
            "Modo de Configura√ß√£o:",
            ["üåê Global (Fixo/Vari√°vel)", "üéØ Detalhado (por Type 06)"],
            horizontal=True
        )
        
        if modo_config == "üåê Global (Fixo/Vari√°vel)":
            # Modo global (original)
            
            # Inicializar session_state para modo global
            if 'sensibilidade_fixo_aplicada' not in st.session_state:
                st.session_state.sensibilidade_fixo_aplicada = 0.0
            if 'sensibilidade_variavel_aplicada' not in st.session_state:
                st.session_state.sensibilidade_variavel_aplicada = 1.0
            if 'inflacao_global_aplicada' not in st.session_state:
                st.session_state.inflacao_global_aplicada = 0.0
            
            # Layout em 3 colunas: Fixo, Vari√°vel, Infla√ß√£o
            col_sens1, col_sens2, col_infl = st.columns(3)
            
            with col_sens1:
                sensibilidade_fixo_temp = st.slider(
                    "üîµ Sensibilidade - Custo Fixo",
                    min_value=0.0,
                    max_value=1.0,
                    value=st.session_state.sensibilidade_fixo_aplicada,
                    step=0.05,
                    help="Define quanto o custo fixo varia com o volume"
                )
                st.info(f"Custo Fixo variar√° **{sensibilidade_fixo_temp*100:.0f}%** da varia√ß√£o do volume")
            
            with col_sens2:
                sensibilidade_variavel_temp = st.slider(
                    "üü† Sensibilidade - Custo Vari√°vel",
                    min_value=0.0,
                    max_value=1.0,
                    value=st.session_state.sensibilidade_variavel_aplicada,
                    step=0.05,
                    help="Define quanto o custo vari√°vel varia com o volume"
                )
                st.info(f"Custo Vari√°vel variar√° **{sensibilidade_variavel_temp*100:.0f}%** da varia√ß√£o do volume")
            
            with col_infl:
                # Usar slider para infla√ß√£o tamb√©m, para manter alinhamento
                inflacao_global_temp = st.slider(
                    "üìà Infla√ß√£o Global",
                    min_value=0.0,
                    max_value=20.0,
                    value=st.session_state.inflacao_global_aplicada,
                    step=0.5,
                    format="%.2f",
                    help="Infla√ß√£o aplicada uma √∫nica vez no primeiro m√™s da previs√£o"
                )
                st.info(f"üìä Infla√ß√£o: **{inflacao_global_temp:.2f}%**")
                st.caption("üí° Aplicada uma vez no 1¬∫ m√™s e mantida nos demais")
            
            # Armazenar valores tempor√°rios para aplicar depois no bot√£o unificado
            config_sensibilidade_temp['sensibilidade_fixo'] = sensibilidade_fixo_temp
            config_sensibilidade_temp['sensibilidade_variavel'] = sensibilidade_variavel_temp
            config_sensibilidade_temp['inflacao_global'] = inflacao_global_temp
            
            # Usar valores aplicados (se existirem) ou tempor√°rios
            if 'sensibilidade_fixo_aplicada' in st.session_state:
                sensibilidade_fixo = st.session_state.sensibilidade_fixo_aplicada
            else:
                sensibilidade_fixo = sensibilidade_fixo_temp
            
            if 'sensibilidade_variavel_aplicada' in st.session_state:
                sensibilidade_variavel = st.session_state.sensibilidade_variavel_aplicada
            else:
                sensibilidade_variavel = sensibilidade_variavel_temp
            
            if 'inflacao_global_aplicada' in st.session_state:
                inflacao_global = st.session_state.inflacao_global_aplicada
            else:
                inflacao_global = inflacao_global_temp
            
            # Criar dicion√°rio de sensibilidades (None = usar global)
            sensibilidades_type06 = None
            
            # Criar dicion√°rio de infla√ß√£o global (aplicar a todos)
            if inflacao_global > 0 and 'Type 06' in df_filtrado.columns:
                type06_valores_global = df_filtrado['Type 06'].dropna().unique().tolist()
                inflacao_type06 = {type06: inflacao_global for type06 in type06_valores_global}
            else:
                inflacao_type06 = None
            
            st.info(f"‚ÑπÔ∏è Usando: Fixo={sensibilidade_fixo*100:.0f}%, Vari√°vel={sensibilidade_variavel*100:.0f}%, Infla√ß√£o={inflacao_global:.2f}%")
            
        else:
            # Modo detalhado por Type 06
            st.markdown("#### üìä Configura√ß√£o por Type 06")
            st.info(f"Configure a sensibilidade individualmente para cada um dos **{len(type06_valores)}** valores de Type 06.")
            
            # Inicializar session_state para valores tempor√°rios dos sliders
            if 'valores_temp_sens' not in st.session_state:
                st.session_state.valores_temp_sens = {}
            if 'valores_temp_infl' not in st.session_state:
                st.session_state.valores_temp_infl = {}
            if 'widget_key_counter' not in st.session_state:
                st.session_state.widget_key_counter = 0
            
            # Criar dicion√°rios para armazenar sensibilidades e infla√ß√£o
            sensibilidades_type06 = {}
            inflacao_type06 = {}
            
            # Bot√µes de a√ß√£o r√°pida NO TOPO
            st.markdown("##### ‚ö° A√ß√µes R√°pidas - Sensibilidade")
            col_btn1, col_btn2, col_btn3, col_btn4 = st.columns(4)
            
            with col_btn1:
                if st.button("üîµ Todos Fixos (0.0)", use_container_width=True, key="btn_fixos"):
                    for type06 in type06_valores:
                        st.session_state.valores_temp_sens[type06] = 0.0
                    st.rerun()
            
            with col_btn2:
                if st.button("üü† Todos Vari√°veis (1.0)", use_container_width=True, key="btn_variaveis"):
                    for type06 in type06_valores:
                        st.session_state.valores_temp_sens[type06] = 1.0
                    st.rerun()
            
            with col_btn3:
                if st.button("‚öñÔ∏è Todos M√©dios (0.5)", use_container_width=True, key="btn_medios"):
                    for type06 in type06_valores:
                        st.session_state.valores_temp_sens[type06] = 0.5
                    st.rerun()
            
            with col_btn4:
                if st.button("üßπ Limpar Configura√ß√µes", use_container_width=True, key="btn_limpar"):
                    st.session_state.sensibilidades_aplicadas = None
                    st.session_state.inflacao_aplicada = None
                    st.session_state.valores_temp_sens = {}
                    st.session_state.valores_temp_infl = {}
                    st.success("Configura√ß√µes limpas!")
                    st.rerun()
            
            # Bot√µes de a√ß√£o r√°pida para INFLA√á√ÉO
            st.markdown("##### üìà A√ß√µes R√°pidas - Infla√ß√£o")
            st.markdown("Digite o valor de infla√ß√£o e clique no bot√£o para aplicar a todas as linhas:")
            
            col_infl_input, col_infl_btn1, col_infl_btn2 = st.columns([2, 1, 1])
            
            with col_infl_input:
                inflacao_rapida = st.number_input(
                    "Infla√ß√£o para todas as linhas (%)",
                    min_value=0.0,
                    max_value=100.0,
                    value=0.0,
                    step=0.5,
                    format="%.2f",
                    key="inflacao_rapida_input",
                    help="Digite o valor e clique em 'Aplicar a Todas'"
                )
            
            with col_infl_btn1:
                st.markdown("<br>", unsafe_allow_html=True)  # Espa√ßamento
                if st.button("üìà Aplicar a Todas", use_container_width=True, key="btn_aplicar_inflacao"):
                    # Aplicar o novo valor a todas as linhas
                    for type06 in type06_valores:
                        st.session_state.valores_temp_infl[type06] = inflacao_rapida
                    # Incrementar contador para for√ßar recria√ß√£o dos widgets
                    st.session_state.widget_key_counter += 1
                    st.rerun()
            
            with col_infl_btn2:
                st.markdown("<br>", unsafe_allow_html=True)  # Espa√ßamento
                if st.button("üîÑ Zerar Infla√ß√£o", use_container_width=True, key="btn_zerar_inflacao"):
                    # Aplicar zero a todas as linhas
                    for type06 in type06_valores:
                        st.session_state.valores_temp_infl[type06] = 0.0
                    # Incrementar contador para for√ßar recria√ß√£o dos widgets
                    st.session_state.widget_key_counter += 1
                    st.rerun()
            
            st.markdown("---")
            
            # Criar tabela interativa com sliders
            st.markdown("##### Tabela de Sensibilidades e Infla√ß√£o")
            
            st.info("""
            üí° **Infla√ß√£o**: Digite o percentual de infla√ß√£o que ser√° aplicado **uma √∫nica vez** no primeiro m√™s da previs√£o.
            Exemplo: 5% significa que o custo aumentar√° 5% a partir do primeiro m√™s e manter√° esse valor ajustado nos meses seguintes.
            """)
            
            # Cabe√ßalho da tabela
            col_header1, col_header2, col_header3, col_header4, col_header5, col_header6 = st.columns([2, 2.5, 1.5, 2.5, 1, 1.5])
            with col_header1:
                st.markdown("**Type 05**")
            with col_header2:
                st.markdown("**Type 06**")
            with col_header3:
                st.markdown("**Tipo**")
            with col_header4:
                st.markdown("**Sensibilidade**")
            with col_header5:
                st.markdown("**%**")
            with col_header6:
                st.markdown("**Infla√ß√£o %**")
            
            st.markdown("---")
            
            # Criar sliders para cada Type 06
            for type06 in type06_valores:
                # Verificar tipo predominante (Fixo ou Vari√°vel)
                df_type06 = df_filtrado[df_filtrado['Type 06'] == type06]
                if 'Custo' in df_type06.columns:
                    tipo_counts = df_type06['Custo'].value_counts()
                    tipo_predominante = tipo_counts.index[0] if len(tipo_counts) > 0 else 'Vari√°vel'
                else:
                    tipo_predominante = 'Vari√°vel'
                
                # Obter Type 05 correspondente (pegar o mais comum)
                type05_valor = ""
                if 'Type 05' in df_type06.columns:
                    type05_counts = df_type06['Type 05'].value_counts()
                    type05_valor = type05_counts.index[0] if len(type05_counts) > 0 else ""
                
                # Definir valor padr√£o baseado no tipo ou usar valor tempor√°rio
                valor_padrao_sens = 0.0 if tipo_predominante == 'Fixo' else 1.0
                if type06 in st.session_state.valores_temp_sens:
                    valor_padrao_sens = st.session_state.valores_temp_sens[type06]
                
                valor_padrao_infl = 0.0
                if type06 in st.session_state.valores_temp_infl:
                    valor_padrao_infl = st.session_state.valores_temp_infl[type06]
                
                # Criar linha da tabela (mais compacta)
                col1, col2, col3, col4, col5, col6 = st.columns([2, 2.5, 1.5, 2.5, 1, 1.5])
                
                with col1:
                    st.markdown(f"<small>{type05_valor}</small>", unsafe_allow_html=True)
                
                with col2:
                    st.markdown(f"<small><b>{type06}</b></small>", unsafe_allow_html=True)
                
                with col3:
                    emoji = "üîµ" if tipo_predominante == 'Fixo' else "üü†"
                    tipo_abrev = "F" if tipo_predominante == 'Fixo' else "V"
                    st.markdown(f"<small>{emoji} {tipo_abrev}</small>", unsafe_allow_html=True)
                
                with col4:
                    sens = st.slider(
                        f"Sensibilidade",
                        min_value=0.0,
                        max_value=1.0,
                        value=valor_padrao_sens,
                        step=0.05,
                        key=f"sens_{type06}",
                        label_visibility="collapsed"
                    )
                    sensibilidades_type06[type06] = sens
                    # Atualizar valor tempor√°rio
                    st.session_state.valores_temp_sens[type06] = sens
                
                with col5:
                    st.markdown(f"<small><b>{sens*100:.0f}%</b></small>", unsafe_allow_html=True)
                
                with col6:
                    # Usar contador para for√ßar recria√ß√£o do widget
                    widget_key = f"infl_{type06}_{st.session_state.widget_key_counter}"
                    inflacao = st.number_input(
                        "Infla√ß√£o %",
                        min_value=0.0,
                        max_value=100.0,
                        value=valor_padrao_infl,
                        step=0.5,
                        format="%.2f",
                        key=widget_key,
                        label_visibility="collapsed"
                    )
                    inflacao_type06[type06] = inflacao
                    # Atualizar valor tempor√°rio
                    st.session_state.valores_temp_infl[type06] = inflacao
            
            # Bot√£o para aplicar configura√ß√µes
            st.markdown("---")
            
            # Armazenar configura√ß√µes tempor√°rias em session_state
            if 'sensibilidades_aplicadas' not in st.session_state:
                st.session_state.sensibilidades_aplicadas = None
            if 'inflacao_aplicada' not in st.session_state:
                st.session_state.inflacao_aplicada = None
            
            # Armazenar valores tempor√°rios para aplicar depois no bot√£o unificado
            config_sensibilidade_temp['sensibilidades_type06'] = sensibilidades_type06.copy() if sensibilidades_type06 else None
            config_sensibilidade_temp['inflacao_type06'] = inflacao_type06.copy() if inflacao_type06 else None
            
            # Usar configura√ß√µes aplicadas (se existirem) ou tempor√°rias
            if st.session_state.sensibilidades_aplicadas is not None:
                sensibilidades_type06 = st.session_state.sensibilidades_aplicadas
                inflacao_type06 = st.session_state.inflacao_aplicada
            else:
                # Usar valores tempor√°rios (ainda n√£o aplicados)
                # sensibilidades_type06 e inflacao_type06 j√° cont√™m os valores tempor√°rios
                pass
            
            # Valores globais para compatibilidade (n√£o ser√£o usados)
            sensibilidade_fixo = 0.0
            sensibilidade_variavel = 1.0
    else:
        st.warning("‚ö†Ô∏è Nenhum valor encontrado na coluna Type 06.")
        sensibilidade_fixo = 0.0
        sensibilidade_variavel = 1.0
        sensibilidades_type06 = None
else:
    st.warning("‚ö†Ô∏è Coluna 'Type 06' n√£o encontrada nos dados.")
    # Fallback para modo global simples
    col_sens1, col_sens2 = st.columns(2)
    with col_sens1:
        sensibilidade_fixo = st.slider(
            "üîµ Sensibilidade - Custo Fixo",
            min_value=0.0,
            max_value=1.0,
            value=0.0,
            step=0.05
        )
    with col_sens2:
        sensibilidade_variavel = st.slider(
            "üü† Sensibilidade - Custo Vari√°vel",
            min_value=0.0,
            max_value=1.0,
            value=1.0,
            step=0.05
        )
    sensibilidades_type06 = None

st.markdown("---")

# ====================================================================
# üéØ BOT√ÉO UNIFICADO PARA APLICAR TODAS AS CONFIGURA√á√ïES
# ====================================================================
# Inicializar session_state para configura√ß√µes do forecast
if 'config_forecast_aplicada' not in st.session_state:
    st.session_state.config_forecast_aplicada = {
        'ultimo_periodo_dados': None,
        'num_meses_prever': None,
        'num_meses_media': None,
        'meses_excluir_media': None,
        'periodos_restantes': None,
        'periodos_para_media': None,
        'ultimo_ano_dados': None
    }

# Armazenar configura√ß√µes tempor√°rias do forecast
config_forecast_temp = {
    'ultimo_periodo_dados': ultimo_periodo_dados,
    'num_meses_prever': num_meses_prever,
    'num_meses_media': num_meses_media,
    'meses_excluir_media': meses_excluir_media,
    'periodos_restantes': periodos_restantes,
    'periodos_para_media': periodos_para_media,
    'ultimo_ano_dados': ultimo_ano_dados
}

# Bot√£o unificado para aplicar todas as configura√ß√µes
col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
with col_btn2:
    aplicar_config_forecast = st.button(
        "‚úÖ Aplicar Configura√ß√µes do Forecast",
        use_container_width=True,
        type="primary",
        help="Clique para aplicar todas as configura√ß√µes (per√≠odos, sensibilidade e infla√ß√£o) e atualizar o forecast"
    )

# Se clicar em aplicar, salvar todas as configura√ß√µes
if aplicar_config_forecast:
    # Salvar configura√ß√µes do forecast
    st.session_state.config_forecast_aplicada = config_forecast_temp.copy()
    
    # Salvar configura√ß√µes de sensibilidade e infla√ß√£o
    # Modo Global
    if config_sensibilidade_temp['sensibilidade_fixo'] is not None:
        st.session_state.sensibilidade_fixo_aplicada = config_sensibilidade_temp['sensibilidade_fixo']
    if config_sensibilidade_temp['sensibilidade_variavel'] is not None:
        st.session_state.sensibilidade_variavel_aplicada = config_sensibilidade_temp['sensibilidade_variavel']
    if config_sensibilidade_temp['inflacao_global'] is not None:
        st.session_state.inflacao_global_aplicada = config_sensibilidade_temp['inflacao_global']
    
    # Modo Detalhado
    if config_sensibilidade_temp['sensibilidades_type06'] is not None:
        st.session_state.sensibilidades_aplicadas = config_sensibilidade_temp['sensibilidades_type06']
    if config_sensibilidade_temp['inflacao_type06'] is not None:
        st.session_state.inflacao_aplicada = config_sensibilidade_temp['inflacao_type06']
    
    # Limpar cache das fun√ß√µes de forecast
    try:
        calcular_medias_forecast.clear()
        calcular_volumes_cpu.clear()
        calcular_forecast_completo.clear()
        processar_tabela_forecast.clear()
    except:
        pass
    
    # üÜï NOVA FUNCIONALIDADE: Marcar que precisa gerar tabela completa com forecast
    st.session_state.gerar_tabela_completa_forecast = True
    
    st.success("‚úÖ Configura√ß√µes aplicadas com sucesso! Recalculando forecast...")
    st.rerun()

# Usar configura√ß√µes aplicadas (se existirem) ou tempor√°rias
if st.session_state.config_forecast_aplicada['ultimo_periodo_dados'] is not None:
    # Usar configura√ß√µes aplicadas
    ultimo_periodo_dados = st.session_state.config_forecast_aplicada['ultimo_periodo_dados']
    num_meses_prever = st.session_state.config_forecast_aplicada['num_meses_prever']
    num_meses_media_salvo = st.session_state.config_forecast_aplicada['num_meses_media']
    meses_excluir_media = st.session_state.config_forecast_aplicada['meses_excluir_media']
    periodos_restantes = st.session_state.config_forecast_aplicada['periodos_restantes']
    periodos_para_media = st.session_state.config_forecast_aplicada['periodos_para_media']
    ultimo_ano_dados = st.session_state.config_forecast_aplicada['ultimo_ano_dados']
    
    # Recalcular √≠ndices e meses baseados nas configura√ß√µes aplicadas
    if ' ' in str(ultimo_periodo_dados):
        ultimo_mes_dados = str(ultimo_periodo_dados).split(' ', 1)[0]
    else:
        ultimo_mes_dados = str(ultimo_periodo_dados)
    ultimo_mes_dados = ultimo_mes_dados.capitalize()
    indice_ultimo_mes = meses_ano.index(ultimo_mes_dados) if ultimo_mes_dados in meses_ano else 0
    
    # üîß CORRE√á√ÉO: Recalcular max_meses_media baseado no novo √∫ltimo per√≠odo e ajustar num_meses_media
    meses_historicos_disponiveis_aplicado = meses_ano[:indice_ultimo_mes + 1]
    meses_com_valor_aplicado = len(meses_historicos_disponiveis_aplicado)  # Valor padr√£o
    if meses_historicos_disponiveis_aplicado and not df_filtrado.empty and 'Per√≠odo' in df_filtrado.columns and 'Total' in df_filtrado.columns:
        # Extrair ano do √∫ltimo per√≠odo
        ano_referencia_contagem_aplicado = None
        if ' ' in str(ultimo_periodo_dados):
            partes_periodo = str(ultimo_periodo_dados).split(' ', 1)
            if len(partes_periodo) > 1 and partes_periodo[1].isdigit():
                ano_referencia_contagem_aplicado = partes_periodo[1]
        if ano_referencia_contagem_aplicado is None:
            ano_referencia_contagem_aplicado = str(ano_maximo) if 'ano_maximo' in locals() else str(datetime.now().year)
        
        # Criar lista de per√≠odos at√© o √∫ltimo m√™s selecionado
        periodos_ate_ultimo_aplicado = []
        for mes in meses_historicos_disponiveis_aplicado:
            periodo_com_ano = f"{mes} {ano_referencia_contagem_aplicado}"
            periodos_ate_ultimo_aplicado.append(periodo_com_ano.lower())
        
        # Filtrar df_filtrado para per√≠odos at√© o √∫ltimo m√™s
        periodos_no_df_aplicado = df_filtrado['Per√≠odo'].astype(str).str.strip().str.lower()
        mask_periodos_ate_ultimo_aplicado = periodos_no_df_aplicado.isin(periodos_ate_ultimo_aplicado)
        df_periodos_ate_ultimo_aplicado = df_filtrado[mask_periodos_ate_ultimo_aplicado].copy()
        
        # Contar per√≠odos √∫nicos que t√™m pelo menos uma linha com Total != 0 (inclui valores negativos, exclui apenas zeros)
        if not df_periodos_ate_ultimo_aplicado.empty:
            # Normalizar per√≠odos para compara√ß√£o
            df_periodos_ate_ultimo_aplicado_copy = df_periodos_ate_ultimo_aplicado.copy()
            df_periodos_ate_ultimo_aplicado_copy['Per√≠odo_Normalizado'] = df_periodos_ate_ultimo_aplicado_copy['Per√≠odo'].astype(str).str.strip().str.lower()
            
            # Verificar se h√° pelo menos uma linha com Total != 0 para cada per√≠odo
            periodos_unicos_aplicado = df_periodos_ate_ultimo_aplicado_copy['Per√≠odo_Normalizado'].unique()
            periodos_com_valor_lista_aplicado = []
            for periodo in periodos_unicos_aplicado:
                df_periodo = df_periodos_ate_ultimo_aplicado_copy[df_periodos_ate_ultimo_aplicado_copy['Per√≠odo_Normalizado'] == periodo]
                # Verificar se h√° pelo menos uma linha com Total != 0
                if (df_periodo['Total'] != 0).any():
                    periodos_com_valor_lista_aplicado.append(periodo)
            meses_com_valor_aplicado = len(periodos_com_valor_lista_aplicado)
    
    # Ajustar num_meses_media se exceder o novo m√°ximo
    max_meses_media_aplicado = max(1, meses_com_valor_aplicado)
    num_meses_media = min(num_meses_media_salvo, max_meses_media_aplicado)
else:
    # Primeira vez - usar configura√ß√µes tempor√°rias mas n√£o calcular ainda
    st.info("‚ÑπÔ∏è Configure os par√¢metros acima e clique em 'Aplicar Configura√ß√µes do Forecast' para calcular o forecast.")
    
    # ====================================================================
    # üìä GR√ÅFICO "SOMA DO VALOR POR PER√çODO" - USANDO DADOS DA PASTA FORECAST
    # Este gr√°fico aparece SEMPRE que houver dados na pasta Forecast
    # ====================================================================
    st.markdown("---")
    st.markdown("### üìä Soma do Valor por Per√≠odo (Dados do Forecast)")
    
    # Fun√ß√£o para ordenar por m√™s (mesma do TC_Ext)
    ORDEM_MESES_GRAFICO = ['janeiro', 'fevereiro', 'mar√ßo', 'abril', 'maio', 'junho',
                           'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro']
    
    def ordenar_por_mes_forecast(df, coluna_periodo='Per√≠odo'):
        """Ordena DataFrame por ordem cronol√≥gica dos meses, considerando ano se dispon√≠vel"""
        df_copy = df.copy()
        
        # Se houver coluna "Ano" e m√∫ltiplos anos, ordenar por ano e m√™s
        if 'Ano' in df_copy.columns and df_copy['Ano'].nunique() > 1:
            # Criar coluna de ordena√ß√£o: ano primeiro, depois m√™s
            df_copy['_ordem_ano'] = df_copy['Ano']
            df_copy['_ordem_mes'] = df_copy[coluna_periodo].astype(str).str.lower().map(
                {mes: idx for idx, mes in enumerate(ORDEM_MESES_GRAFICO)}
            ).fillna(999)
            df_copy = df_copy.sort_values(['_ordem_ano', '_ordem_mes'])
            df_copy = df_copy.drop(columns=['_ordem_ano', '_ordem_mes'])
        else:
            # Ordena√ß√£o simples por m√™s
            df_copy['_ordem_mes'] = df_copy[coluna_periodo].astype(str).str.lower().map(
                {mes: idx for idx, mes in enumerate(ORDEM_MESES_GRAFICO)}
            ).fillna(999)
            df_copy = df_copy.sort_values('_ordem_mes')
            df_copy = df_copy.drop(columns=['_ordem_mes'])
        
        return df_copy
    
    try:
        # Carregar dados do arquivo forecast gerado na pasta Forecast
        caminho_forecast_grafico = os.path.join("dados", "Forecast", "forecast_completo.parquet")
        if os.path.exists(caminho_forecast_grafico):
            df_forecast_grafico = pd.read_parquet(caminho_forecast_grafico)
            
            # Aplicar filtros (Oficina, Ve√≠culo, USI) mas N√ÉO filtrar por Per√≠odo
            # As vari√°veis j√° est√£o definidas no escopo global
            if 'Oficina' in df_forecast_grafico.columns:
                if oficina_selecionadas and "Todos" not in oficina_selecionadas:
                    df_forecast_grafico = df_forecast_grafico[
                        df_forecast_grafico['Oficina'].astype(str).isin(oficina_selecionadas)
                    ].copy()
            
            if 'Ve√≠culo' in df_forecast_grafico.columns:
                if veiculo_selecionados and "Todos" not in veiculo_selecionados:
                    df_forecast_grafico = df_forecast_grafico[
                        df_forecast_grafico['Ve√≠culo'].astype(str).isin(veiculo_selecionados)
                    ].copy()
            
            if 'USI' in df_forecast_grafico.columns:
                if usi_selecionada and "Todos" not in usi_selecionada:
                    df_forecast_grafico = df_forecast_grafico[
                        df_forecast_grafico['USI'].astype(str).isin(usi_selecionada)
                    ].copy()
            
            # Verificar se h√° coluna Total
            if 'Total' in df_forecast_grafico.columns and 'Per√≠odo' in df_forecast_grafico.columns:
                # Verificar se h√° m√∫ltiplos anos
                tem_multiplos_anos = 'Ano' in df_forecast_grafico.columns and df_forecast_grafico['Ano'].nunique() > 1
                
                if tem_multiplos_anos:
                    # Agrupar por Ano e Per√≠odo
                    chart_data = df_forecast_grafico.groupby(['Ano', 'Per√≠odo'])['Total'].sum().reset_index()
                    
                    # Criar coluna combinada para o r√≥tulo do gr√°fico
                    chart_data['Per√≠odo_Completo'] = chart_data['Per√≠odo'].astype(str) + ' ' + chart_data['Ano'].astype(str)
                    
                    # Ordenar por ano e m√™s (usar fun√ß√£o similar ao TC_Ext)
                    chart_data = ordenar_por_mes_forecast(chart_data, 'Per√≠odo')
                    ordem_periodos = chart_data['Per√≠odo_Completo'].tolist()
                    coluna_periodo_grafico = 'Per√≠odo_Completo'
                else:
                    # Agrupar apenas por Per√≠odo
                    chart_data = df_forecast_grafico.groupby('Per√≠odo')['Total'].sum().reset_index()
                    
                    # Ordenar por m√™s
                    chart_data = ordenar_por_mes_forecast(chart_data, 'Per√≠odo')
                    ordem_periodos = chart_data['Per√≠odo'].tolist()
                    coluna_periodo_grafico = 'Per√≠odo'
                
                # Criar gr√°fico (mesma l√≥gica do TC_Ext)
                grafico_barras = alt.Chart(chart_data).mark_bar().encode(
                    x=alt.X(
                        f'{coluna_periodo_grafico}:N',
                        title='Per√≠odo',
                        sort=ordem_periodos
                    ),
                    y=alt.Y('Total:Q', title='Soma do Valor (R$)'),
                    color=alt.Color(
                        'Total:Q',
                        title='Total',
                        scale=alt.Scale(scheme='blues')
                    ),
                    tooltip=[
                        alt.Tooltip(f'{coluna_periodo_grafico}:N', title='Per√≠odo'),
                        alt.Tooltip('Total:Q', title='Soma do Valor', format=',.2f')
                    ]
                ).properties(
                    title='Soma do Valor por Per√≠odo',
                    height=400
                )
                
                # Adicionar r√≥tulos com valores nas barras
                rotulos = grafico_barras.mark_text(
                    align='center',
                    baseline='middle',
                    dy=-10,
                    color='white',
                    fontSize=11
                ).encode(
                    text=alt.Text('Total:Q', format=',.2f')
                )
                
                grafico_final = grafico_barras + rotulos
                st.altair_chart(grafico_final, use_container_width=True)
                
                # Mostrar resumo
                total_geral = chart_data['Total'].sum()
                st.info(f"üìä **Total Geral:** R$ {total_geral:,.2f}")
            else:
                st.warning("‚ö†Ô∏è Colunas 'Total' ou 'Per√≠odo' n√£o encontradas no arquivo forecast.")
        else:
            st.warning(f"‚ö†Ô∏è Arquivo n√£o encontrado: {caminho_forecast_grafico}")
            st.info("‚ÑπÔ∏è O arquivo ser√° gerado quando voc√™ clicar em 'Aplicar Configura√ß√µes do Forecast'.")
    except Exception as e:
        st.error(f"‚ùå Erro ao criar gr√°fico 'Soma do Valor por Per√≠odo': {str(e)}")
        import traceback
        st.error(f"Detalhes: {traceback.format_exc()}")
    
    st.stop()

st.markdown("---")

# Carregar dados de volume
df_vol = load_volume_data(ano_selecionado)

# üîß CORRE√á√ÉO: Filtrar volumes pelas oficinas e ve√≠culos selecionados
if df_vol is not None and not df_vol.empty:
    # Filtrar por Oficina
    if 'Oficina' in df_vol.columns:
        if oficina_selecionadas and "Todos" not in oficina_selecionadas:
            df_vol = df_vol[
                df_vol['Oficina'].astype(str).isin(oficina_selecionadas)
            ].copy()
    # Filtrar por Ve√≠culo
    if 'Ve√≠culo' in df_vol.columns:
        if veiculo_selecionados and "Todos" not in veiculo_selecionados:
            df_vol = df_vol[
                df_vol['Ve√≠culo'].astype(str).isin(veiculo_selecionados)
            ].copy()

# Carregar dados de volume hist√≥rico (priorit√°rio para meses futuros)
df_vol_historico = load_volume_historico_data()

# üîß CORRE√á√ÉO: Filtrar volumes hist√≥ricos pelas oficinas e ve√≠culos selecionados
if df_vol_historico is not None and not df_vol_historico.empty:
    # Filtrar por Oficina
    if 'Oficina' in df_vol_historico.columns:
        if oficina_selecionadas and "Todos" not in oficina_selecionadas:
            df_vol_historico = df_vol_historico[
                df_vol_historico['Oficina'].astype(str).isin(oficina_selecionadas)
            ].copy()
    # Filtrar por Ve√≠culo
    if 'Ve√≠culo' in df_vol_historico.columns:
        if veiculo_selecionados and "Todos" not in veiculo_selecionados:
            df_vol_historico = df_vol_historico[
                df_vol_historico['Ve√≠culo'].astype(str).isin(veiculo_selecionados)
            ].copy()

# Combinar os dados, priorizando o hist√≥rico
if df_vol_historico is not None and not df_vol_historico.empty:
    if df_vol is not None and not df_vol.empty:
        # Combinar: hist√≥rico tem prioridade, mas manter dados regulares que n√£o est√£o no hist√≥rico
        # Primeiro, identificar per√≠odos que est√£o no hist√≥rico
        if 'Per√≠odo' in df_vol_historico.columns and 'Per√≠odo' in df_vol.columns:
            periodos_historico = df_vol_historico['Per√≠odo'].unique()
            # Filtrar df_vol para remover per√≠odos que est√£o no hist√≥rico
            df_vol_filtrado = df_vol[~df_vol['Per√≠odo'].isin(periodos_historico)]
            # Combinar: hist√≥rico primeiro, depois dados regulares restantes
            df_vol = pd.concat([df_vol_historico, df_vol_filtrado], ignore_index=True)
        else:
            # Se n√£o tiver coluna Per√≠odo, apenas usar hist√≥rico
            df_vol = df_vol_historico
    else:
        # Se n√£o tiver df_vol, usar apenas hist√≥rico
        df_vol = df_vol_historico
    st.info("‚ÑπÔ∏è Dados de volume hist√≥rico carregados. Volumes futuros ser√£o priorizados do arquivo hist√≥rico.")
elif df_vol is None:
    st.warning("‚ö†Ô∏è Arquivo df_vol.parquet n√£o encontrado. Algumas funcionalidades podem n√£o estar dispon√≠veis.")
    df_vol = pd.DataFrame()

# üîß CORRE√á√ÉO: Garantir que volumes finais estejam filtrados pelas oficinas e ve√≠culos selecionados
# (aplicar novamente ap√≥s combina√ß√£o para garantir que funcione em todos os casos)
if df_vol is not None and not df_vol.empty:
    # Filtrar por Oficina
    if 'Oficina' in df_vol.columns:
        if oficina_selecionadas and "Todos" not in oficina_selecionadas:
            df_vol = df_vol[
                df_vol['Oficina'].astype(str).isin(oficina_selecionadas)
            ].copy()
    # Filtrar por Ve√≠culo
    if 'Ve√≠culo' in df_vol.columns:
        if veiculo_selecionados and "Todos" not in veiculo_selecionados:
            df_vol = df_vol[
                df_vol['Ve√≠culo'].astype(str).isin(veiculo_selecionados)
            ].copy()

# üîß CORRE√á√ÉO CR√çTICA: Filtrar volume para manter apenas oficinas/ve√≠culos que t√™m valores (Total != 0)
# Isso garante que apenas oficinas com dados reais sejam consideradas no volume
if df_vol is not None and not df_vol.empty and 'df_filtrado' in locals() and df_filtrado is not None and not df_filtrado.empty:
    # Identificar quais oficinas e ve√≠culos t√™m valores (Total != 0) no df_filtrado
    if 'Total' in df_filtrado.columns:
        # Filtrar apenas linhas com Total != 0
        df_com_valores = df_filtrado[df_filtrado['Total'] != 0].copy()
        
        if not df_com_valores.empty:
            # Obter lista de oficinas que t√™m valores
            oficinas_com_valores = set()
            if 'Oficina' in df_com_valores.columns:
                oficinas_com_valores = set(df_com_valores['Oficina'].astype(str).unique())
            
            # Obter lista de ve√≠culos que t√™m valores
            veiculos_com_valores = set()
            if 'Ve√≠culo' in df_com_valores.columns:
                veiculos_com_valores = set(df_com_valores['Ve√≠culo'].astype(str).unique())
            
            # Filtrar df_vol para manter apenas oficinas e ve√≠culos que t√™m valores
            if 'Oficina' in df_vol.columns and oficinas_com_valores:
                df_vol = df_vol[
                    df_vol['Oficina'].astype(str).isin(oficinas_com_valores)
                ].copy()
            
            if 'Ve√≠culo' in df_vol.columns and veiculos_com_valores:
                df_vol = df_vol[
                    df_vol['Ve√≠culo'].astype(str).isin(veiculos_com_valores)
                ].copy()

# Verificar se temos as colunas necess√°rias
colunas_necessarias = ['Oficina', 'Ve√≠culo', 'Per√≠odo', 'Total', 'Custo']
colunas_faltando = [col for col in colunas_necessarias if col not in df_filtrado.columns]

if colunas_faltando:
    st.error(f"‚ùå Colunas necess√°rias n√£o encontradas: {', '.join(colunas_faltando)}")
    st.info("‚ÑπÔ∏è Certifique-se de que o arquivo df_final.parquet cont√©m todas as colunas necess√°rias.")
else:
    # Fun√ß√£o para identificar se √© custo fixo ou vari√°vel
    def is_custo_fixo(valor_custo):
        """Identifica se o custo √© fixo baseado no valor da coluna Custo"""
        if pd.isna(valor_custo):
            return False
        valor_str = str(valor_custo).strip().upper()
        # Considerar como fixo se cont√©m palavras-chave
        palavras_fixo = ['FIXO', 'FIX', 'FIXED']
        return any(palavra in valor_str for palavra in palavras_fixo)
    
    # Criar coluna indicando se √© fixo ou vari√°vel
    df_filtrado['Tipo_Custo'] = df_filtrado['Custo'].apply(is_custo_fixo)
    df_filtrado['Tipo_Custo'] = df_filtrado['Tipo_Custo'].map({True: 'Fixo', False: 'Vari√°vel'})
    
    # Valida√ß√£o: verificar se h√° per√≠odos para calcular a m√©dia
    # Se n√£o houver per√≠odos configurados, tentar usar per√≠odos dispon√≠veis nos dados
    if not periodos_para_media:
        # Tentar encontrar per√≠odos dispon√≠veis nos dados at√© o √∫ltimo m√™s selecionado
        if 'Per√≠odo' in df_filtrado.columns:
            periodos_disponiveis_df = df_filtrado['Per√≠odo'].dropna().unique()
            # Filtrar per√≠odos at√© o √∫ltimo m√™s selecionado
            if ultimo_periodo_dados:
                # Extrair m√™s e ano do √∫ltimo per√≠odo
                if ' ' in str(ultimo_periodo_dados):
                    ultimo_mes_nome = str(ultimo_periodo_dados).split(' ', 1)[0].lower()
                    ultimo_ano_num = int(str(ultimo_periodo_dados).split(' ', 1)[1]) if str(ultimo_periodo_dados).split(' ', 1)[1].isdigit() else None
                else:
                    ultimo_mes_nome = str(ultimo_periodo_dados).lower()
                    ultimo_ano_num = None
                
                # Tentar encontrar per√≠odos que correspondem aos meses hist√≥ricos dispon√≠veis
                periodos_encontrados = []
                for periodo_df in periodos_disponiveis_df:
                    periodo_df_str = str(periodo_df).strip().lower()
                    periodo_df_mes = periodo_df_str.split(' ', 1)[0] if ' ' in periodo_df_str else periodo_df_str
                    periodo_df_ano = int(periodo_df_str.split(' ', 1)[1]) if ' ' in periodo_df_str and periodo_df_str.split(' ', 1)[1].isdigit() else None
                    
                    # Verificar se o per√≠odo est√° antes ou no √∫ltimo m√™s selecionado
                    if periodo_df_mes in [m.lower() for m in meses_historicos_disponiveis]:
                        if ultimo_ano_num and periodo_df_ano:
                            if periodo_df_ano < ultimo_ano_num or (periodo_df_ano == ultimo_ano_num and periodo_df_mes <= ultimo_mes_nome):
                                periodos_encontrados.append(str(periodo_df))
                        elif not ultimo_ano_num or not periodo_df_ano:
                            periodos_encontrados.append(str(periodo_df))
                
                if periodos_encontrados:
                    # Pegar os √∫ltimos N per√≠odos encontrados
                    periodos_para_media = periodos_encontrados[-num_meses_media:] if len(periodos_encontrados) >= num_meses_media else periodos_encontrados
                    st.warning(f"‚ö†Ô∏è **Aviso:** N√£o foram encontrados todos os {num_meses_media} per√≠odos solicitados. Usando {len(periodos_para_media)} per√≠odo(s) dispon√≠vel(is): {', '.join(periodos_para_media)}")
                else:
                    st.error("‚ùå **Erro de Configura√ß√£o:** Nenhum per√≠odo dispon√≠vel para calcular a m√©dia hist√≥rica.")
                    st.info("üí° Ajuste a configura√ß√£o do forecast na sidebar:")
                    st.info("   - Selecione um m√™s hist√≥rico v√°lido")
                    st.info("   - Ajuste os meses a excluir")
                    st.info("   - Verifique se h√° dados hist√≥ricos dispon√≠veis")
                    st.stop()
            else:
                st.error("‚ùå **Erro de Configura√ß√£o:** Nenhum per√≠odo dispon√≠vel para calcular a m√©dia hist√≥rica.")
                st.info("üí° Ajuste a configura√ß√£o do forecast na sidebar:")
                st.info("   - Selecione um m√™s hist√≥rico v√°lido")
                st.info("   - Ajuste os meses a excluir")
                st.info("   - Verifique se h√° dados hist√≥ricos dispon√≠veis")
                st.stop()
        else:
            st.error("‚ùå **Erro de Configura√ß√£o:** Nenhum per√≠odo dispon√≠vel para calcular a m√©dia hist√≥rica.")
            st.info("üí° Ajuste a configura√ß√£o do forecast na sidebar:")
            st.info("   - Selecione um m√™s hist√≥rico v√°lido")
            st.info("   - Ajuste os meses a excluir")
            st.info("   - Verifique se h√° dados hist√≥ricos dispon√≠veis")
            st.stop()
    
    # Valida√ß√£o: verificar se h√° per√≠odos para prever
    if not periodos_restantes:
        st.error("‚ùå **Erro de Configura√ß√£o:** Nenhum per√≠odo selecionado para prever.")
        st.info("üí° Ajuste a configura√ß√£o do forecast na sidebar:")
        st.info("   - Selecione o √∫ltimo m√™s com dados reais")
        st.info("   - Defina quantos meses prever")
        st.stop()
    
    # Fun√ß√£o para calcular m√©dias com cache
    @st.cache_data(ttl=3600, max_entries=10, show_spinner=False)
    def calcular_medias_forecast(df_filtrado_cache, colunas_adicionais_cache, periodos_para_media_cache, ultimo_periodo_dados_cache=None):
        """Calcula m√©dias mensais hist√≥ricas com cache, usando apenas os per√≠odos selecionados"""
        # üîß CORRE√á√ÉO CR√çTICA: Extrair ano de refer√™ncia ANTES de qualquer filtro
        # Isso garante que o mesmo ano seja usado em todos os filtros
        ano_referencia_filtro = None
        if periodos_para_media_cache:
            # Extrair ano dos per√≠odos procurados
            anos_nos_periodos = []
            for periodo_procurado in periodos_para_media_cache:
                periodo_str = str(periodo_procurado).strip()
                if ' ' in periodo_str:
                    partes = periodo_str.split(' ', 1)
                    if len(partes) > 1 and partes[1].isdigit():
                        anos_nos_periodos.append(int(partes[1]))
            if anos_nos_periodos:
                ano_referencia_filtro = max(anos_nos_periodos)
        if ano_referencia_filtro is None and ultimo_periodo_dados_cache:
            ultimo_periodo_str = str(ultimo_periodo_dados_cache).strip()
            if ' ' in ultimo_periodo_str:
                ano_str = ultimo_periodo_str.split(' ', 1)[1]
                if ano_str.isdigit():
                    ano_referencia_filtro = int(ano_str)
        
        # Filtrar apenas os per√≠odos que ser√£o usados para calcular a m√©dia
        if periodos_para_media_cache and 'Per√≠odo' in df_filtrado_cache.columns:
            # Normalizar per√≠odos procurados (manter m√™s + ano se dispon√≠vel)
            periodos_procurados_normalizados = []
            for periodo_procurado in periodos_para_media_cache:
                periodo_str = str(periodo_procurado).strip()
                # Normalizar para min√∫sculas para compara√ß√£o
                periodos_procurados_normalizados.append(periodo_str.lower())
            
            # Extrair √∫ltimo m√™s e ano para valida√ß√£o
            ultimo_mes_limite = None
            ultimo_ano_limite = None
            if ultimo_periodo_dados_cache:
                ultimo_periodo_str = str(ultimo_periodo_dados_cache).strip().lower()
                if ' ' in ultimo_periodo_str:
                    ultimo_mes_limite = ultimo_periodo_str.split(' ', 1)[0]
                    ultimo_ano_limite = int(ultimo_periodo_str.split(' ', 1)[1]) if ultimo_periodo_str.split(' ', 1)[1].isdigit() else None
                else:
                    ultimo_mes_limite = ultimo_periodo_str
                    ultimo_ano_limite = None
            
            # Verificar per√≠odos no DataFrame
            periodos_no_df = df_filtrado_cache['Per√≠odo'].astype(str).str.strip().str.lower()
            
            # üîß CORRE√á√ÉO: Usar ano_referencia_filtro j√° definido no in√≠cio da fun√ß√£o
            # Se n√£o foi definido, usar ultimo_ano_limite como fallback
            if ano_referencia_filtro is None:
                ano_referencia_filtro = ultimo_ano_limite
            
            # Criar m√°scara: comparar per√≠odo completo (m√™s + ano) quando dispon√≠vel
            # üîß CORRE√á√ÉO CR√çTICA: Garantir que apenas per√≠odos do ano de refer√™ncia sejam inclu√≠dos
            def periodo_corresponde(periodo_df):
                periodo_df_lower = str(periodo_df).strip().lower()
                
                # üîß CORRE√á√ÉO CR√çTICA: Se h√° ano de refer√™ncia definido, filtrar APENAS esse ano
                if ano_referencia_filtro:
                    periodo_df_tem_ano = ' ' in periodo_df_lower and len(periodo_df_lower.split(' ', 1)) > 1
                    if periodo_df_tem_ano:
                        periodo_df_ano = int(periodo_df_lower.split(' ', 1)[1]) if periodo_df_lower.split(' ', 1)[1].isdigit() else None
                        # Se o per√≠odo tem ano diferente do ano de refer√™ncia, N√ÉO incluir
                        if periodo_df_ano != ano_referencia_filtro:
                            return False
                    else:
                        # Se o per√≠odo n√£o tem ano mas h√° ano de refer√™ncia, N√ÉO incluir
                        # (evita incluir per√≠odos sem ano quando h√° per√≠odos com ano)
                        return False
                
                # Verificar se o per√≠odo est√° antes ou no √∫ltimo m√™s selecionado
                if ultimo_mes_limite and ultimo_ano_limite:
                    periodo_df_tem_ano = ' ' in periodo_df_lower and len(periodo_df_lower.split(' ', 1)) > 1
                    if periodo_df_tem_ano:
                        periodo_df_ano = int(periodo_df_lower.split(' ', 1)[1]) if periodo_df_lower.split(' ', 1)[1].isdigit() else None
                        periodo_df_mes = periodo_df_lower.split(' ', 1)[0]
                        
                        # Verificar se est√° antes do √∫ltimo m√™s
                        if periodo_df_ano and periodo_df_ano > ultimo_ano_limite:
                            return False
                        if periodo_df_ano == ultimo_ano_limite:
                            # Comparar meses usando √≠ndice
                            meses_ano_lower = [m.lower() for m in meses_ano]
                            if periodo_df_mes in meses_ano_lower and ultimo_mes_limite in meses_ano_lower:
                                idx_periodo = meses_ano_lower.index(periodo_df_mes)
                                idx_limite = meses_ano_lower.index(ultimo_mes_limite)
                                if idx_periodo > idx_limite:
                                    return False
                    else:
                        # Se o per√≠odo do DataFrame n√£o tem ano, verificar apenas pelo m√™s
                        periodo_df_mes = periodo_df_lower
                        meses_ano_lower = [m.lower() for m in meses_ano]
                        if periodo_df_mes in meses_ano_lower and ultimo_mes_limite in meses_ano_lower:
                            idx_periodo = meses_ano_lower.index(periodo_df_mes)
                            idx_limite = meses_ano_lower.index(ultimo_mes_limite)
                            if idx_periodo > idx_limite:
                                return False
                
                # Compara√ß√£o exata primeiro (per√≠odo completo)
                if periodo_df_lower in periodos_procurados_normalizados:
                    return True
                
                # Se n√£o houver correspond√™ncia exata, verificar se ambos t√™m ano
                periodo_df_tem_ano = ' ' in periodo_df_lower and len(periodo_df_lower.split(' ', 1)) > 1
                
                for periodo_procurado in periodos_procurados_normalizados:
                    periodo_procurado_tem_ano = ' ' in periodo_procurado and len(periodo_procurado.split(' ', 1)) > 1
                    
                    # Se ambos t√™m ano, comparar per√≠odo completo (j√° verificamos exato acima)
                    if periodo_df_tem_ano and periodo_procurado_tem_ano:
                        # Se ambos t√™m ano mas n√£o s√£o iguais, n√£o corresponde
                        continue
                    
                    # Se nenhum tem ano ou apenas um tem, comparar apenas o m√™s
                    # MAS APENAS se n√£o houver ano de refer√™ncia definido
                    if not ano_referencia_filtro:
                        mes_df = periodo_df_lower.split(' ', 1)[0] if ' ' in periodo_df_lower else periodo_df_lower
                        mes_procurado = periodo_procurado.split(' ', 1)[0] if ' ' in periodo_procurado else periodo_procurado
                        
                        if mes_df == mes_procurado:
                            # Se o per√≠odo procurado tem ano mas o do DF n√£o tem, n√£o incluir
                            if periodo_procurado_tem_ano and not periodo_df_tem_ano:
                                continue
                            return True
                
                return False
            
            df_filtrado_media = df_filtrado_cache[
                periodos_no_df.apply(periodo_corresponde)
            ].copy()
            
            # Se n√£o encontrou correspond√™ncias, tentar encontrar per√≠odos alternativos pelos meses
            # MAS APENAS se estiverem antes do √∫ltimo m√™s selecionado
            if df_filtrado_media.empty:
                # Tentar encontrar per√≠odos dispon√≠veis nos dados que correspondem aos meses solicitados
                periodos_disponiveis_df = df_filtrado_cache['Per√≠odo'].dropna().unique()
                periodos_encontrados_alternativos = []
                
                # Extrair apenas os meses dos per√≠odos procurados
                meses_procurados = []
                for periodo_procurado in periodos_para_media_cache:
                    periodo_str = str(periodo_procurado).strip().lower()
                    mes_procurado = periodo_str.split(' ', 1)[0] if ' ' in periodo_str else periodo_str
                    meses_procurados.append(mes_procurado)
                
                # Procurar per√≠odos no DataFrame que correspondem aos meses procurados
                # MAS APENAS se estiverem antes ou no √∫ltimo m√™s selecionado
                for periodo_df in periodos_disponiveis_df:
                    periodo_df_str = str(periodo_df).strip().lower()
                    periodo_df_mes = periodo_df_str.split(' ', 1)[0] if ' ' in periodo_df_str else periodo_df_str
                    periodo_df_ano = int(periodo_df_str.split(' ', 1)[1]) if ' ' in periodo_df_str and periodo_df_str.split(' ', 1)[1].isdigit() else None
                    
                    # Verificar se o m√™s corresponde
                    if periodo_df_mes in meses_procurados:
                        # Verificar se est√° antes ou no √∫ltimo m√™s selecionado
                        if ultimo_mes_limite and ultimo_ano_limite:
                            if periodo_df_ano:
                                if periodo_df_ano > ultimo_ano_limite:
                                    continue
                                if periodo_df_ano == ultimo_ano_limite:
                                    # Comparar meses usando √≠ndice
                                    meses_ano_lower = [m.lower() for m in meses_ano]
                                    if periodo_df_mes in meses_ano_lower and ultimo_mes_limite in meses_ano_lower:
                                        idx_periodo = meses_ano_lower.index(periodo_df_mes)
                                        idx_limite = meses_ano_lower.index(ultimo_mes_limite)
                                        if idx_periodo > idx_limite:
                                            continue
                            elif not periodo_df_ano:
                                # Se n√£o tem ano, verificar pelo m√™s
                                meses_ano_lower = [m.lower() for m in meses_ano]
                                if periodo_df_mes in meses_ano_lower and ultimo_mes_limite in meses_ano_lower:
                                    idx_periodo = meses_ano_lower.index(periodo_df_mes)
                                    idx_limite = meses_ano_lower.index(ultimo_mes_limite)
                                    if idx_periodo > idx_limite:
                                        continue
                        
                        periodos_encontrados_alternativos.append(str(periodo_df))
                
                # Se encontrou per√≠odos alternativos, usar eles
                if periodos_encontrados_alternativos:
                    periodos_alternativos_normalizados = [p.strip().lower() for p in periodos_encontrados_alternativos]
                    df_filtrado_media = df_filtrado_cache[
                        periodos_no_df.isin(periodos_alternativos_normalizados)
                    ].copy()
        else:
            # Se n√£o houver per√≠odos selecionados, usar todos os dados (comportamento original)
            df_filtrado_media = df_filtrado_cache.copy()
        
        if df_filtrado_media.empty:
            # Retornar DataFrames vazios se n√£o houver dados
            colunas_base = ['Oficina', 'Ve√≠culo', 'Per√≠odo', 'Tipo_Custo'] + colunas_adicionais_cache
            df_medias = pd.DataFrame(columns=colunas_base + ['Total'])
            colunas_media = ['Oficina', 'Ve√≠culo', 'Tipo_Custo'] + colunas_adicionais_cache
            df_media_mensal = pd.DataFrame(columns=colunas_media + ['Total'])
            return df_medias, df_media_mensal
        
        # üîß CORRE√á√ÉO CR√çTICA: Normalizar Per√≠odo para SEMPRE incluir o ano antes do groupby
        # Isso evita somar meses de anos diferentes (ex: "Novembro 2024" + "Novembro 2025")
        # üîß CORRE√á√ÉO: Usar o mesmo ano_referencia_filtro que foi usado no filtro inicial
        ano_referencia = ano_referencia_filtro
        if ano_referencia is None:
            if ultimo_periodo_dados_cache:
                ultimo_periodo_str = str(ultimo_periodo_dados_cache).strip()
                if ' ' in ultimo_periodo_str:
                    ano_str = ultimo_periodo_str.split(' ', 1)[1]
                    if ano_str.isdigit():
                        ano_referencia = int(ano_str)
            elif periodos_para_media_cache:
                # Tentar extrair ano dos per√≠odos selecionados
                for p in periodos_para_media_cache:
                    p_str = str(p).strip()
                    if ' ' in p_str:
                        ano_str = p_str.split(' ', 1)[1]
                        if ano_str.isdigit():
                            ano_referencia = int(ano_str)
                            break
        
        # üîß CORRE√á√ÉO CR√çTICA: Normalizar Per√≠odo usando coluna Ano ORIGINAL (n√£o ano_referencia)
        # Estrat√©gia: Se Per√≠odo n√£o tem ano, usar coluna Ano original dos dados
        # Isso garante que Per√≠odo e Ano sejam sempre consistentes
        if 'Per√≠odo' in df_filtrado_media.columns:
            df_filtrado_media = df_filtrado_media.copy()
            # üîß CORRE√á√ÉO: Converter Per√≠odo para string ANTES de qualquer opera√ß√£o (pode ser Categorical)
            df_filtrado_media['Per√≠odo'] = df_filtrado_media['Per√≠odo'].astype(str).str.lower().str.strip()
            
            def extrair_ano_do_periodo(periodo_str):
                periodo_str = str(periodo_str).strip()
                if ' ' in periodo_str:
                    partes = periodo_str.split(' ', 1)
                    if len(partes) > 1 and partes[1].isdigit():
                        return int(partes[1])
                return None
            
            # Verificar quais per√≠odos n√£o t√™m ano
            df_filtrado_media['Ano_Do_Periodo'] = df_filtrado_media['Per√≠odo'].apply(extrair_ano_do_periodo)
            mask_sem_ano_periodo = df_filtrado_media['Ano_Do_Periodo'].isna()
            
            # üîß CORRE√á√ÉO: Usar coluna Ano ORIGINAL dos dados para normalizar Per√≠odo
            if 'Ano' in df_filtrado_media.columns:
                # Converter Ano para int (remover .0 se for float)
                df_filtrado_media['Ano'] = pd.to_numeric(df_filtrado_media['Ano'], errors='coerce')
                
                # Se Per√≠odo n√£o tem ano, adicionar ano da coluna Ano ORIGINAL
                mask_ano_valido = df_filtrado_media.loc[mask_sem_ano_periodo, 'Ano'].notna()
                # üîß CORRE√á√ÉO: Converter Per√≠odo para string antes de concatenar (pode ser Categorical)
                df_filtrado_media.loc[mask_sem_ano_periodo & mask_ano_valido, 'Per√≠odo'] = (
                    df_filtrado_media.loc[mask_sem_ano_periodo & mask_ano_valido, 'Per√≠odo'].astype(str) + ' ' +
                    df_filtrado_media.loc[mask_sem_ano_periodo & mask_ano_valido, 'Ano'].astype(int).astype(str)
                )
                # Re-extrair ano ap√≥s adicionar
                df_filtrado_media.loc[mask_sem_ano_periodo & mask_ano_valido, 'Ano_Do_Periodo'] = (
                    df_filtrado_media.loc[mask_sem_ano_periodo & mask_ano_valido, 'Per√≠odo'].apply(extrair_ano_do_periodo)
                )
                
                # Se Per√≠odo j√° tem ano, sincronizar coluna Ano com o ano do Per√≠odo
                # Mas manter a coluna Ano original se n√£o houver conflito
                mask_ano_periodo_valido = df_filtrado_media['Ano_Do_Periodo'].notna()
                # Sincronizar: usar ano do Per√≠odo na coluna Ano (j√° est√° normalizado)
                df_filtrado_media.loc[mask_ano_periodo_valido, 'Ano'] = df_filtrado_media.loc[mask_ano_periodo_valido, 'Ano_Do_Periodo']
            
            df_filtrado_media = df_filtrado_media.drop(columns=['Ano_Do_Periodo'], errors='ignore')
        
        # üîß CORRE√á√ÉO CR√çTICA: Filtrar por ano ANTES do groupby para evitar incluir dados de ambos os anos
        # Isso garante que apenas per√≠odos do ano de refer√™ncia sejam agrupados
        if ano_referencia:
            if 'Ano' in df_filtrado_media.columns:
                # Filtrar diretamente pela coluna Ano ANTES do groupby
                df_filtrado_media = df_filtrado_media[df_filtrado_media['Ano'] == ano_referencia].copy()
            elif 'Per√≠odo' in df_filtrado_media.columns:
                # Filtrar pelo ano no Per√≠odo se n√£o houver coluna Ano
                def periodo_tem_ano_correto_pre_groupby(periodo_val):
                    periodo_str = str(periodo_val).strip()
                    if ' ' in periodo_str:
                        ano_val = periodo_str.split(' ', 1)[1]
                        if ano_val.isdigit():
                            return int(ano_val) == ano_referencia
                    return False
                df_filtrado_media = df_filtrado_media[
                    df_filtrado_media['Per√≠odo'].apply(periodo_tem_ano_correto_pre_groupby)
                ].copy()
        
        # Agrupar por Oficina, Ve√≠culo, Per√≠odo (com ano) e Tipo_Custo para obter totais
        # üîß CORRE√á√ÉO: Se houver coluna Ano, inclu√≠-la no groupby (mesma l√≥gica da TC_Ext)
        # Isso garante que "Julho 2024" e "Julho 2025" sejam tratados separadamente
        # MAS agora df_filtrado_media j√° cont√©m APENAS o ano de refer√™ncia
        colunas_groupby = ['Oficina', 'Ve√≠culo', 'Per√≠odo', 'Tipo_Custo'] + colunas_adicionais_cache
        # Se houver coluna Ano, inclu√≠-la no groupby para evitar somar meses de anos diferentes
        if 'Ano' in df_filtrado_media.columns:
            colunas_groupby = ['Ano'] + colunas_groupby
        colunas_groupby = [col for col in colunas_groupby if col in df_filtrado_media.columns]
        agg_dict = {'Total': 'sum'}  # Usar 'sum' para ter valores totais reais
        df_medias = df_filtrado_media.groupby(colunas_groupby).agg(agg_dict).reset_index()
        
        # üîß CORRE√á√ÉO: df_medias j√° cont√©m apenas o ano de refer√™ncia (foi filtrado antes do groupby)
        # Mas vamos garantir novamente para seguran√ßa
        df_medias_ano_recente = df_medias.copy()
        if ano_referencia:
            if 'Ano' in df_medias_ano_recente.columns:
                # Filtrar diretamente pela coluna Ano (mais eficiente e correto)
                df_medias_ano_recente = df_medias_ano_recente[df_medias_ano_recente['Ano'] == ano_referencia].copy()
            elif 'Per√≠odo' in df_medias.columns:
                # Fallback: filtrar pelo ano no Per√≠odo
                def periodo_tem_ano_correto(periodo_val):
                    periodo_str = str(periodo_val).strip()
                    if ' ' in periodo_str:
                        ano_val = periodo_str.split(' ', 1)[1]
                        if ano_val.isdigit():
                            return int(ano_val) == ano_referencia
                    # Se n√£o tem ano ap√≥s normaliza√ß√£o, excluir
                    return False
                df_medias_ano_recente = df_medias[
                    df_medias['Per√≠odo'].apply(periodo_tem_ano_correto)
                ].copy()
            else:
                # Se n√£o temos coluna Ano nem Per√≠odo, usar todos (compatibilidade)
                df_medias_ano_recente = df_medias.copy()
        else:
            # Se n√£o temos ano de refer√™ncia, usar todos (compatibilidade)
            df_medias_ano_recente = df_medias.copy()
        
        # Calcular m√©dia geral mensal por linha (m√©dia das m√©dias dos meses selecionados)
        # üîß CORRE√á√ÉO CR√çTICA: Garantir que df_medias_ano_recente cont√©m APENAS o ano de refer√™ncia
        # Se ainda houver dados de outros anos ap√≥s o filtro, filtrar novamente
        if ano_referencia and 'Ano' in df_medias_ano_recente.columns:
            anos_ainda_presentes = df_medias_ano_recente['Ano'].dropna().unique()
            if len(anos_ainda_presentes) > 1 or (len(anos_ainda_presentes) == 1 and anos_ainda_presentes[0] != ano_referencia):
                # For√ßar filtro novamente
                df_medias_ano_recente = df_medias_ano_recente[df_medias_ano_recente['Ano'] == ano_referencia].copy()
        elif ano_referencia and 'Per√≠odo' in df_medias_ano_recente.columns:
            # Filtrar pelo ano no Per√≠odo se n√£o houver coluna Ano
            def periodo_tem_ano_correto_final(periodo_val):
                periodo_str = str(periodo_val).strip()
                if ' ' in periodo_str:
                    ano_val = periodo_str.split(' ', 1)[1]
                    if ano_val.isdigit():
                        return int(ano_val) == ano_referencia
                return False
            df_medias_ano_recente = df_medias_ano_recente[
                df_medias_ano_recente['Per√≠odo'].apply(periodo_tem_ano_correto_final)
            ].copy()
        
        # Calcular m√©dia geral mensal por linha (m√©dia das m√©dias dos meses selecionados)
        # üîß CORRE√á√ÉO: Incluir 'Ano' no groupby se existir (preservar ano para forecast)
        # IMPORTANTE: df_medias_ano_recente j√° deve conter APENAS o ano de refer√™ncia
        colunas_groupby_media = ['Oficina', 'Ve√≠culo', 'Tipo_Custo'] + colunas_adicionais_cache
        if 'Ano' in df_medias_ano_recente.columns:
            colunas_groupby_media.insert(2, 'Ano')  # Inserir Ano ap√≥s Ve√≠culo
        colunas_groupby_media = [col for col in colunas_groupby_media if col in df_medias_ano_recente.columns]
        agg_dict_media = {'Total': 'mean'}
        df_media_mensal = df_medias_ano_recente.groupby(colunas_groupby_media).agg(agg_dict_media).reset_index()
        
        # üîß VERIFICA√á√ÉO FINAL: Garantir que n√£o h√° duplicatas ap√≥s o agrupamento
        # Se ainda houver duplicatas, significa que o agrupamento n√£o est√° funcionando corretamente
        if len(colunas_groupby_media) > 0:
            duplicatas_final = df_media_mensal.duplicated(subset=colunas_groupby_media, keep=False)
            if duplicatas_final.any():
                # Se ainda houver duplicatas, for√ßar agrupamento novamente
                df_media_mensal = df_media_mensal.groupby(
                    colunas_groupby_media, as_index=False
                ).agg(agg_dict_media)
        
        return df_medias, df_media_mensal

    # Calcular m√©dias mensais hist√≥ricas por Oficina, Ve√≠culo e Per√≠odo
    st.markdown("### üìä C√°lculo de M√©dias Mensais Hist√≥ricas")
    
    st.markdown("---")

    # Verificar se as colunas Type 05, Type 06 e Account existem
    colunas_adicionais = []
    if 'Type 05' in df_filtrado.columns:
        colunas_adicionais.append('Type 05')
    if 'Type 06' in df_filtrado.columns:
        colunas_adicionais.append('Type 06')
    if 'Account' in df_filtrado.columns:
        colunas_adicionais.append('Account')

    # Calcular m√©dias com cache (usando apenas os per√≠odos selecionados)
    df_medias, df_media_mensal = calcular_medias_forecast(df_filtrado, colunas_adicionais, periodos_para_media, ultimo_periodo_dados)
    
    # ====================================================================
    # üîß FUN√á√ÉO CENTRALIZADA: Calcular m√©dia hist√≥rica de forma padronizada
    # (Definida aqui para poder ser usada imediatamente)
    # ====================================================================
    def calcular_media_historica_padronizada(df_medias_fonte, periodos_para_media_fonte, filtro_oficina=None, df_forecast_fonte=None, meses_excluir_media_fonte=None):
        """
        Calcula m√©dia hist√≥rica de forma padronizada usando a mesma l√≥gica do gr√°fico.
        Retorna: float com a m√©dia hist√≥rica ou None se n√£o conseguir calcular
        """
        try:
            # OP√á√ÉO 2: Calcular agregando por per√≠odo e tirando m√©dia (mesma l√≥gica do gr√°fico)
            if df_medias_fonte is None or df_medias_fonte.empty:
                return None
            
            if 'Per√≠odo' not in df_medias_fonte.columns or 'Total' not in df_medias_fonte.columns:
                return None
            
            df_temp = df_medias_fonte.copy()
            
            # Filtrar por oficina se especificado
            if filtro_oficina and 'Oficina' in df_temp.columns:
                df_temp = df_temp[df_temp['Oficina'] == filtro_oficina].copy()
                # üîß CORRE√á√ÉO: Se ap√≥s filtrar por oficina n√£o h√° dados, retornar 0 imediatamente
                if df_temp.empty:
                    return 0.0
            
            # Normalizar Per√≠odo para incluir ano ANTES do groupby
            ano_referencia = None
            if periodos_para_media_fonte:
                for p in periodos_para_media_fonte:
                    p_str = str(p).strip()
                    if ' ' in p_str:
                        ano_str = p_str.split(' ', 1)[1]
                        if ano_str.isdigit():
                            ano_referencia = int(ano_str)
                            break
            
            if ano_referencia and 'Per√≠odo' in df_temp.columns:
                def normalizar_periodo_com_ano(periodo_val):
                    periodo_str = str(periodo_val).strip()
                    if ' ' in periodo_str:
                        partes = periodo_str.split(' ', 1)
                        if len(partes) > 1 and partes[1].isdigit():
                            return periodo_str
                    return f"{periodo_str} {ano_referencia}"
                
                df_temp['Per√≠odo'] = df_temp['Per√≠odo'].astype(str)
                df_temp['Per√≠odo'] = df_temp['Per√≠odo'].apply(normalizar_periodo_com_ano)
            
            # Filtrar per√≠odos selecionados e excluir meses marcados
            if periodos_para_media_fonte:
                periodos_normalizados = [str(p).strip().lower() for p in periodos_para_media_fonte]
                meses_excluir_media_normalizados = []
                if meses_excluir_media_fonte:
                    for mes_excluir in meses_excluir_media_fonte:
                        mes_str = str(mes_excluir).strip().lower()
                        meses_excluir_media_normalizados.append(mes_str)
                
                def periodo_esta_selecionado(p):
                    p_str = str(p).strip().lower()
                    
                    if meses_excluir_media_normalizados:
                        periodo_mes = None
                        if ' ' in p_str:
                            periodo_mes = p_str.split(' ', 1)[0]
                        else:
                            periodo_mes = p_str
                        if periodo_mes in meses_excluir_media_normalizados:
                            return False
                    
                    if p_str in periodos_normalizados:
                        return True
                    if ' ' in p_str:
                        p_parts = p_str.split(' ', 1)
                        p_mes = p_parts[0]
                        p_ano = p_parts[1] if len(p_parts) > 1 else None
                        for periodo_ref in periodos_normalizados:
                            if ' ' in periodo_ref:
                                ref_parts = periodo_ref.split(' ', 1)
                                ref_mes = ref_parts[0]
                                ref_ano = ref_parts[1] if len(ref_parts) > 1 else None
                                if p_mes == ref_mes and p_ano and ref_ano and p_ano == ref_ano:
                                    return True
                    return False
                
                mask = df_temp['Per√≠odo'].apply(periodo_esta_selecionado)
                df_temp = df_temp[mask].copy()
            
            if ano_referencia and 'Per√≠odo' in df_temp.columns:
                def periodo_tem_ano_correto(periodo_val):
                    periodo_str = str(periodo_val).strip()
                    if ' ' in periodo_str:
                        ano_val = periodo_str.split(' ', 1)[1]
                        if ano_val.isdigit():
                            return int(ano_val) == ano_referencia
                    return False
                df_temp = df_temp[df_temp['Per√≠odo'].apply(periodo_tem_ano_correto)].copy()
            
            if df_temp.empty:
                # üîß CORRE√á√ÉO: Se n√£o h√° dados ap√≥s filtros, retornar 0 (n√£o None)
                return 0.0
            
            if 'Ano' in df_temp.columns:
                df_agregado = df_temp.groupby(['Ano', 'Per√≠odo'], as_index=False)['Total'].sum()
            else:
                df_agregado = df_temp.groupby('Per√≠odo', as_index=False)['Total'].sum()
            
            if len(df_agregado) > 0:
                # Verificar se h√° pelo menos um valor n√£o-zero
                total_soma = df_agregado['Total'].sum()
                if total_soma == 0 or pd.isna(total_soma):
                    # Se a soma √© zero, retornar 0 (n√£o None) para indicar que n√£o h√° valores
                    return 0.0
                media = float(df_agregado['Total'].mean())
            else:
                # Se n√£o h√° dados agregados, retornar 0 (n√£o None)
                return 0.0
            
            return media
        except Exception:
            return None
    
    # ====================================================================
    # üîß FUN√á√ÉO CENTRALIZADA: Calcular m√©dia hist√≥rica de VOLUME de forma padronizada
    # (Similar √† fun√ß√£o de custo, mas para volume)
    # ====================================================================
    def calcular_media_historica_volume_padronizada(df_vol_fonte, periodos_para_media_fonte, meses_excluir_media_fonte=None):
        """
        Calcula m√©dia hist√≥rica de volume de forma padronizada usando a MESMA L√ìGICA da fun√ß√£o de custo.
        Retorna: float com a m√©dia hist√≥rica de volume ou None se n√£o conseguir calcular
        
        L√ìGICA ID√äNTICA √Ä FUN√á√ÉO DE CUSTO (que est√° funcionando):
        1. Normalizar Per√≠odo para incluir ano ANTES do groupby
        2. Filtrar per√≠odos selecionados e excluir meses marcados
        3. Filtrar APENAS per√≠odos do ano de refer√™ncia
        4. Agregar volumes por per√≠odo √∫nico (m√™s + ano)
        5. Calcular m√©dia dos volumes agregados
        """
        try:
            # OP√á√ÉO 2: Calcular agregando por per√≠odo e tirando m√©dia (mesma l√≥gica do gr√°fico e da fun√ß√£o de custo)
            if df_vol_fonte is None or df_vol_fonte.empty:
                return None
            
            if 'Per√≠odo' not in df_vol_fonte.columns or 'Volume' not in df_vol_fonte.columns:
                return None
            
            df_temp = df_vol_fonte.copy()
            
            # Normalizar Per√≠odo para incluir ano ANTES do groupby (MESMA L√ìGICA DA FUN√á√ÉO DE CUSTO)
            # üîß CORRE√á√ÉO: Pegar o ANO MAIS RECENTE, n√£o o primeiro encontrado
            ano_referencia = None
            anos_encontrados = []
            if periodos_para_media_fonte:
                for p in periodos_para_media_fonte:
                    p_str = str(p).strip()
                    if ' ' in p_str:
                        ano_str = p_str.split(' ', 1)[1]
                        if ano_str.isdigit():
                            anos_encontrados.append(int(ano_str))
            
            # Usar o ano mais recente (maior valor)
            if anos_encontrados:
                ano_referencia = max(anos_encontrados)
            
            if ano_referencia and 'Per√≠odo' in df_temp.columns:
                def normalizar_periodo_com_ano_vol(periodo_val):
                    periodo_str = str(periodo_val).strip()
                    if ' ' in periodo_str:
                        partes = periodo_str.split(' ', 1)
                        if len(partes) > 1 and partes[1].isdigit():
                            return periodo_str
                    return f"{periodo_str} {ano_referencia}"
                
                df_temp['Per√≠odo'] = df_temp['Per√≠odo'].astype(str)
                df_temp['Per√≠odo'] = df_temp['Per√≠odo'].apply(normalizar_periodo_com_ano_vol)
            
            # Filtrar per√≠odos selecionados e excluir meses marcados (MESMA L√ìGICA DA FUN√á√ÉO DE CUSTO)
            if periodos_para_media_fonte:
                periodos_normalizados = [str(p).strip().lower() for p in periodos_para_media_fonte]
                meses_excluir_media_normalizados = []
                if meses_excluir_media_fonte:
                    for mes_excluir in meses_excluir_media_fonte:
                        mes_str = str(mes_excluir).strip().lower()
                        meses_excluir_media_normalizados.append(mes_str)
                
                def periodo_esta_selecionado_vol(p):
                    p_str = str(p).strip().lower()
                    
                    if meses_excluir_media_normalizados:
                        periodo_mes = None
                        if ' ' in p_str:
                            periodo_mes = p_str.split(' ', 1)[0]
                        else:
                            periodo_mes = p_str
                        if periodo_mes in meses_excluir_media_normalizados:
                            return False
                    
                    if p_str in periodos_normalizados:
                        return True
                    if ' ' in p_str:
                        p_parts = p_str.split(' ', 1)
                        p_mes = p_parts[0]
                        p_ano = p_parts[1] if len(p_parts) > 1 else None
                        for periodo_ref in periodos_normalizados:
                            if ' ' in periodo_ref:
                                ref_parts = periodo_ref.split(' ', 1)
                                ref_mes = ref_parts[0]
                                ref_ano = ref_parts[1] if len(ref_parts) > 1 else None
                                if p_mes == ref_mes and p_ano and ref_ano and p_ano == ref_ano:
                                    return True
                    return False
                
                mask = df_temp['Per√≠odo'].apply(periodo_esta_selecionado_vol)
                df_temp = df_temp[mask].copy()
            
            # Filtrar APENAS per√≠odos do ano de refer√™ncia (MESMA L√ìGICA DA FUN√á√ÉO DE CUSTO)
            # üîß CORRE√á√ÉO: Filtrar sempre, mesmo quando n√£o h√° coluna 'Ano' (se o Per√≠odo incluir o ano)
            tem_coluna_ano = 'Ano' in df_temp.columns
            if ano_referencia and 'Per√≠odo' in df_temp.columns:
                def periodo_tem_ano_correto_vol(periodo_val):
                    periodo_str = str(periodo_val).strip()
                    if ' ' in periodo_str:
                        ano_val = periodo_str.split(' ', 1)[1]
                        if ano_val.isdigit():
                            return int(ano_val) == ano_referencia
                    # Se o per√≠odo n√£o tem ano, manter apenas se n√£o houver coluna 'Ano' (caso contr√°rio ser√° filtrado pela coluna Ano)
                    return not tem_coluna_ano
                df_temp = df_temp[df_temp['Per√≠odo'].apply(periodo_tem_ano_correto_vol)].copy()
            
            # üîß CORRE√á√ÉO ADICIONAL: Se h√° coluna 'Ano', tamb√©m filtrar por ano mais recente
            if 'Ano' in df_temp.columns and not df_temp.empty:
                # Filtrar apenas o ano mais recente (mesma l√≥gica do gr√°fico de custos)
                anos_unicos = df_temp['Ano'].dropna().unique()
                if len(anos_unicos) > 1:
                    ano_mais_recente = df_temp['Ano'].max()
                    df_temp = df_temp[df_temp['Ano'] == ano_mais_recente].copy()
            
            if df_temp.empty:
                return None
            
            # Agregar volumes por per√≠odo (MESMA L√ìGICA DA FUN√á√ÉO DE CUSTO)
            # üîß CORRE√á√ÉO: Normalizar Per√≠odo ANTES de agrupar para garantir consist√™ncia
            if 'Ano' in df_temp.columns:
                # Normalizar Per√≠odo antes de agrupar (garante que per√≠odos com mesmo m√™s+ano sejam agrupados juntos)
                def normalizar_periodo_vol_func(periodo_str, ano_val):
                    periodo_str = str(periodo_str).strip()
                    ano_str = str(ano_val).strip()
                    # Se o per√≠odo j√° cont√©m o ano, retornar como est√°
                    if ano_str in periodo_str:
                        return periodo_str
                    # Caso contr√°rio, adicionar o ano
                    return periodo_str + ' ' + ano_str
                
                # Normalizar Per√≠odo antes de agrupar
                df_temp['Per√≠odo_Normalizado'] = df_temp.apply(
                    lambda row: normalizar_periodo_vol_func(row['Per√≠odo'], row['Ano']), axis=1
                )
                
                # Agrupar por Ano e Per√≠odo_Normalizado
                df_agregado = df_temp.groupby(['Ano', 'Per√≠odo_Normalizado'], as_index=False)['Volume'].sum()
                # Renomear Per√≠odo_Normalizado de volta para Per√≠odo
                df_agregado = df_agregado.rename(columns={'Per√≠odo_Normalizado': 'Per√≠odo'})
                # Remover coluna Ano (j√° est√° inclu√≠da no Per√≠odo)
                df_agregado = df_agregado.drop(columns=['Ano'])
            else:
                df_agregado = df_temp.groupby('Per√≠odo', as_index=False)['Volume'].sum()
            
            if len(df_agregado) > 0:
                # Calcular m√©dia dos volumes totais por per√≠odo (MESMA L√ìGICA DA FUN√á√ÉO DE CUSTO)
                media_volume = float(df_agregado['Volume'].mean())
            else:
                media_volume = None
            
            return media_volume
        except Exception:
            return None
    
    # üîß CORRE√á√ÉO CR√çTICA: Calcular m√©dia hist√≥rica total padronizada e ajustar m√©dias por linha
    # Isso garante que a soma das m√©dias por linha seja igual √† m√©dia hist√≥rica total do gr√°fico
    # E que todos os c√°lculos (forecast, gr√°ficos, tabelas) usem a mesma m√©dia padronizada
    media_historica_total_padronizada = calcular_media_historica_padronizada(
        df_medias, periodos_para_media, filtro_oficina=None, 
        df_forecast_fonte=None, meses_excluir_media_fonte=meses_excluir_media
    )
    
    # Se conseguimos calcular a m√©dia padronizada, ajustar as m√©dias por linha
    if media_historica_total_padronizada is not None and media_historica_total_padronizada > 0:
        # Calcular soma atual das m√©dias por linha
        soma_medias_linhas = float(df_media_mensal['Total'].sum())
        
        # Se a soma for diferente da m√©dia padronizada, ajustar proporcionalmente
        if abs(soma_medias_linhas - media_historica_total_padronizada) > 0.01:
            # Calcular fator de ajuste
            if soma_medias_linhas > 0:
                fator_ajuste = media_historica_total_padronizada / soma_medias_linhas
                # Aplicar ajuste proporcional em todas as linhas
                df_media_mensal['Total'] = df_media_mensal['Total'] * fator_ajuste
                
                # üîß VERIFICA√á√ÉO: Confirmar que o ajuste funcionou
                soma_medias_linhas_apos_ajuste = float(df_media_mensal['Total'].sum())
                if abs(soma_medias_linhas_apos_ajuste - media_historica_total_padronizada) > 0.01:
                    # Se ainda houver diferen√ßa, for√ßar ajuste direto
                    diferenca = media_historica_total_padronizada - soma_medias_linhas_apos_ajuste
                    # Distribuir a diferen√ßa proporcionalmente
                    if len(df_media_mensal) > 0:
                        ajuste_adicional = diferenca / len(df_media_mensal)
                        df_media_mensal['Total'] = df_media_mensal['Total'] + ajuste_adicional
    
    # Verificar se encontrou menos per√≠odos do que o solicitado
    if not df_medias.empty and 'Per√≠odo' in df_medias.columns:
        periodos_encontrados = df_medias['Per√≠odo'].unique()
        if len(periodos_encontrados) < len(periodos_para_media):
            st.info(f"‚ÑπÔ∏è **Informa√ß√£o:** Foram encontrados {len(periodos_encontrados)} per√≠odo(s) nos dados (solicitados: {len(periodos_para_media)}). O c√°lculo ser√° feito com os per√≠odos dispon√≠veis.")
    
    # Fun√ß√£o para calcular volumes e CPU com cache
    @st.cache_data(ttl=3600, max_entries=10, show_spinner=False)
    def calcular_volumes_cpu(df_vol_cache, df_medias_cache, colunas_adicionais_cache, periodos_para_media_cache, ultimo_periodo_dados_cache=None, meses_excluir_media_cache=None):
        """
        Calcula volumes e CPU hist√≥rico com cache, usando apenas os per√≠odos selecionados
        e EXCLUINDO os meses marcados para exclus√£o (meses_excluir_media_cache)
        """
        if df_vol_cache.empty or 'Per√≠odo' not in df_vol_cache.columns or 'Volume' not in df_vol_cache.columns:
            return None, None, None, None
        
        # Filtrar apenas os per√≠odos que ser√£o usados para calcular a m√©dia de volume
        if periodos_para_media_cache and 'Per√≠odo' in df_vol_cache.columns:
            # Normalizar per√≠odos procurados (manter m√™s + ano se dispon√≠vel)
            periodos_procurados_normalizados = []
            for periodo_procurado in periodos_para_media_cache:
                periodo_str = str(periodo_procurado).strip()
                # Normalizar para min√∫sculas para compara√ß√£o
                periodos_procurados_normalizados.append(periodo_str.lower())
            
            # Extrair √∫ltimo m√™s e ano para valida√ß√£o
            ultimo_mes_limite = None
            ultimo_ano_limite = None
            if ultimo_periodo_dados_cache:
                ultimo_periodo_str = str(ultimo_periodo_dados_cache).strip().lower()
                if ' ' in ultimo_periodo_str:
                    ultimo_mes_limite = ultimo_periodo_str.split(' ', 1)[0]
                    ultimo_ano_limite = int(ultimo_periodo_str.split(' ', 1)[1]) if ultimo_periodo_str.split(' ', 1)[1].isdigit() else None
                else:
                    ultimo_mes_limite = ultimo_periodo_str
                    ultimo_ano_limite = None
            
            # Verificar per√≠odos no DataFrame
            periodos_no_df = df_vol_cache['Per√≠odo'].astype(str).str.strip().str.lower()
            
            # Criar m√°scara: comparar per√≠odo completo (m√™s + ano) quando dispon√≠vel
            def periodo_corresponde(periodo_df):
                periodo_df_lower = str(periodo_df).strip().lower()
                
                # Verificar se o per√≠odo est√° antes ou no √∫ltimo m√™s selecionado
                if ultimo_mes_limite and ultimo_ano_limite:
                    periodo_df_tem_ano = ' ' in periodo_df_lower and len(periodo_df_lower.split(' ', 1)) > 1
                    if periodo_df_tem_ano:
                        periodo_df_ano = int(periodo_df_lower.split(' ', 1)[1]) if periodo_df_lower.split(' ', 1)[1].isdigit() else None
                        periodo_df_mes = periodo_df_lower.split(' ', 1)[0]
                        
                        # Verificar se est√° antes do √∫ltimo m√™s
                        if periodo_df_ano and periodo_df_ano > ultimo_ano_limite:
                            return False
                        if periodo_df_ano == ultimo_ano_limite:
                            # Comparar meses usando √≠ndice
                            meses_ano_lower = [m.lower() for m in meses_ano]
                            if periodo_df_mes in meses_ano_lower and ultimo_mes_limite in meses_ano_lower:
                                idx_periodo = meses_ano_lower.index(periodo_df_mes)
                                idx_limite = meses_ano_lower.index(ultimo_mes_limite)
                                if idx_periodo > idx_limite:
                                    return False
                    else:
                        # Se o per√≠odo do DataFrame n√£o tem ano, verificar apenas pelo m√™s
                        periodo_df_mes = periodo_df_lower
                        meses_ano_lower = [m.lower() for m in meses_ano]
                        if periodo_df_mes in meses_ano_lower and ultimo_mes_limite in meses_ano_lower:
                            idx_periodo = meses_ano_lower.index(periodo_df_mes)
                            idx_limite = meses_ano_lower.index(ultimo_mes_limite)
                            if idx_periodo > idx_limite:
                                return False
                
                # Compara√ß√£o exata primeiro (per√≠odo completo)
                if periodo_df_lower in periodos_procurados_normalizados:
                    return True
                
                # Se n√£o houver correspond√™ncia exata, verificar se ambos t√™m ano
                periodo_df_tem_ano = ' ' in periodo_df_lower and len(periodo_df_lower.split(' ', 1)) > 1
                
                for periodo_procurado in periodos_procurados_normalizados:
                    periodo_procurado_tem_ano = ' ' in periodo_procurado and len(periodo_procurado.split(' ', 1)) > 1
                    
                    # Se ambos t√™m ano, comparar per√≠odo completo (j√° verificamos exato acima)
                    if periodo_df_tem_ano and periodo_procurado_tem_ano:
                        # Se ambos t√™m ano mas n√£o s√£o iguais, n√£o corresponde
                        continue
                    
                    # Se nenhum tem ano ou apenas um tem, comparar apenas o m√™s
                    # (compatibilidade com dados antigos)
                    mes_df = periodo_df_lower.split(' ', 1)[0] if ' ' in periodo_df_lower else periodo_df_lower
                    mes_procurado = periodo_procurado.split(' ', 1)[0] if ' ' in periodo_procurado else periodo_procurado
                    
                    if mes_df == mes_procurado:
                        # Se o per√≠odo procurado tem ano mas o do DF n√£o tem, n√£o incluir
                        # (para evitar incluir per√≠odos futuros sem ano)
                        if periodo_procurado_tem_ano and not periodo_df_tem_ano:
                            continue
                        return True
                
                return False
            
            df_vol_para_media = df_vol_cache[
                periodos_no_df.apply(periodo_corresponde)
            ].copy()
            
            # üîß CORRE√á√ÉO: Excluir meses marcados para exclus√£o do c√°lculo do volume
            # Isso garante que o volume m√©dio hist√≥rico tamb√©m exclua os mesmos meses que foram exclu√≠dos da m√©dia de custo
            if meses_excluir_media_cache and not df_vol_para_media.empty:
                meses_excluir_normalizados = [str(mes).strip().lower() for mes in meses_excluir_media_cache]
                
                def periodo_nao_esta_excluido(periodo_val):
                    periodo_str = str(periodo_val).strip().lower()
                    # Extrair m√™s do per√≠odo
                    periodo_mes = None
                    if ' ' in periodo_str:
                        periodo_mes = periodo_str.split(' ', 1)[0]
                    else:
                        periodo_mes = periodo_str
                    # Se o m√™s est√° na lista de exclu√≠dos, retornar False (n√£o incluir)
                    return periodo_mes not in meses_excluir_normalizados
                
                df_vol_para_media = df_vol_para_media[
                    df_vol_para_media['Per√≠odo'].apply(periodo_nao_esta_excluido)
            ].copy()

            # Se, por algum motivo, o filtro n√£o encontrar nada, voltar a usar todos os dados
            # para n√£o ficar com volume hist√≥rico zero (mant√©m a regra de neg√≥cio funcionando)
            if df_vol_para_media.empty:
                df_vol_para_media = df_vol_cache.copy()
        else:
            # Se n√£o houver per√≠odos selecionados, usar todos os dados (comportamento original)
            # Mas ainda excluir meses marcados para exclus√£o
            df_vol_para_media = df_vol_cache.copy()
            
            # üîß CORRE√á√ÉO: Excluir meses marcados para exclus√£o mesmo quando n√£o h√° per√≠odos selecionados
            if meses_excluir_media_cache and not df_vol_para_media.empty:
                meses_excluir_normalizados = [str(mes).strip().lower() for mes in meses_excluir_media_cache]
                
                def periodo_nao_esta_excluido(periodo_val):
                    periodo_str = str(periodo_val).strip().lower()
                    periodo_mes = periodo_str.split(' ', 1)[0] if ' ' in periodo_str else periodo_str
                    return periodo_mes not in meses_excluir_normalizados
                
                df_vol_para_media = df_vol_para_media[
                    df_vol_para_media['Per√≠odo'].apply(periodo_nao_esta_excluido)
                ].copy()
        
        # Calcular m√©dia de volume por per√≠odo hist√≥rico (apenas meses selecionados)
        if not df_vol_para_media.empty:
            # üîß CORRE√á√ÉO CR√çTICA: Filtrar apenas volumes do ano mais recente (evita somar 2024 e 2025)
            if 'Ano' in df_vol_para_media.columns:
                anos_unicos = df_vol_para_media['Ano'].dropna().unique()
                if len(anos_unicos) > 1:
                    # Pegar o ano mais recente
                    ano_mais_recente = df_vol_para_media['Ano'].max()
                    df_vol_para_media = df_vol_para_media[df_vol_para_media['Ano'] == ano_mais_recente].copy()
            
            # üîß CORRE√á√ÉO: Normalizar Per√≠odo usando coluna Ano ORIGINAL dos dados (IGUAL TC EXT)
            # Estrat√©gia: Se Per√≠odo n√£o tem ano, usar coluna Ano original para adicionar ao Per√≠odo
            if 'Per√≠odo' in df_vol_para_media.columns:
                df_vol_para_media = df_vol_para_media.copy()
                # üîß CORRE√á√ÉO: Converter Per√≠odo para string ANTES de qualquer opera√ß√£o (pode ser Categorical)
                df_vol_para_media['Per√≠odo'] = df_vol_para_media['Per√≠odo'].astype(str).str.lower().str.strip()
                
                def extrair_ano_do_periodo(periodo_str):
                    periodo_str = str(periodo_str).strip()
                    if ' ' in periodo_str:
                        partes = periodo_str.split(' ', 1)
                        if len(partes) > 1 and partes[1].isdigit():
                            return int(partes[1])
                    return None
                
                df_vol_para_media['Ano_Do_Periodo'] = df_vol_para_media['Per√≠odo'].apply(extrair_ano_do_periodo)
                mask_sem_ano_periodo = df_vol_para_media['Ano_Do_Periodo'].isna()
                
                # Se Per√≠odo n√£o tem ano, adicionar ano da coluna Ano ORIGINAL
                if 'Ano' in df_vol_para_media.columns:
                    df_vol_para_media['Ano'] = pd.to_numeric(df_vol_para_media['Ano'], errors='coerce')
                    mask_ano_valido = df_vol_para_media.loc[mask_sem_ano_periodo, 'Ano'].notna()
                    # üîß CORRE√á√ÉO: Converter Per√≠odo para string antes de concatenar (pode ser Categorical)
                    df_vol_para_media.loc[mask_sem_ano_periodo & mask_ano_valido, 'Per√≠odo'] = (
                        df_vol_para_media.loc[mask_sem_ano_periodo & mask_ano_valido, 'Per√≠odo'].astype(str) + ' ' +
                        df_vol_para_media.loc[mask_sem_ano_periodo & mask_ano_valido, 'Ano'].astype(int).astype(str)
                    )
                    # Re-extrair ano ap√≥s adicionar
                    df_vol_para_media.loc[mask_sem_ano_periodo & mask_ano_valido, 'Ano_Do_Periodo'] = (
                        df_vol_para_media.loc[mask_sem_ano_periodo & mask_ano_valido, 'Per√≠odo'].apply(extrair_ano_do_periodo)
                    )
                    # Sincronizar: se Per√≠odo tem ano, usar na coluna Ano
                    mask_ano_periodo_valido = df_vol_para_media['Ano_Do_Periodo'].notna()
                    df_vol_para_media.loc[mask_ano_periodo_valido, 'Ano'] = df_vol_para_media.loc[mask_ano_periodo_valido, 'Ano_Do_Periodo']
                
                df_vol_para_media = df_vol_para_media.drop(columns=['Ano_Do_Periodo'], errors='ignore')
            
            # Agrupar incluindo Ano (IGUAL TC EXT)
            colunas_groupby_vol_medio = ['Oficina', 'Ve√≠culo', 'Per√≠odo']
            if 'Ano' in df_vol_para_media.columns:
                colunas_groupby_vol_medio.append('Ano')
            df_vol_medio = df_vol_para_media.groupby(colunas_groupby_vol_medio, as_index=False)['Volume'].mean()
            
            # Calcular volume m√©dio mensal (m√©dia dos meses selecionados do ano correto)
            df_vol_medio_mensal = df_vol_medio.groupby(['Oficina', 'Ve√≠culo'], as_index=False)['Volume'].mean()
            df_vol_medio_mensal = df_vol_medio_mensal.rename(columns={'Volume': 'Volume_Medio_Historico'})
        else:
            # Se n√£o houver dados, criar DataFrames vazios
            df_vol_medio = pd.DataFrame(columns=['Oficina', 'Ve√≠culo', 'Per√≠odo', 'Volume'])
            df_vol_medio_mensal = pd.DataFrame(columns=['Oficina', 'Ve√≠culo', 'Volume_Medio_Historico'])
        
        # Volume por m√™s (incluindo meses futuros)
        # üîß CORRE√á√ÉO CR√çTICA: Filtrar apenas volumes do ano mais recente (ou do ano do per√≠odo de forecast)
        # Isso evita somar volumes de 2024 e 2025 quando busca um m√™s espec√≠fico
        df_vol_para_por_mes = df_vol_cache.copy()
        
        # Se h√° coluna 'Ano', filtrar apenas o ano mais recente (ou anos de forecast se dispon√≠vel)
        if 'Ano' in df_vol_para_por_mes.columns:
            anos_unicos = df_vol_para_por_mes['Ano'].dropna().unique()
            if len(anos_unicos) > 1:
                # Pegar o ano mais recente
                ano_mais_recente = df_vol_para_por_mes['Ano'].max()
                # Mas tamb√©m incluir anos futuros (se houver per√≠odos de forecast com anos diferentes)
                # Por enquanto, usar apenas o ano mais recente para evitar duplica√ß√£o
                df_vol_para_por_mes = df_vol_para_por_mes[df_vol_para_por_mes['Ano'] == ano_mais_recente].copy()
        
        # üîß CORRE√á√ÉO: Incluir 'Ano' no groupby (IGUAL TC EXT) para separar per√≠odos de anos diferentes
        colunas_groupby_vol_por_mes = ['Oficina', 'Ve√≠culo', 'Per√≠odo']
        if 'Ano' in df_vol_para_por_mes.columns:
            colunas_groupby_vol_por_mes.append('Ano')
        df_vol_por_mes = df_vol_para_por_mes.groupby(colunas_groupby_vol_por_mes, as_index=False)['Volume'].sum()
        
        # Calcular rela√ß√£o custo/volume hist√≥rica para custos vari√°veis
        # üîß CORRE√á√ÉO: Incluir 'Ano' no merge (IGUAL TC EXT)
        colunas_merge_custo_volume = ['Oficina', 'Ve√≠culo', 'Per√≠odo']
        if 'Ano' in df_medias_cache.columns and 'Ano' in df_vol_medio.columns:
            colunas_merge_custo_volume.append('Ano')
        df_custo_volume = pd.merge(
            df_medias_cache[df_medias_cache['Tipo_Custo'] == 'Vari√°vel'],
            df_vol_medio,
            on=colunas_merge_custo_volume,
            how='left'
        )
        
        # Calcular CPU hist√≥rico
        df_custo_volume['CPU_Historico'] = df_custo_volume.apply(
            lambda row: row['Total'] / row['Volume'] if pd.notnull(row['Volume']) and row['Volume'] > 0 else 0,
            axis=1
        )
        
        # Calcular CPU m√©dio
        colunas_groupby_cpu = ['Oficina', 'Ve√≠culo'] + colunas_adicionais_cache
        df_cpu_medio = df_custo_volume.groupby(colunas_groupby_cpu).agg({
            'CPU_Historico': 'mean',
            'Volume': 'mean'
        }).reset_index()
        df_cpu_medio = df_cpu_medio.rename(columns={'Volume': 'Volume_Medio_Ref'})
        
        return df_vol_medio_mensal, df_vol_por_mes, df_cpu_medio, df_vol_medio

    # Carregar volumes futuros (se dispon√≠vel) e calcular rela√ß√£o custo/volume
    # O df_vol j√° cont√©m os volumes futuros que ser√£o usados para o forecast
    # üîß CORRE√á√ÉO: Passar meses_excluir_media para que o volume tamb√©m exclua os meses marcados
    volume_base, volume_por_mes, df_cpu_medio, df_vol_medio = calcular_volumes_cpu(df_vol, df_medias, colunas_adicionais, periodos_para_media, ultimo_periodo_dados, meses_excluir_media)
    
    if volume_base is None:
        st.warning("‚ö†Ô∏è Dados de volume n√£o dispon√≠veis. Usando valores fixos para forecast.")
        volume_base = pd.DataFrame(columns=['Oficina', 'Ve√≠culo', 'Volume_Medio_Historico'])
        volume_por_mes = pd.DataFrame(columns=['Oficina', 'Ve√≠culo', 'Per√≠odo', 'Volume'])
        df_cpu_medio = pd.DataFrame(columns=['Oficina', 'Ve√≠culo'] + colunas_adicionais + ['CPU_Historico', 'Volume_Medio_Ref'])
    
    # Fun√ß√£o para calcular forecast completo com cache
    @st.cache_data(ttl=3600, max_entries=10, show_spinner=False)
    def calcular_forecast_completo(df_media_mensal_cache, volume_base_cache, df_cpu_medio_cache, 
                                    volume_por_mes_cache, colunas_adicionais_cache, meses_restantes_cache,
                                    sensibilidade_fixo_cache, sensibilidade_variavel_cache, sensibilidades_type06_cache,
                                    inflacao_type06_cache):
        """
        Calcula forecast completo linha a linha seguindo l√≥gica matem√°tica clara:
        
        L√ìGICA DO C√ÅLCULO (linha a linha):
        ===================================
        
        1. Para cada linha do forecast:
           - M√©dia hist√≥rica do custo (j√° considera exclus√£o de meses, √∫ltimo per√≠odo com dados reais, etc.)
           - Volume do m√™s futuro (volume realizado do per√≠odo de forecast)
           - Volume m√©dio hist√≥rico (j√° considera exclus√£o de meses, √∫ltimo per√≠odo com dados reais, etc.)
        
        2. Calcular propor√ß√£o de volume:
           proporcao_volume = Volume_do_mes / Volume_medio_historico
           
           Exemplo: Se volume m√©dio hist√≥rico = 100 e volume do m√™s = 110
           proporcao_volume = 110 / 100 = 1.1
        
        3. Calcular varia√ß√£o percentual:
           variacao_percentual = proporcao_volume - 1.0
           
           Exemplo: Se propor√ß√£o = 1.1, ent√£o varia√ß√£o = 1.1 - 1.0 = 0.1 (10% de aumento)
        
        4. Aplicar sensibilidade (linha a linha, baseado no Tipo_Custo):
           - Se Tipo_Custo == 'Fixo': sensibilidade = sensibilidade_fixo
           - Se Tipo_Custo == 'Vari√°vel': sensibilidade = sensibilidade_variavel
           - Se modo Type 06: usar sensibilidade espec√≠fica do Type 06
           
           varia√ß√£o_ajustada = variacao_percentual * sensibilidade
           
           Exemplos:
           - Se varia√ß√£o = 10% (0.1) e sensibilidade = 0.0: varia√ß√£o_ajustada = 0.1 * 0.0 = 0.0 (0%)
           - Se varia√ß√£o = 10% (0.1) e sensibilidade = 0.5: varia√ß√£o_ajustada = 0.1 * 0.5 = 0.05 (5%)
           - Se varia√ß√£o = 10% (0.1) e sensibilidade = 0.6: varia√ß√£o_ajustada = 0.1 * 0.6 = 0.06 (6%)
        
        5. Calcular forecast:
           fator_variacao = 1.0 + varia√ß√£o_ajustada
           fator_inflacao = 1.0 + (inflacao / 100.0)
           forecast = M√©dia_historica * fator_variacao * fator_inflacao
           
           Se sensibilidade = 0: fator_variacao = 1.0, ent√£o forecast = M√©dia_historica * 1.0 = M√©dia_historica
        
        6. Total do forecast = Soma de todas as linhas (n√£o h√° ajustes manuais)
        
        IMPORTANTE:
        - Volume m√©dio hist√≥rico e M√©dia hist√≥rica do custo j√° consideram:
          * Exclus√£o de meses (meses_excluir_media)
          * √öltimo per√≠odo com dados reais (ultimo_periodo_dados)
          * Todas as configura√ß√µes do Forecast
        - C√°lculo √© feito linha a linha, sem agrega√ß√µes intermedi√°rias
        - O total √© sempre a soma das linhas individuais
        """
        # Converter tuple de volta para dict se necess√°rio
        if sensibilidades_type06_cache is not None:
            sensibilidades_type06_dict = dict(sensibilidades_type06_cache)
        else:
            sensibilidades_type06_dict = None
        
        if inflacao_type06_cache is not None:
            inflacao_type06_dict = dict(inflacao_type06_cache)
        else:
            inflacao_type06_dict = None
        
        # üîß VERIFICA√á√ÉO: Garantir que df_media_mensal n√£o tem duplicatas
        # Se houver duplicatas, o merge vai criar linhas multiplicadas
        # üîß CORRE√á√ÉO: Incluir 'Ano' na chave se existir (evita agrupar dados de 2024 com 2025)
        colunas_chave_media = ['Oficina', 'Ve√≠culo', 'Tipo_Custo'] + colunas_adicionais_cache
        if 'Ano' in df_media_mensal_cache.columns:
            colunas_chave_media.insert(2, 'Ano')  # Inserir Ano ap√≥s Ve√≠culo
        colunas_chave_media_existentes = [col for col in colunas_chave_media if col in df_media_mensal_cache.columns]
        
        if len(colunas_chave_media_existentes) > 0:
            duplicatas_media = df_media_mensal_cache.duplicated(subset=colunas_chave_media_existentes, keep=False)
            if duplicatas_media.any():
                # üîß CORRE√á√ÉO CR√çTICA: Se houver duplicatas, SOMAR (n√£o tirar m√©dia)
                # Cada linha duplicada representa uma parte do total que deve ser somada
                agg_dict_media_dup = {'Total': 'sum'}  # SOMAR as m√©dias duplicadas (n√£o tirar m√©dia)
                df_media_mensal_cache = df_media_mensal_cache.groupby(
                    colunas_chave_media_existentes, as_index=False
                ).agg(agg_dict_media_dup)
        
        # üîß VERIFICA√á√ÉO: Garantir que volume_base n√£o tem duplicatas
        # Se houver m√∫ltiplas linhas para mesma Oficina + Ve√≠culo, o merge vai duplicar
        # üîß CORRE√á√ÉO CR√çTICA: volume_base √© volume m√©dio hist√≥rico (n√£o espec√≠fico por ano)
        # N√ÉO usar 'Ano' no agrupamento - volume_base j√° √© uma m√©dia geral
        if not volume_base_cache.empty and 'Oficina' in volume_base_cache.columns and 'Ve√≠culo' in volume_base_cache.columns:
            colunas_dup_volume = ['Oficina', 'Ve√≠culo']
            # N√ÉO incluir 'Ano' - volume_base √© m√©dio hist√≥rico geral
            duplicatas_volume = volume_base_cache.duplicated(subset=colunas_dup_volume, keep=False)
            if duplicatas_volume.any():
                # üîß CORRE√á√ÉO CR√çTICA: Se houver duplicatas, SOMAR (n√£o tirar m√©dia)
                # Cada linha duplicada representa uma parte do volume que deve ser somada
                volume_base_cache = volume_base_cache.groupby(
                    colunas_dup_volume, as_index=False
                ).agg({'Volume_Medio_Historico': 'sum'})  # SOMAR os volumes duplicados (n√£o tirar m√©dia)
        
        # Usar df_media_mensal_cache que j√° cont√©m a m√©dia hist√≥rica calculada
        # (a m√©dia j√° foi calculada usando a l√≥gica correta: m√©dia dos totais por per√≠odo)
        df_forecast_base = df_media_mensal_cache.copy()
        
        # Fazer merge com volume_base
        # üîß CORRE√á√ÉO CR√çTICA: volume_base √© volume m√©dio hist√≥rico (n√£o √© por m√™s espec√≠fico)
        # N√ÉO usar 'Ano' como chave aqui, pois volume_base √© uma m√©dia geral
        # Usar apenas Oficina e Ve√≠culo (e colunas adicionais se necess√°rio)
        colunas_merge_volume = ['Oficina', 'Ve√≠culo']
        # N√ÉO incluir 'Ano' aqui - volume_base √© m√©dio hist√≥rico, n√£o espec√≠fico por ano
        
        df_forecast_base = df_forecast_base.merge(
            volume_base_cache,
            on=colunas_merge_volume,
            how='left'
        )
        
        # Verificar se o merge criou duplicatas
        num_linhas_apos_merge = len(df_forecast_base)
        num_linhas_antes_merge = len(df_media_mensal_cache)
        if num_linhas_apos_merge > num_linhas_antes_merge:
            # Verificar duplicatas por chave completa
            colunas_chave_completa = colunas_merge_volume + ['Tipo_Custo'] + [col for col in colunas_adicionais_cache if col in df_forecast_base.columns]
            colunas_chave_completa_existentes = [col for col in colunas_chave_completa if col in df_forecast_base.columns]
            if len(colunas_chave_completa_existentes) > 0:
                duplicatas_merge = df_forecast_base.duplicated(subset=colunas_chave_completa_existentes, keep=False)
                num_duplicatas_merge = duplicatas_merge.sum()
                if num_duplicatas_merge > 0:
                    st.sidebar.error(f"‚ùå PROBLEMA CR√çTICO: Merge criou {num_duplicatas_merge} linhas duplicadas! Isso causa valores pela metade!")
                    # üîß CORRE√á√ÉO: Agrupar duplicatas somando valores num√©ricos
                    agg_dict_merge_dup = {}
                    for col in df_forecast_base.columns:
                        if col not in colunas_chave_completa_existentes:
                            if col == 'M√©dia_Mensal_Hist√≥rica' or col == 'Total':
                                agg_dict_merge_dup[col] = 'sum'  # Somar m√©dias duplicadas
                            elif col == 'Volume_Medio_Historico':
                                agg_dict_merge_dup[col] = 'sum'  # Somar volumes duplicados
                            else:
                                agg_dict_merge_dup[col] = 'first'
                    df_forecast_base = df_forecast_base.groupby(
                        colunas_chave_completa_existentes, as_index=False
                    ).agg(agg_dict_merge_dup)
                    st.sidebar.success(f"‚úÖ Corrigido: {len(df_forecast_base)} linhas ap√≥s agrupamento de duplicatas")
        
        # Se n√£o houver volume m√©dio hist√≥rico, manter como 0 para n√£o distorcer a propor√ß√£o
        df_forecast_base['Volume_Medio_Historico'] = df_forecast_base['Volume_Medio_Historico'].fillna(0.0)
        
        # üîß VERIFICA√á√ÉO: Garantir que df_cpu_medio n√£o tem duplicatas
        # Se houver m√∫ltiplas linhas para mesma combina√ß√£o, o merge vai duplicar
        if df_cpu_medio_cache is not None and not df_cpu_medio_cache.empty:
            colunas_merge_cpu = ['Oficina', 'Ve√≠culo'] + colunas_adicionais_cache
            colunas_merge_cpu_existentes = [col for col in colunas_merge_cpu if col in df_cpu_medio_cache.columns]
            
            if len(colunas_merge_cpu_existentes) > 0:
                duplicatas_cpu = df_cpu_medio_cache.duplicated(subset=colunas_merge_cpu_existentes, keep=False)
                if duplicatas_cpu.any():
                    # üîß CORRE√á√ÉO CR√çTICA: Se houver duplicatas, SOMAR valores num√©ricos (n√£o tirar m√©dia)
                    # Cada linha duplicada representa uma parte do total que deve ser somada
                    colunas_agregar_cpu = [col for col in df_cpu_medio_cache.columns if col not in colunas_merge_cpu_existentes]
                    agg_dict_cpu = {col: 'sum' if df_cpu_medio_cache[col].dtype in ['float64', 'int64'] else 'first' for col in colunas_agregar_cpu}
                    df_cpu_medio_cache = df_cpu_medio_cache.groupby(
                        colunas_merge_cpu_existentes, as_index=False
                    ).agg(agg_dict_cpu)
            
            df_forecast_base = df_forecast_base.merge(
                df_cpu_medio_cache,
                on=colunas_merge_cpu_existentes,
                how='left'
            )
            df_forecast_base['CPU_Historico'] = df_forecast_base['CPU_Historico'].fillna(0)
            df_forecast_base['Volume_Medio_Ref'] = df_forecast_base['Volume_Medio_Ref'].fillna(df_forecast_base['Volume_Medio_Historico'])
        else:
            df_forecast_base['CPU_Historico'] = 0
            df_forecast_base['Volume_Medio_Ref'] = df_forecast_base['Volume_Medio_Historico']
        
        # Renomear 'Total' para 'M√©dia_Mensal_Hist√≥rica'
        df_forecast_base = df_forecast_base.rename(columns={'Total': 'M√©dia_Mensal_Hist√≥rica'})
        
        # Verificar se h√° duplicatas finais no df_forecast_base
        colunas_chave_final = ['Oficina', 'Ve√≠culo', 'Tipo_Custo'] + [col for col in colunas_adicionais_cache if col in df_forecast_base.columns]
        if 'Ano' in df_forecast_base.columns:
            colunas_chave_final.insert(2, 'Ano')
        colunas_chave_final_existentes = [col for col in colunas_chave_final if col in df_forecast_base.columns]
        if len(colunas_chave_final_existentes) > 0:
            duplicatas_final_base = df_forecast_base.duplicated(subset=colunas_chave_final_existentes, keep=False)
            num_duplicatas_final_base = duplicatas_final_base.sum()
            if num_duplicatas_final_base > 0:
                st.sidebar.error(f"‚ùå PROBLEMA: {num_duplicatas_final_base} linhas duplicadas finais em df_forecast_base!")
                # üîß CORRE√á√ÉO FINAL: Agrupar duplicatas finais
                agg_dict_final_dup = {}
                for col in df_forecast_base.columns:
                    if col not in colunas_chave_final_existentes:
                        if col == 'M√©dia_Mensal_Hist√≥rica':
                            agg_dict_final_dup[col] = 'sum'  # Somar m√©dias duplicadas
                        elif col == 'Volume_Medio_Historico':
                            agg_dict_final_dup[col] = 'sum'  # Somar volumes duplicados
                        else:
                            agg_dict_final_dup[col] = 'first'
                df_forecast_base = df_forecast_base.groupby(
                    colunas_chave_final_existentes, as_index=False
                ).agg(agg_dict_final_dup)
                st.sidebar.success(f"‚úÖ Corrigido: {len(df_forecast_base)} linhas √∫nicas ap√≥s agrupamento final")
        
        # Criar DataFrame final de forecast
        # üîß CORRE√á√ÉO: Incluir 'Ano' se existir em df_media_mensal (preservar ano original)
        forecast_cols = ['Oficina', 'Ve√≠culo'] + colunas_adicionais_cache + ['Tipo_Custo', 'M√©dia_Mensal_Hist√≥rica']
        if 'Ano' in df_forecast_base.columns:
            forecast_cols.insert(2, 'Ano')  # Inserir Ano ap√≥s Ve√≠culo
        df_forecast = df_forecast_base[forecast_cols].copy()
        
        # Calcular forecast para cada per√≠odo
        for idx_mes, periodo in enumerate(meses_restantes_cache):
            # Buscar volume espec√≠fico deste per√≠odo
            # Regra de neg√≥cio: s√≥ h√° previs√£o se existir volume para aquele m√™s/ano
            if volume_por_mes_cache is not None and not volume_por_mes_cache.empty:
                # Extrair m√™s e ano do per√≠odo procurado
                periodo_str = str(periodo).strip()
                if ' ' in periodo_str:
                    mes_procurado = periodo_str.split(' ', 1)[0].lower()
                    ano_procurado = periodo_str.split(' ', 1)[1] if len(periodo_str.split(' ', 1)) > 1 else None
                else:
                    mes_procurado = periodo_str.lower()
                    ano_procurado = None
                
                # Criar fun√ß√£o para comparar per√≠odos de forma flex√≠vel
                def periodo_corresponde(periodo_df):
                    periodo_df_str = str(periodo_df).strip().lower()
                    if ' ' in periodo_df_str:
                        mes_df = periodo_df_str.split(' ', 1)[0]
                        ano_df = periodo_df_str.split(' ', 1)[1] if len(periodo_df_str.split(' ', 1)) > 1 else None
                    else:
                        mes_df = periodo_df_str
                        ano_df = None
                    
                    # Comparar m√™s
                    if mes_df != mes_procurado:
                        return False
                    
                    # Se ambos t√™m ano, comparar ano tamb√©m
                    if ano_procurado is not None and ano_df is not None:
                        return str(ano_procurado) == str(ano_df)
                    
                    # Se pelo menos um n√£o tem ano, considerar como correspondente (compatibilidade)
                    return True
                
                # Aplicar filtro flex√≠vel
                periodos_no_df = volume_por_mes_cache['Per√≠odo'].astype(str)
                mask_corresponde = periodos_no_df.apply(periodo_corresponde)
                
                # üîß CORRE√á√ÉO CR√çTICA: Se h√° coluna 'Ano' e o per√≠odo tem ano, tamb√©m filtrar por Ano
                if ano_procurado is not None and 'Ano' in volume_por_mes_cache.columns:
                    # Converter ano_procurado para o mesmo tipo da coluna Ano
                    try:
                        ano_procurado_num = int(ano_procurado) if ano_procurado.isdigit() else None
                        if ano_procurado_num is not None:
                            # Filtrar tamb√©m por Ano
                            mask_ano = volume_por_mes_cache['Ano'] == ano_procurado_num
                            mask_corresponde = mask_corresponde & mask_ano
                    except:
                        pass
                
                # Selecionar colunas para merge
                # üîß CORRE√á√ÉO CR√çTICA: N√ÉO usar 'Ano' como chave separada
                # O per√≠odo j√° cont√©m m√™s + ano (ex: "Novembro 2025")
                # Usar apenas Oficina e Ve√≠culo para o merge
                colunas_merge_vol = ['Oficina', 'Ve√≠culo', 'Volume']
                
                vol_mes_df = volume_por_mes_cache[mask_corresponde][colunas_merge_vol].copy()
                
                if not vol_mes_df.empty:
                    # Agrupar por Oficina e Ve√≠culo e SOMAR volumes (n√£o fazer mean)
                    # üîß CORRE√á√ÉO: N√ÉO usar 'Ano' no groupby - o per√≠odo j√° foi filtrado corretamente
                    # Se houver m√∫ltiplos registros com mesmo Oficina+Ve√≠culo para o mesmo per√≠odo, somar
                    colunas_groupby_vol = ['Oficina', 'Ve√≠culo']
                    vol_mes_df = vol_mes_df.groupby(colunas_groupby_vol, as_index=False)['Volume'].sum()
                    
                    # Fazer merge usando apenas Oficina e Ve√≠culo
                    # üîß CORRE√á√ÉO: N√ÉO usar 'Ano' no merge - volume_por_mes j√° foi filtrado pelo per√≠odo correto
                    colunas_merge_forecast = ['Oficina', 'Ve√≠culo']
                    
                    # Verificar se vol_mes_df tem duplicatas
                    duplicatas_vol_mes = vol_mes_df.duplicated(subset=colunas_merge_forecast, keep=False)
                    if duplicatas_vol_mes.any():
                        # Agrupar duplicatas antes do merge
                        vol_mes_df = vol_mes_df.groupby(colunas_merge_forecast, as_index=False)['Volume'].sum()
                    
                    df_vol_mes_merge = df_forecast_base[colunas_merge_forecast].merge(
                        vol_mes_df,
                        on=colunas_merge_forecast,
                        how='left',
                        suffixes=('', '_mes')
                    )
                    
                    volume_mes_serie = df_vol_mes_merge['Volume']
                else:
                    # Sem volume para este per√≠odo: n√£o calcular forecast (mant√©m 0)
                    continue
            else:
                # Sem nenhum volume dispon√≠vel: n√£o calcular forecast para este per√≠odo
                continue
            
            # Alinhar volume do m√™s futuro com o √≠ndice do df_forecast_base
            if isinstance(volume_mes_serie, pd.Series):
                volume_mes_aligned = volume_mes_serie.reindex(df_forecast_base.index).fillna(df_forecast_base['Volume_Medio_Historico'])
            else:
                volume_mes_aligned = volume_mes_serie.reindex(df_forecast_base.index).fillna(df_forecast_base['Volume_Medio_Historico'])
            
            # üîß C√ÅLCULO LINHA A LINHA (sem ajustes manuais):
            # Para cada linha, calcular forecast seguindo a f√≥rmula matem√°tica exata
            
            # Inicializar coluna de forecast
            df_forecast[periodo] = 0.0
            
            # Calcular forecast linha a linha
            for idx in df_forecast_base.index:
                # 1. Obter valores da linha
                media_historica = float(df_forecast_base.loc[idx, 'M√©dia_Mensal_Hist√≥rica'])
                volume_medio_historico = float(df_forecast_base.loc[idx, 'Volume_Medio_Historico'])
                volume_mes = float(volume_mes_aligned.loc[idx])
                tipo_custo = df_forecast_base.loc[idx, 'Tipo_Custo']
                
                # 2. Calcular propor√ß√£o de volume: Volume_mes / Volume_medio_historico
                if volume_medio_historico > 0:
                    proporcao_volume = volume_mes / volume_medio_historico
                else:
                    # Se n√£o h√° volume hist√≥rico, usar propor√ß√£o neutra (1.0)
                    proporcao_volume = 1.0
                
                # 3. Calcular varia√ß√£o percentual: proporcao_volume - 1.0
                # Exemplo: se propor√ß√£o = 1.1, ent√£o varia√ß√£o = 0.1 (10% de aumento)
                variacao_percentual = proporcao_volume - 1.0
                
                # 4. Obter sensibilidade (linha a linha, baseado no Tipo_Custo)
                if sensibilidades_type06_dict is not None and 'Type 06' in df_forecast_base.columns:
                    # Modo detalhado: usar sensibilidade espec√≠fica do Type 06
                    type06_valor = df_forecast_base.loc[idx, 'Type 06']
                    if pd.notna(type06_valor) and type06_valor in sensibilidades_type06_dict:
                        sensibilidade = sensibilidades_type06_dict[type06_valor]
                    else:
                        # Se n√£o encontrar Type 06, usar sensibilidade baseada no Tipo_Custo
                        sensibilidade = sensibilidade_fixo_cache if tipo_custo == 'Fixo' else sensibilidade_variavel_cache
                else:
                    # Modo global: usar sensibilidade baseada no Tipo_Custo
                    sensibilidade = sensibilidade_fixo_cache if tipo_custo == 'Fixo' else sensibilidade_variavel_cache
                
                # 5. Aplicar sensibilidade: varia√ß√£o_ajustada = variacao_percentual * sensibilidade
                # Exemplos:
                # - Se varia√ß√£o = 10% (0.1) e sensibilidade = 0.0: varia√ß√£o_ajustada = 0.0 (0%)
                # - Se varia√ß√£o = 10% (0.1) e sensibilidade = 0.5: varia√ß√£o_ajustada = 0.05 (5%)
                # - Se varia√ß√£o = 10% (0.1) e sensibilidade = 0.6: varia√ß√£o_ajustada = 0.06 (6%)
                variacao_ajustada = variacao_percentual * sensibilidade
                
                # 6. Obter infla√ß√£o (linha a linha)
                if sensibilidades_type06_dict is not None and 'Type 06' in df_forecast_base.columns:
                    # Modo detalhado: usar infla√ß√£o espec√≠fica do Type 06
                    type06_valor = df_forecast_base.loc[idx, 'Type 06']
                    if inflacao_type06_dict is not None and pd.notna(type06_valor) and type06_valor in inflacao_type06_dict:
                        inflacao_percentual = inflacao_type06_dict[type06_valor] / 100.0
                    else:
                        inflacao_percentual = 0.0
                else:
                    # Modo global: usar infla√ß√£o global
                    if inflacao_type06_dict is not None:
                        primeiro_valor = next(iter(inflacao_type06_dict.values()), 0.0)
                        inflacao_percentual = primeiro_valor / 100.0
                    else:
                        inflacao_percentual = 0.0
                
                # 7. Calcular forecast: M√©dia_historica * (1 + varia√ß√£o_ajustada) * (1 + infla√ß√£o)
                # Se sensibilidade = 0: varia√ß√£o_ajustada = 0, ent√£o forecast = M√©dia_historica * 1.0 = M√©dia_historica
                fator_variacao = 1.0 + variacao_ajustada
                fator_inflacao = 1.0 + inflacao_percentual
                forecast = media_historica * fator_variacao * fator_inflacao
                
                if sensibilidade == 0 and inflacao_percentual == 0 and abs(proporcao_volume - 1.0) < 0.01:
                    if abs(forecast - media_historica) > 0.01:
                        # Avisar apenas uma vez por per√≠odo
                        if idx == df_forecast_base.index[0] and periodo == meses_restantes_cache[0] if meses_restantes_cache else False:
                            st.sidebar.error(f"‚ùå PROBLEMA: forecast ({forecast:,.2f}) ‚â† m√©dia ({media_historica:,.2f}) quando deveria ser igual!")
                
                # 8. Atribuir forecast √† linha
                df_forecast.loc[idx, periodo] = forecast
            
            # Total do forecast = Soma de todas as linhas (calculado automaticamente pelo pandas)
        
        # N√£o h√° necessidade de verifica√ß√£o final ou ajustes manuais
        # O c√°lculo linha a linha garante que:
        # - Se sensibilidade = 0: varia√ß√£o_ajustada = 0, ent√£o forecast = m√©dia_historica * 1.0 = m√©dia_historica
        # - Se infla√ß√£o = 0: fator_inflacao = 1.0, ent√£o forecast = m√©dia_historica * fator_variacao * 1.0
        # - O total √© sempre a soma das linhas individuais
        
        return df_forecast

    # Preparar dados para forecast usando opera√ß√µes vetorizadas (mais r√°pido)
    # Calcular forecast com cache (incluindo sensibilidades e infla√ß√£o)
    # Converter sensibilidades_type06 para tuple se for dict (para ser hashable no cache)
    sens_type06_cache = tuple(sorted(sensibilidades_type06.items())) if sensibilidades_type06 is not None else None
    inflacao_type06_cache = tuple(sorted(inflacao_type06.items())) if inflacao_type06 is not None else None
    
    # üîß CORRE√á√ÉO: Passar media_historica_total_padronizada para a fun√ß√£o calcular_forecast_completo
    # para garantir que o forecast use a m√©dia correta
    if sensibilidade_fixo is None or sensibilidade_variavel is None:
        st.error(f"‚ùå Erro: Sensibilidade n√£o configurada corretamente!")
        st.stop()
    
    df_forecast = calcular_forecast_completo(
        df_media_mensal, 
        volume_base if volume_base is not None else pd.DataFrame(columns=['Oficina', 'Ve√≠culo', 'Volume_Medio_Historico']),
        df_cpu_medio,
        volume_por_mes if volume_por_mes is not None else pd.DataFrame(columns=['Oficina', 'Ve√≠culo', 'Per√≠odo', 'Volume']),
        colunas_adicionais,
        periodos_restantes,
        sensibilidade_fixo,
        sensibilidade_variavel,
        sens_type06_cache,
        inflacao_type06_cache
    )
    
    # N√£o h√° ajustes manuais: o c√°lculo linha a linha garante que os valores est√£o corretos
    # A m√©dia hist√≥rica j√° foi ajustada anteriormente para corresponder √† m√©dia padronizada
    # Guardar vers√£o bruta do forecast (antes do agrupamento) para diagn√≥sticos
    df_forecast_bruto = df_forecast.copy()
    
    # üÜï NOVA FUNCIONALIDADE: Gerar tabela completa com forecast linha a linha
    if st.session_state.get('gerar_tabela_completa_forecast', False):
        try:
            # CRIAR PASTA FORECAST PRIMEIRO (antes de qualquer processamento)
            pasta_dados = "dados"
            pasta_forecast = os.path.join(pasta_dados, "Forecast")
            try:
                # Criar pasta dados se n√£o existir
                if not os.path.exists(pasta_dados):
                    os.makedirs(pasta_dados, exist_ok=True)
                    st.info(f"üìÅ Pasta 'dados' criada: {os.path.abspath(pasta_dados)}")
                
                # Criar pasta Forecast dentro de dados
                if not os.path.exists(pasta_forecast):
                    os.makedirs(pasta_forecast, exist_ok=True)
                    st.success(f"‚úÖ Pasta Forecast criada: {os.path.abspath(pasta_forecast)}")
                else:
                    st.info(f"üìÅ Pasta Forecast j√° existe: {os.path.abspath(pasta_forecast)}")
            except Exception as e_pasta_inicial:
                st.error(f"‚ùå Erro ao criar pasta Forecast no in√≠cio: {str(e_pasta_inicial)}")
                import traceback
                st.error(f"Detalhes: {traceback.format_exc()}")
            
            with st.spinner("üîÑ Gerando tabela completa com forecast linha a linha..."):
                # Carregar dados completos da base original
                # SEMPRE tentar carregar, mas se n√£o existir, ser√° criado durante o processo
                caminho_base_original = os.path.join("dados", "historico_consolidado", "df_final_historico.parquet")
                df_base_completo = None
                
                if os.path.exists(caminho_base_original):
                    df_base_completo = pd.read_parquet(caminho_base_original)
                else:
                    # Se n√£o existir, tentar carregar do arquivo forecast ou usar dados filtrados
                    caminho_forecast_original = os.path.join("dados", "historico_consolidado", "df_final_historico_forecast.parquet")
                    if os.path.exists(caminho_forecast_original):
                        st.info(f"‚ÑπÔ∏è Usando arquivo forecast como base: {os.path.basename(caminho_forecast_original)}")
                        df_base_completo = pd.read_parquet(caminho_forecast_original)
                    else:
                        st.warning(f"‚ö†Ô∏è Arquivo base n√£o encontrado: {caminho_base_original}")
                        st.info("‚ÑπÔ∏è O arquivo ser√° criado durante o processo de consolida√ß√£o.")
                
                # Verificar se df_base_completo foi carregado corretamente
                if df_base_completo is None or df_base_completo.empty:
                    st.error("‚ùå Erro: N√£o foi poss√≠vel carregar dados hist√≥ricos.")
                    st.error("‚ÑπÔ∏è Por favor, verifique se o arquivo 'df_final_historico.parquet' existe na pasta 'dados/historico_consolidado/'")
                    st.error("‚ö†Ô∏è O processo ser√° interrompido, mas a pasta Forecast ser√° criada mesmo assim.")
                    # Criar pasta mesmo em caso de erro
                    try:
                        pasta_dados = "dados"
                        pasta_forecast = os.path.join(pasta_dados, "Forecast")
                        if not os.path.exists(pasta_dados):
                            os.makedirs(pasta_dados, exist_ok=True)
                        if not os.path.exists(pasta_forecast):
                            os.makedirs(pasta_forecast, exist_ok=True)
                            st.info(f"üìÅ Pasta Forecast criada: {os.path.abspath(pasta_forecast)}")
                    except:
                        pass
                    st.stop()
                
                # Aplicar filtros (Oficina, Ve√≠culo, USI) mas N√ÉO filtrar por Per√≠odo
                # para incluir TODOS os per√≠odos hist√≥ricos no arquivo forecast_completo.parquet
                df_base_filtrado = aplicar_filtros(
                    df_base_completo,
                    tuple(oficina_selecionadas) if oficina_selecionadas else tuple(),
                    tuple(veiculo_selecionados) if veiculo_selecionados else tuple(),
                    tuple(usi_selecionada) if usi_selecionada else tuple(),
                    "Todos"  # N√ÉO filtrar por per√≠odo - incluir todos os per√≠odos hist√≥ricos
                )
                
                # üîß CORRE√á√ÉO: Criar coluna Tipo_Custo se n√£o existir (mesma l√≥gica do c√≥digo principal)
                if 'Tipo_Custo' not in df_base_filtrado.columns:
                    def is_custo_fixo(valor_custo):
                        """Identifica se o custo √© fixo baseado no valor da coluna Custo"""
                        if pd.isna(valor_custo):
                            return False
                        valor_str = str(valor_custo).strip().upper()
                        # Considerar como fixo se cont√©m palavras-chave
                        palavras_fixo = ['FIXO', 'FIX', 'FIXED']
                        return any(palavra in valor_str for palavra in palavras_fixo)
                    
                    # Verificar se existe coluna 'Custo' para determinar Tipo_Custo
                    if 'Custo' in df_base_filtrado.columns:
                        df_base_filtrado['Tipo_Custo'] = df_base_filtrado['Custo'].apply(is_custo_fixo)
                        df_base_filtrado['Tipo_Custo'] = df_base_filtrado['Tipo_Custo'].map({True: 'Fixo', False: 'Vari√°vel'})
                    else:
                        # Se n√£o existe coluna Custo, usar padr√£o 'Vari√°vel'
                        df_base_filtrado['Tipo_Custo'] = 'Vari√°vel'
                
                # Calcular m√©dias hist√≥ricas linha a linha (mesma l√≥gica do forecast)
                # Agrupar por chave √∫nica (Oficina, Ve√≠culo, Tipo_Custo, etc) e per√≠odo
                colunas_chave_forecast = ['Oficina', 'Ve√≠culo', 'Tipo_Custo'] + colunas_adicionais
                if 'Ano' in df_base_filtrado.columns:
                    colunas_chave_forecast.insert(2, 'Ano')
                colunas_chave_forecast_existentes = [col for col in colunas_chave_forecast if col in df_base_filtrado.columns]
                
                # Filtrar apenas per√≠odos selecionados para m√©dia
                if periodos_para_media and 'Per√≠odo' in df_base_filtrado.columns:
                    # Normalizar per√≠odos
                    periodos_normalizados = [str(p).strip().lower() for p in periodos_para_media]
                    df_base_filtrado['Per√≠odo_Norm'] = df_base_filtrado['Per√≠odo'].astype(str).str.strip().str.lower()
                    df_base_para_media = df_base_filtrado[df_base_filtrado['Per√≠odo_Norm'].isin(periodos_normalizados)].copy()
                    
                    # Excluir meses marcados
                    if meses_excluir_media:
                        meses_excluir_normalizados = [str(m).strip().lower() for m in meses_excluir_media]
                        df_base_para_media = df_base_para_media[~df_base_para_media['Per√≠odo_Norm'].isin(meses_excluir_normalizados)].copy()
                else:
                    df_base_para_media = df_base_filtrado.copy()
                
                # Calcular m√©dia hist√≥rica por chave √∫nica
                if 'Total' in df_base_para_media.columns:
                    df_medias_linha = df_base_para_media.groupby(colunas_chave_forecast_existentes, as_index=False)['Total'].mean()
                    df_medias_linha.rename(columns={'Total': 'M√©dia_Mensal_Hist√≥rica'}, inplace=True)
                else:
                    df_medias_linha = pd.DataFrame(columns=colunas_chave_forecast_existentes + ['M√©dia_Mensal_Hist√≥rica'])
                
                # Fazer merge com volume_base para obter Volume_Medio_Historico
                if volume_base is not None and not volume_base.empty:
                    colunas_merge_vol = ['Oficina', 'Ve√≠culo']
                    df_medias_linha = df_medias_linha.merge(
                        volume_base[colunas_merge_vol + ['Volume_Medio_Historico']],
                        on=colunas_merge_vol,
                        how='left'
                    )
                    df_medias_linha['Volume_Medio_Historico'] = df_medias_linha['Volume_Medio_Historico'].fillna(0.0)
                else:
                    df_medias_linha['Volume_Medio_Historico'] = 0.0
                
                # Preparar dados para c√°lculo de forecast linha a linha
                # IMPORTANTE: Usar a mesma l√≥gica do df_forecast_bruto (que √© usado no gr√°fico)
                # O df_forecast_bruto j√° foi calculado com a fun√ß√£o calcular_forecast_completo
                # que usa a mesma l√≥gica do modo Custo Total do gr√°fico
                
                # Primeiro, criar df_forecast_completo a partir de df_base_filtrado
                df_forecast_completo = df_base_filtrado.copy()
                
                # Adicionar M√©dia_Mensal_Hist√≥rica e Volume_Medio_Historico via merge
                # IMPORTANTE: Usar apenas as colunas chave que existem em ambos os DataFrames
                colunas_merge_medias = [col for col in colunas_chave_forecast_existentes if col in df_medias_linha.columns]
                # Verificar se as colunas existem em df_medias_linha antes de fazer merge
                colunas_para_merge = colunas_merge_medias.copy()
                if 'M√©dia_Mensal_Hist√≥rica' in df_medias_linha.columns:
                    colunas_para_merge.append('M√©dia_Mensal_Hist√≥rica')
                if 'Volume_Medio_Historico' in df_medias_linha.columns:
                    colunas_para_merge.append('Volume_Medio_Historico')
                
                df_forecast_completo = df_forecast_completo.merge(
                    df_medias_linha[colunas_para_merge],
                    on=colunas_merge_medias,
                    how='left'
                )
                
                # Garantir que as colunas existam ap√≥s o merge
                if 'M√©dia_Mensal_Hist√≥rica' not in df_forecast_completo.columns:
                    df_forecast_completo['M√©dia_Mensal_Hist√≥rica'] = 0.0
                else:
                    df_forecast_completo['M√©dia_Mensal_Hist√≥rica'] = df_forecast_completo['M√©dia_Mensal_Hist√≥rica'].fillna(0.0)
                
                if 'Volume_Medio_Historico' not in df_forecast_completo.columns:
                    df_forecast_completo['Volume_Medio_Historico'] = 0.0
                else:
                    df_forecast_completo['Volume_Medio_Historico'] = df_forecast_completo['Volume_Medio_Historico'].fillna(0.0)
                
                # IMPORTANTE: Tentar usar valores do df_forecast_bruto se dispon√≠vel (mesma l√≥gica do gr√°fico)
                # Isso garante que os valores sejam id√™nticos aos do gr√°fico
                if 'df_forecast_bruto' in locals() and df_forecast_bruto is not None and not df_forecast_bruto.empty:
                    # Fazer merge com df_forecast_bruto para obter valores de forecast j√° calculados
                    colunas_merge_forecast = [col for col in colunas_chave_forecast_existentes if col in df_forecast_bruto.columns]
                    if colunas_merge_forecast:
                        # Adicionar colunas de forecast do df_forecast_bruto
                        colunas_forecast_bruto = colunas_merge_forecast + [p for p in periodos_restantes if p in df_forecast_bruto.columns]
                        df_forecast_completo = df_forecast_completo.merge(
                            df_forecast_bruto[colunas_forecast_bruto],
                            on=colunas_merge_forecast,
                            how='left',
                            suffixes=('', '_bruto')
                        )
                        # Preencher valores de forecast do df_forecast_bruto onde dispon√≠vel
                        for periodo in periodos_restantes:
                            coluna_bruto = f"{periodo}_bruto" if f"{periodo}_bruto" in df_forecast_completo.columns else periodo
                            if coluna_bruto in df_forecast_completo.columns:
                                # Usar valores do df_forecast_bruto onde dispon√≠vel
                                mask_nao_preenchido = df_forecast_completo[periodo].isna() | (df_forecast_completo[periodo] == 0)
                                if coluna_bruto != periodo:
                                    df_forecast_completo.loc[mask_nao_preenchido, periodo] = df_forecast_completo.loc[mask_nao_preenchido, coluna_bruto].fillna(0.0)
                                    df_forecast_completo = df_forecast_completo.drop(columns=[coluna_bruto])
                
                # IMPORTANTE: Inicializar colunas de forecast com 0.0 se n√£o existirem
                for periodo in periodos_restantes:
                    if periodo not in df_forecast_completo.columns:
                        df_forecast_completo[periodo] = 0.0
                
                # Converter sensibilidades e infla√ß√£o para dict se necess√°rio
                sensibilidades_type06_dict = None
                if sensibilidades_type06 is not None:
                    if isinstance(sensibilidades_type06, dict):
                        sensibilidades_type06_dict = sensibilidades_type06
                    elif isinstance(sensibilidades_type06, tuple):
                        sensibilidades_type06_dict = dict(sensibilidades_type06)
                
                inflacao_type06_dict = None
                if inflacao_type06 is not None:
                    if isinstance(inflacao_type06, dict):
                        inflacao_type06_dict = inflacao_type06
                    elif isinstance(inflacao_type06, tuple):
                        inflacao_type06_dict = dict(inflacao_type06)
                
                # Calcular forecast para cada per√≠odo linha a linha
                for periodo in periodos_restantes:
                    # Buscar volume para este per√≠odo
                    volume_mes_serie = None
                    if volume_por_mes is not None and not volume_por_mes.empty:
                        periodo_str = str(periodo).strip()
                        mes_procurado = periodo_str.split(' ', 1)[0].lower() if ' ' in periodo_str else periodo_str.lower()
                        
                        # Filtrar volume para este per√≠odo
                        volume_por_mes_temp = volume_por_mes.copy()
                        volume_por_mes_temp['Per√≠odo_Normalizado'] = volume_por_mes_temp['Per√≠odo'].astype(str).str.strip().str.lower().str.split(' ', expand=True)[0]
                        vol_mes_df = volume_por_mes_temp[volume_por_mes_temp['Per√≠odo_Normalizado'] == mes_procurado].copy()
                        
                        if not vol_mes_df.empty:
                            # Agrupar por Oficina e Ve√≠culo
                            vol_mes_df = vol_mes_df.groupby(['Oficina', 'Ve√≠culo'], as_index=False)['Volume'].sum()
                            
                            # Fazer merge com df_forecast_completo
                            df_forecast_completo = df_forecast_completo.merge(
                                vol_mes_df.rename(columns={'Volume': f'Volume_{periodo}'}),
                                on=['Oficina', 'Ve√≠culo'],
                                how='left'
                            )
                            # Verificar se Volume_Medio_Historico existe antes de usar
                            if 'Volume_Medio_Historico' in df_forecast_completo.columns:
                                volume_mes_serie = df_forecast_completo[f'Volume_{periodo}'].fillna(df_forecast_completo['Volume_Medio_Historico'])
                            else:
                                volume_mes_serie = df_forecast_completo[f'Volume_{periodo}'].fillna(0.0)
                            df_forecast_completo = df_forecast_completo.drop(columns=[f'Volume_{periodo}'])
                        else:
                            # Verificar se Volume_Medio_Historico existe antes de usar
                            if 'Volume_Medio_Historico' in df_forecast_completo.columns:
                                volume_mes_serie = df_forecast_completo['Volume_Medio_Historico']
                            else:
                                volume_mes_serie = pd.Series(0.0, index=df_forecast_completo.index)
                    else:
                        # Verificar se Volume_Medio_Historico existe antes de usar
                        if 'Volume_Medio_Historico' in df_forecast_completo.columns:
                            volume_mes_serie = df_forecast_completo['Volume_Medio_Historico']
                        else:
                            volume_mes_serie = pd.Series(0.0, index=df_forecast_completo.index)
                    
                    # Calcular forecast linha a linha (mesma l√≥gica de calcular_forecast_completo)
                    df_forecast_completo[periodo] = 0.0
                    
                    for idx in df_forecast_completo.index:
                            try:
                                # Verificar se as colunas existem antes de acess√°-las
                                if 'M√©dia_Mensal_Hist√≥rica' not in df_forecast_completo.columns:
                                    df_forecast_completo['M√©dia_Mensal_Hist√≥rica'] = 0.0
                                if 'Volume_Medio_Historico' not in df_forecast_completo.columns:
                                    df_forecast_completo['Volume_Medio_Historico'] = 0.0
                                
                                media_historica = float(df_forecast_completo.loc[idx, 'M√©dia_Mensal_Hist√≥rica'])
                                volume_medio_historico = float(df_forecast_completo.loc[idx, 'Volume_Medio_Historico'])
                                if isinstance(volume_mes_serie, pd.Series):
                                    volume_mes = float(volume_mes_serie.loc[idx]) if idx in volume_mes_serie.index else float(volume_medio_historico)
                                else:
                                    volume_mes = float(volume_mes_serie) if isinstance(volume_mes_serie, (int, float)) else float(volume_medio_historico)
                                
                                # Verificar se Tipo_Custo existe
                                if 'Tipo_Custo' not in df_forecast_completo.columns:
                                    # Se n√£o existe, usar padr√£o 'Vari√°vel'
                                    tipo_custo = 'Vari√°vel'
                                else:
                                    tipo_custo = df_forecast_completo.loc[idx, 'Tipo_Custo']
                                    # Garantir que tipo_custo seja string v√°lida
                                    if pd.isna(tipo_custo) or tipo_custo not in ['Fixo', 'Vari√°vel']:
                                        tipo_custo = 'Vari√°vel'
                            except Exception as e:
                                # Em caso de erro, usar valores padr√£o e continuar
                                st.warning(f"‚ö†Ô∏è Erro ao processar linha {idx}: {str(e)}")
                                continue
                            
                            # Calcular propor√ß√£o de volume
                            if volume_medio_historico > 0:
                                proporcao_volume = volume_mes / volume_medio_historico
                            else:
                                proporcao_volume = 1.0
                            
                            # Calcular varia√ß√£o percentual
                            variacao_percentual = proporcao_volume - 1.0
                            
                            # Obter sensibilidade
                            if sensibilidades_type06_dict is not None and 'Type 06' in df_forecast_completo.columns:
                                type06_valor = df_forecast_completo.loc[idx, 'Type 06']
                                if pd.notna(type06_valor) and type06_valor in sensibilidades_type06_dict:
                                    sensibilidade = sensibilidades_type06_dict[type06_valor]
                                else:
                                    sensibilidade = sensibilidade_fixo if tipo_custo == 'Fixo' else sensibilidade_variavel
                            else:
                                sensibilidade = sensibilidade_fixo if tipo_custo == 'Fixo' else sensibilidade_variavel
                            
                            # Aplicar sensibilidade
                            variacao_ajustada = variacao_percentual * sensibilidade
                            
                            # Obter infla√ß√£o
                            if inflacao_type06_dict is not None and 'Type 06' in df_forecast_completo.columns:
                                type06_valor = df_forecast_completo.loc[idx, 'Type 06']
                                if pd.notna(type06_valor) and type06_valor in inflacao_type06_dict:
                                    inflacao_percentual = inflacao_type06_dict[type06_valor] / 100.0
                                else:
                                    inflacao_percentual = 0.0
                            else:
                                if inflacao_type06_dict is not None:
                                    primeiro_valor = next(iter(inflacao_type06_dict.values()), 0.0)
                                    inflacao_percentual = primeiro_valor / 100.0
                                else:
                                    inflacao_percentual = 0.0
                            
                            # Calcular forecast
                            fator_variacao = 1.0 + variacao_ajustada
                            fator_inflacao = 1.0 + inflacao_percentual
                            forecast = media_historica * fator_variacao * fator_inflacao
                            
                            df_forecast_completo.loc[idx, periodo] = forecast
                    
                    # ====================================================================
                    # üÜï TRANSFORMAR COLUNAS DE FORECAST EM LINHAS NA COLUNA "Per√≠odo"
                    # ====================================================================
                    # Ao inv√©s de ter colunas separadas para cada per√≠odo, criar linhas
                    # onde cada linha tem Per√≠odo = "Novembro 2025", "Dezembro 2025", etc.
                    # IMPORTANTE: Usar valores do df_forecast_bruto (mesma l√≥gica do gr√°fico)
                    
                    linhas_finais = []
                    
                    # 1. Adicionar linhas hist√≥ricas (j√° est√£o no df_base_filtrado)
                    # Manter apenas as colunas necess√°rias e adicionar Tipo = 'Hist√≥rico'
                    df_historico_linhas = df_base_filtrado.copy()
                    # Remover colunas de forecast se existirem
                    for periodo in periodos_restantes:
                        if periodo in df_historico_linhas.columns:
                            df_historico_linhas = df_historico_linhas.drop(columns=[periodo])
                    # Adicionar coluna Tipo = 'Hist√≥rico'
                    df_historico_linhas['Tipo'] = 'Hist√≥rico'
                    linhas_finais.append(df_historico_linhas)
                    
                    # 2. Criar linhas de forecast para cada per√≠odo
                    # IMPORTANTE: Usar df_forecast_bruto para garantir valores iguais ao gr√°fico
                    df_fonte_forecast = None
                    if 'df_forecast_bruto' in locals() and df_forecast_bruto is not None and not df_forecast_bruto.empty:
                        df_fonte_forecast = df_forecast_bruto.copy()
                        st.info("‚úÖ Usando valores do df_forecast_bruto (mesma l√≥gica do gr√°fico)")
                    else:
                        # Fallback: usar df_forecast_completo com valores calculados
                        df_fonte_forecast = df_forecast_completo.copy()
                        st.info("‚ÑπÔ∏è Usando valores calculados do df_forecast_completo")
                    
                    for periodo in periodos_restantes:
                        if periodo in df_fonte_forecast.columns:
                            # Para cada linha √∫nica, criar uma nova linha com Per√≠odo = periodo
                            colunas_chave_linha = ['Oficina', 'Ve√≠culo', 'Tipo_Custo'] + colunas_adicionais
                            if 'Ano' in df_fonte_forecast.columns:
                                colunas_chave_linha.insert(2, 'Ano')
                            colunas_chave_linha = [col for col in colunas_chave_linha if col in df_fonte_forecast.columns]
                            
                            # Obter linhas √∫nicas com valores de forecast
                            colunas_para_linha = colunas_chave_linha + [periodo]
                            df_linhas_unicas = df_fonte_forecast[colunas_para_linha].drop_duplicates(
                                subset=colunas_chave_linha
                            )
                            
                            for _, linha_original in df_linhas_unicas.iterrows():
                                nova_linha = linha_original.to_dict()
                                
                                # Definir Per√≠odo como per√≠odo de forecast
                                nova_linha['Per√≠odo'] = str(periodo)
                                
                                # Extrair ano do per√≠odo se poss√≠vel
                                periodo_str = str(periodo)
                                if ' ' in periodo_str:
                                    partes = periodo_str.split(' ', 1)
                                    if len(partes) == 2 and partes[1].isdigit():
                                        nova_linha['Ano'] = int(partes[1])
                                
                                # Definir Total como valor de forecast (mesma l√≥gica do gr√°fico)
                                nova_linha['Total'] = float(nova_linha.get(periodo, 0.0))
                                
                                # Remover coluna do per√≠odo (j√° est√° em 'Total')
                                if periodo in nova_linha:
                                    del nova_linha[periodo]
                                
                                # Remover outras colunas de forecast
                                for p in periodos_restantes:
                                    if p in nova_linha and p != periodo:
                                        del nova_linha[p]
                                
                                # Remover colunas auxiliares se existirem
                                if 'M√©dia_Mensal_Hist√≥rica' in nova_linha:
                                    del nova_linha['M√©dia_Mensal_Hist√≥rica']
                                if 'Volume_Medio_Historico' in nova_linha:
                                    del nova_linha['Volume_Medio_Historico']
                                
                                # Adicionar coluna Tipo = 'Forecast'
                                nova_linha['Tipo'] = 'Forecast'
                                
                                linhas_finais.append(pd.DataFrame([nova_linha]))
                    
                    # 3. Combinar todas as linhas em um √∫nico DataFrame
                    if linhas_finais:
                        df_forecast_final = pd.concat(linhas_finais, ignore_index=True)
                        
                        # Garantir que todas as colunas estejam presentes
                        todas_colunas = sorted(set([col for df in linhas_finais for col in df.columns]))
                        df_forecast_final = df_forecast_final.reindex(columns=todas_colunas)
                        
                        # Substituir df_forecast_completo pelo resultado final
                        df_forecast_completo = df_forecast_final
                        
                        st.info(f"‚úÖ Tabela criada com {len(df_forecast_completo):,} linhas (hist√≥rico + forecast)")
                        st.info(f"üìä Per√≠odos de forecast inclu√≠dos: {', '.join(periodos_restantes)}")
                        
                        # Debug: Verificar per√≠odos √∫nicos e anos
                        if 'Per√≠odo' in df_forecast_completo.columns:
                            periodos_unicos = df_forecast_completo['Per√≠odo'].unique()
                            st.info(f"üìÖ Per√≠odos √∫nicos no arquivo: {len(periodos_unicos)} per√≠odos")
                            if 'Ano' in df_forecast_completo.columns:
                                anos_unicos = df_forecast_completo['Ano'].unique()
                                st.info(f"üìÖ Anos √∫nicos no arquivo: {sorted(anos_unicos)}")
                    else:
                        st.warning("‚ö†Ô∏è Nenhuma linha foi criada!")
                        # Se n√£o criou linhas, usar df_base_filtrado como base
                        df_forecast_completo = df_base_filtrado.copy()
                        df_forecast_completo['Tipo'] = 'Hist√≥rico'
                        st.info("‚ÑπÔ∏è Usando apenas dados hist√≥ricos (sem forecast)")
                    
                    # Verificar se df_forecast_completo existe e n√£o est√° vazio
                    if df_forecast_completo is None or df_forecast_completo.empty:
                        st.error("‚ùå Erro: DataFrame vazio! N√£o √© poss√≠vel salvar.")
                        st.stop()
                    
                    # Remover colunas especificadas
                    colunas_para_remover = ['N¬∫conta', 'N¬∫doc.ref.', 'Dt.l√ßto.', 'QTD', 'N¬∫doc.ref', 'Doc.compra', 'Texto breve', 'Material', 'Usu√°rio']
                    colunas_para_remover_existentes = [col for col in colunas_para_remover if col in df_forecast_completo.columns]
                    if colunas_para_remover_existentes:
                        df_forecast_completo = df_forecast_completo.drop(columns=colunas_para_remover_existentes)
                    
                    # Remover linhas com valores nulos em colunas importantes para reduzir tamanho do arquivo
                    linhas_antes = len(df_forecast_completo)
                    
                    # 1. Remover linhas onde Total √© nulo ou zero (se a coluna Total existir)
                    if 'Total' in df_forecast_completo.columns:
                        mask_total_valido = df_forecast_completo['Total'].notna() & (df_forecast_completo['Total'] != 0)
                        df_forecast_completo = df_forecast_completo[mask_total_valido].copy()
                    
                    # 2. Remover linhas onde colunas cr√≠ticas s√£o todas nulas
                    colunas_criticas = ['Oficina', 'Ve√≠culo', 'Per√≠odo']
                    colunas_criticas_existentes = [col for col in colunas_criticas if col in df_forecast_completo.columns]
                    
                    if colunas_criticas_existentes:
                        # Remover linhas onde todas as colunas cr√≠ticas s√£o nulas
                        mask_linhas_validas = df_forecast_completo[colunas_criticas_existentes].notna().any(axis=1)
                        df_forecast_completo = df_forecast_completo[mask_linhas_validas].copy()
                    
                    linhas_depois = len(df_forecast_completo)
                    linhas_removidas = linhas_antes - linhas_depois
                    
                    if linhas_removidas > 0:
                        st.info(f"üßπ Removidas {linhas_removidas:,} linhas com valores nulos/zerados (de {linhas_antes:,} para {linhas_depois:,})")
                    
                    # 3. Remover colunas que s√£o completamente nulas (para otimizar ainda mais)
                    colunas_todas_nulas = df_forecast_completo.columns[df_forecast_completo.isna().all()].tolist()
                    if colunas_todas_nulas:
                        df_forecast_completo = df_forecast_completo.drop(columns=colunas_todas_nulas)
                        st.info(f"üßπ Removidas {len(colunas_todas_nulas)} colunas completamente nulas: {', '.join(colunas_todas_nulas[:5])}{'...' if len(colunas_todas_nulas) > 5 else ''}")
                    
                    # Criar pasta Forecast em dados/Forecast (ANTES de tentar salvar)
                    pasta_dados = "dados"
                    pasta_forecast = os.path.join(pasta_dados, "Forecast")
                    
                    st.info(f"üìÅ Preparando para salvar em: {os.path.abspath(pasta_forecast)}")
                    try:
                        # Criar pasta dados se n√£o existir
                        if not os.path.exists(pasta_dados):
                            os.makedirs(pasta_dados, exist_ok=True)
                            st.info(f"üìÅ Pasta 'dados' criada: {os.path.abspath(pasta_dados)}")
                        
                        # Criar pasta Forecast dentro de dados
                        if not os.path.exists(pasta_forecast):
                            os.makedirs(pasta_forecast, exist_ok=True)
                            st.success(f"‚úÖ Pasta Forecast criada: {os.path.abspath(pasta_forecast)}")
                        else:
                            st.info(f"üìÅ Pasta Forecast j√° existe: {os.path.abspath(pasta_forecast)}")
                    except Exception as e_pasta:
                        st.error(f"‚ùå Erro ao criar pasta Forecast: {str(e_pasta)}")
                        import traceback
                        st.error(f"Detalhes: {traceback.format_exc()}")
                        # Fallback: tentar criar na raiz
                        pasta_forecast = "Forecast"
                        try:
                            os.makedirs(pasta_forecast, exist_ok=True)
                            st.warning(f"‚ö†Ô∏è Usando pasta Forecast na raiz: {os.path.abspath(pasta_forecast)}")
                        except:
                            pasta_forecast = "."  # √öltimo fallback: diret√≥rio atual
                            st.error(f"‚ùå Usando diret√≥rio atual como fallback: {os.path.abspath(pasta_forecast)}")
                    
                    # Usar nome fixo para substituir arquivo existente (n√£o usar timestamp)
                    nome_arquivo_base = "forecast_completo"
                    
                    # ============================================================
                    # PASSO 1: Copiar arquivo completo de volume hist√≥rico
                    # ============================================================
                    try:
                        # Carregar arquivo completo de volume hist√≥rico (antes dos filtros)
                        caminho_vol_historico_original = os.path.join("dados", "historico_consolidado", "df_vol_historico.parquet")
                        
                        if os.path.exists(caminho_vol_historico_original):
                            # Copiar arquivo completo para a pasta Forecast
                            caminho_vol_historico_destino = os.path.join(pasta_forecast, "df_vol_historico.parquet")
                            shutil.copy2(caminho_vol_historico_original, caminho_vol_historico_destino)
                            
                            # Tamb√©m salvar em Excel
                            df_vol_historico_completo = pd.read_parquet(caminho_vol_historico_original)
                            caminho_vol_historico_excel = os.path.join(pasta_forecast, "df_vol_historico.xlsx")
                            df_vol_historico_completo.to_excel(caminho_vol_historico_excel, index=False, engine='openpyxl')
                            
                            st.success(f"‚úÖ Arquivo de volume hist√≥rico copiado: {os.path.abspath(caminho_vol_historico_destino)}")
                            st.info(f"   üìä Total de linhas: {len(df_vol_historico_completo):,}")
                        else:
                            st.warning(f"‚ö†Ô∏è Arquivo de volume hist√≥rico n√£o encontrado: {caminho_vol_historico_original}")
                    except Exception as e_volume:
                        st.warning(f"‚ö†Ô∏è Erro ao copiar arquivo de volume hist√≥rico: {str(e_volume)}")
                        import traceback
                        st.error(f"Detalhes: {traceback.format_exc()}")
                    
                    # ============================================================
                    # PASSO 2: Salvar forecast_completo
                    # ============================================================
                    # Salvar em parquet (sempre substituir se existir)
                    caminho_parquet = os.path.join(pasta_forecast, f"{nome_arquivo_base}.parquet")
                    caminho_parquet_absoluto = os.path.abspath(caminho_parquet)
                    try:
                        st.info(f"üíæ Salvando Parquet em: {caminho_parquet_absoluto}")
                        st.info(f"üìä Total de linhas: {len(df_forecast_completo):,}")
                        df_forecast_completo.to_parquet(caminho_parquet, index=False, engine='pyarrow')
                        
                        # Verificar se foi salvo
                        if os.path.exists(caminho_parquet):
                            tamanho_arquivo = os.path.getsize(caminho_parquet) / (1024 * 1024)  # MB
                            st.success(f"‚úÖ Parquet salvo com sucesso!")
                            st.info(f"   üìÑ Arquivo: {caminho_parquet_absoluto}")
                            st.info(f"   üìè Tamanho: {tamanho_arquivo:.2f} MB")
                        else:
                            st.error(f"‚ùå Arquivo Parquet n√£o foi criado: {caminho_parquet_absoluto}")
                    except Exception as e_parquet:
                        st.error(f"‚ùå Erro ao salvar Parquet: {str(e_parquet)}")
                        import traceback
                        st.error(f"Detalhes: {traceback.format_exc()}")
                    
                    # Salvar em excel (sempre substituir se existir)
                    caminho_excel = os.path.join(pasta_forecast, f"{nome_arquivo_base}.xlsx")
                    caminho_excel_absoluto = os.path.abspath(caminho_excel)
                    try:
                        st.info(f"üíæ Salvando Excel em: {caminho_excel_absoluto}")
                        st.info(f"üìä Total de linhas para salvar: {len(df_forecast_completo):,}")
                        
                        # Para arquivos grandes, pode ser necess√°rio usar xlsxwriter ou dividir em chunks
                        # Primeiro, tentar salvar normalmente (mode='w' substitui arquivo existente)
                        with pd.ExcelWriter(caminho_excel, engine='openpyxl', mode='w') as writer:
                            df_forecast_completo.to_excel(writer, index=False, sheet_name='Forecast')
                        
                        # Verificar se o arquivo foi criado
                        if os.path.exists(caminho_excel):
                            tamanho_arquivo = os.path.getsize(caminho_excel) / (1024 * 1024)  # Tamanho em MB
                            st.success(f"‚úÖ Excel salvo/substitu√≠do com sucesso!")
                            st.info(f"   üìÑ Arquivo: {caminho_excel_absoluto}")
                            st.info(f"   üìè Tamanho: {tamanho_arquivo:.2f} MB")
                        else:
                            st.error(f"‚ùå Arquivo Excel n√£o foi criado: {caminho_excel_absoluto}")
                            # Tentar salvar com xlsxwriter como alternativa
                            try:
                                import xlsxwriter
                                st.info(f"üîÑ Tentando salvar com xlsxwriter...")
                                with pd.ExcelWriter(caminho_excel, engine='xlsxwriter') as writer:
                                    df_forecast_completo.to_excel(writer, index=False, sheet_name='Forecast')
                                if os.path.exists(caminho_excel):
                                    tamanho_arquivo = os.path.getsize(caminho_excel) / (1024 * 1024)
                                    st.success(f"‚úÖ Excel salvo com xlsxwriter: {os.path.abspath(caminho_excel)} ({tamanho_arquivo:.2f} MB)")
                            except Exception as e_excel_alt:
                                st.error(f"‚ùå Erro ao salvar Excel com xlsxwriter: {str(e_excel_alt)}")
                                import traceback
                                st.error(f"Detalhes: {traceback.format_exc()}")
                    except Exception as e_excel:
                        st.error(f"‚ùå Erro ao salvar Excel: {str(e_excel)}")
                        import traceback
                        st.error(f"Detalhes: {traceback.format_exc()}")
                        # Tentar salvar com xlsxwriter como alternativa
                        try:
                            import xlsxwriter
                            st.info(f"üîÑ Tentando salvar com xlsxwriter como alternativa...")
                            with pd.ExcelWriter(caminho_excel, engine='xlsxwriter') as writer:
                                df_forecast_completo.to_excel(writer, index=False, sheet_name='Forecast')
                            if os.path.exists(caminho_excel):
                                tamanho_arquivo = os.path.getsize(caminho_excel) / (1024 * 1024)
                                st.success(f"‚úÖ Excel salvo com xlsxwriter: {os.path.abspath(caminho_excel)} ({tamanho_arquivo:.2f} MB)")
                        except Exception as e_excel_alt:
                            st.error(f"‚ùå Erro ao salvar Excel com xlsxwriter: {str(e_excel_alt)}")
                            import traceback
                            st.error(f"Detalhes: {traceback.format_exc()}")
                    
                    st.success(f"‚úÖ Tabela completa gerada com sucesso!")
                    st.info(f"üìÅ Arquivos salvos em: **{pasta_forecast}/**")
                    if os.path.exists(caminho_parquet):
                        st.info(f"   ‚úÖ {nome_arquivo_base}.parquet")
                    if os.path.exists(caminho_excel):
                        st.info(f"   ‚úÖ {nome_arquivo_base}.xlsx")
                    st.info(f"üìä Total de linhas: {len(df_forecast_completo):,}")
                    
                    # ====================================================================
                    # üÜï CRIAR LINHAS DE FORECAST E SALVAR NO df_final_historico.parquet
                    # ====================================================================
                    st.markdown("---")
                    st.markdown("### üìù Gerando arquivo consolidado com hist√≥rico + forecast")
                    
                    try:
                        with st.spinner("üîÑ Criando linhas de forecast e consolidando com hist√≥rico..."):
                            # 1. Carregar dados hist√≥ricos originais (sem filtros, para manter todos os dados)
                            caminho_historico_consolidado = os.path.join("dados", "historico_consolidado", "df_final_historico.parquet")
                            
                            # Sempre tentar carregar o arquivo, mas se n√£o existir, usar df_base_completo
                            df_historico_completo = None
                            if os.path.exists(caminho_historico_consolidado):
                                # Carregar hist√≥rico completo do arquivo existente
                                df_historico_completo = pd.read_parquet(caminho_historico_consolidado)
                            else:
                                # Se o arquivo n√£o existir, usar os dados do df_base_completo (j√° carregado anteriormente)
                                st.info(f"‚ÑπÔ∏è Arquivo {os.path.basename(caminho_historico_consolidado)} n√£o encontrado. Usando dados da base original.")
                                if df_base_completo is not None and not df_base_completo.empty:
                                    df_historico_completo = df_base_completo.copy()
                            
                            # Continuar com o processamento (sempre gerar/substituir o arquivo)
                            # Se n√£o tiver dados hist√≥ricos, usar df_base_completo como fallback
                            if df_historico_completo is None or df_historico_completo.empty:
                                if df_base_completo is not None and not df_base_completo.empty:
                                    df_historico_completo = df_base_completo.copy()
                                    st.info("‚ÑπÔ∏è Usando dados da base original como hist√≥rico.")
                            
                            # SEMPRE continuar para gerar/substituir o arquivo, mesmo que n√£o tenha dados hist√≥ricos
                            # (os dados de forecast ser√£o adicionados)
                            if df_historico_completo is not None and not df_historico_completo.empty:
                                
                                # Adicionar coluna Tipo se n√£o existir (para identificar hist√≥rico vs forecast)
                                if 'Tipo' not in df_historico_completo.columns:
                                    df_historico_completo['Tipo'] = 'Hist√≥rico'
                                
                                # 2. Agrupar dados hist√≥ricos conforme necess√°rio (mesma l√≥gica do modo Custo Total)
                                # Identificar colunas de agrupamento (remover colunas que n√£o devem ser agrupadas)
                                colunas_para_agrupar = ['Oficina', 'Ve√≠culo', 'Per√≠odo']
                                if 'Ano' in df_historico_completo.columns:
                                    colunas_para_agrupar.insert(2, 'Ano')
                                if 'Tipo_Custo' in df_historico_completo.columns:
                                    colunas_para_agrupar.append('Tipo_Custo')
                                
                                # Adicionar colunas adicionais se existirem
                                colunas_adicionais_para_agrupar = [col for col in colunas_adicionais if col in df_historico_completo.columns]
                                colunas_para_agrupar.extend(colunas_adicionais_para_agrupar)
                                
                                # Colunas num√©ricas para somar
                                colunas_numericas = ['Total']
                                if 'Volume' in df_historico_completo.columns:
                                    colunas_numericas.append('Volume')
                                
                                # Agrupar hist√≥rico (somando valores por chave √∫nica)
                                df_historico_agrupado = df_historico_completo.groupby(
                                    [col for col in colunas_para_agrupar if col in df_historico_completo.columns],
                                    as_index=False
                                )[colunas_numericas].sum()
                                
                                # Manter outras colunas importantes (pegar primeiro valor de cada grupo)
                                colunas_manter = [col for col in df_historico_completo.columns 
                                                 if col not in colunas_para_agrupar and col not in colunas_numericas and col != 'Tipo']
                                if colunas_manter:
                                    df_historico_agrupado = df_historico_agrupado.merge(
                                        df_historico_completo[colunas_para_agrupar + colunas_manter].drop_duplicates(
                                            subset=colunas_para_agrupar
                                        ),
                                        on=colunas_para_agrupar,
                                        how='left'
                                    )
                                
                                # Garantir que Tipo = 'Hist√≥rico'
                                df_historico_agrupado['Tipo'] = 'Hist√≥rico'
                                
                                # 3. Criar linhas de forecast a partir de df_forecast_completo
                                linhas_forecast = []
                                
                                # Para cada per√≠odo de forecast
                                for periodo in periodos_restantes:
                                    # Para cada linha √∫nica em df_forecast_completo
                                    colunas_chave_linha = ['Oficina', 'Ve√≠culo', 'Tipo_Custo'] + colunas_adicionais_para_agrupar
                                    if 'Ano' in df_forecast_completo.columns:
                                        colunas_chave_linha.insert(2, 'Ano')
                                    
                                    # Obter linhas √∫nicas (uma por combina√ß√£o de chave)
                                    # Verificar se as colunas existem antes de acess√°-las
                                    colunas_para_selecionar = colunas_chave_linha.copy()
                                    if 'M√©dia_Mensal_Hist√≥rica' in df_forecast_completo.columns:
                                        colunas_para_selecionar.append('M√©dia_Mensal_Hist√≥rica')
                                    if 'Volume_Medio_Historico' in df_forecast_completo.columns:
                                        colunas_para_selecionar.append('Volume_Medio_Historico')
                                    
                                    # Filtrar apenas colunas que existem
                                    colunas_para_selecionar = [col for col in colunas_para_selecionar if col in df_forecast_completo.columns]
                                    
                                    df_linhas_unicas = df_forecast_completo[colunas_para_selecionar].drop_duplicates(
                                        subset=colunas_chave_linha
                                    )
                                    
                                    for _, linha_original in df_linhas_unicas.iterrows():
                                        # Criar nova linha de forecast
                                        nova_linha = linha_original.to_dict()
                                        
                                        # Definir Per√≠odo como per√≠odo de forecast
                                        nova_linha['Per√≠odo'] = str(periodo)
                                        
                                        # Extrair ano do per√≠odo se poss√≠vel
                                        periodo_str = str(periodo)
                                        if ' ' in periodo_str:
                                            partes = periodo_str.split(' ', 1)
                                            if len(partes) == 2 and partes[1].isdigit():
                                                nova_linha['Ano'] = int(partes[1])
                                        
                                        # Obter valor de forecast calculado
                                        # Buscar linha correspondente em df_forecast_completo
                                        mask = True
                                        for col in colunas_chave_linha:
                                            if col in df_forecast_completo.columns:
                                                mask = mask & (df_forecast_completo[col] == linha_original[col])
                                        
                                        linha_forecast = df_forecast_completo[mask]
                                        if not linha_forecast.empty and periodo in linha_forecast.columns:
                                            valor_forecast = float(linha_forecast[periodo].iloc[0])
                                        else:
                                            # Calcular forecast na hora se n√£o estiver na coluna
                                            media_historica = float(linha_original.get('M√©dia_Mensal_Hist√≥rica', 0.0))
                                            volume_medio_historico = float(linha_original.get('Volume_Medio_Historico', 0.0))
                                            
                                            # Buscar volume do per√≠odo
                                            volume_mes = volume_medio_historico
                                            if volume_por_mes is not None and not volume_por_mes.empty:
                                                periodo_str_norm = str(periodo).strip().lower().split(' ', 1)[0]
                                                volume_por_mes_temp = volume_por_mes.copy()
                                                volume_por_mes_temp['Per√≠odo_Norm'] = volume_por_mes_temp['Per√≠odo'].astype(str).str.strip().str.lower().str.split(' ', expand=True)[0]
                                                vol_mes_df = volume_por_mes_temp[volume_por_mes_temp['Per√≠odo_Norm'] == periodo_str_norm].copy()
                                                
                                                if not vol_mes_df.empty:
                                                    # Filtrar por Oficina e Ve√≠culo
                                                    vol_mes_filtrado = vol_mes_df[
                                                        (vol_mes_df['Oficina'] == linha_original['Oficina']) &
                                                        (vol_mes_df['Ve√≠culo'] == linha_original['Ve√≠culo'])
                                                    ]
                                                    if not vol_mes_filtrado.empty:
                                                        volume_mes = float(vol_mes_filtrado['Volume'].sum())
                                            
                                            # Calcular forecast
                                            tipo_custo = linha_original.get('Tipo_Custo', 'Vari√°vel')
                                            if volume_medio_historico > 0:
                                                proporcao_volume = volume_mes / volume_medio_historico
                                                variacao_percentual = proporcao_volume - 1.0
                                            else:
                                                variacao_percentual = 0.0
                                            
                                            # Obter sensibilidade
                                            if sensibilidades_type06_dict is not None and 'Type 06' in linha_original:
                                                type06_valor = linha_original.get('Type 06')
                                                if pd.notna(type06_valor) and type06_valor in sensibilidades_type06_dict:
                                                    sensibilidade = sensibilidades_type06_dict[type06_valor]
                                                else:
                                                    sensibilidade = sensibilidade_fixo if tipo_custo == 'Fixo' else sensibilidade_variavel
                                            else:
                                                sensibilidade = sensibilidade_fixo if tipo_custo == 'Fixo' else sensibilidade_variavel
                                            
                                            variacao_ajustada = variacao_percentual * sensibilidade
                                            
                                            # Obter infla√ß√£o
                                            if inflacao_type06_dict is not None and 'Type 06' in linha_original:
                                                type06_valor = linha_original.get('Type 06')
                                                if pd.notna(type06_valor) and type06_valor in inflacao_type06_dict:
                                                    inflacao_percentual = inflacao_type06_dict[type06_valor] / 100.0
                                                else:
                                                    inflacao_percentual = 0.0
                                            else:
                                                inflacao_percentual = 0.0
                                            
                                            fator_variacao = 1.0 + variacao_ajustada
                                            fator_inflacao = 1.0 + inflacao_percentual
                                            valor_forecast = media_historica * fator_variacao * fator_inflacao
                                        
                                        # Definir Total como valor de forecast
                                        nova_linha['Total'] = valor_forecast
                                        
                                        # Definir Volume (usar volume do per√≠odo)
                                        if volume_por_mes is not None and not volume_por_mes.empty:
                                            periodo_str_norm = str(periodo).strip().lower().split(' ', 1)[0]
                                            volume_por_mes_temp = volume_por_mes.copy()
                                            volume_por_mes_temp['Per√≠odo_Norm'] = volume_por_mes_temp['Per√≠odo'].astype(str).str.strip().str.lower().str.split(' ', expand=True)[0]
                                            vol_mes_df = volume_por_mes_temp[volume_por_mes_temp['Per√≠odo_Norm'] == periodo_str_norm].copy()
                                            
                                            if not vol_mes_df.empty:
                                                vol_mes_filtrado = vol_mes_df[
                                                    (vol_mes_df['Oficina'] == linha_original['Oficina']) &
                                                    (vol_mes_df['Ve√≠culo'] == linha_original['Ve√≠culo'])
                                                ]
                                                if not vol_mes_filtrado.empty:
                                                    nova_linha['Volume'] = float(vol_mes_filtrado['Volume'].sum())
                                                else:
                                                    nova_linha['Volume'] = volume_medio_historico
                                            else:
                                                nova_linha['Volume'] = volume_medio_historico
                                        else:
                                            nova_linha['Volume'] = volume_medio_historico
                                        
                                        # Definir Tipo como 'Forecast'
                                        nova_linha['Tipo'] = 'Forecast'
                                        
                                        # Remover colunas que n√£o devem estar no arquivo final
                                        colunas_remover_linha = ['M√©dia_Mensal_Hist√≥rica', 'Volume_Medio_Historico'] + [p for p in periodos_restantes if p != periodo]
                                        for col_remover in colunas_remover_linha:
                                            if col_remover in nova_linha:
                                                del nova_linha[col_remover]
                                        
                                        linhas_forecast.append(nova_linha)
                                
                                # 4. Criar DataFrame com linhas de forecast
                                if linhas_forecast:
                                    df_forecast_linhas = pd.DataFrame(linhas_forecast)
                                    
                                    # 5. Combinar hist√≥rico agrupado + forecast
                                    # Garantir que todas as colunas estejam presentes em ambos
                                    colunas_comuns = list(set(df_historico_agrupado.columns) & set(df_forecast_linhas.columns))
                                    colunas_historico_faltantes = [col for col in df_forecast_linhas.columns if col not in df_historico_agrupado.columns]
                                    colunas_forecast_faltantes = [col for col in df_historico_agrupado.columns if col not in df_forecast_linhas.columns]
                                    
                                    # Adicionar colunas faltantes com valores padr√£o
                                    for col in colunas_historico_faltantes:
                                        df_historico_agrupado[col] = None
                                    for col in colunas_forecast_faltantes:
                                        df_forecast_linhas[col] = None
                                    
                                    # Reordenar colunas para que sejam iguais
                                    todas_colunas = sorted(set(df_historico_agrupado.columns) | set(df_forecast_linhas.columns))
                                    df_historico_agrupado = df_historico_agrupado.reindex(columns=todas_colunas)
                                    df_forecast_linhas = df_forecast_linhas.reindex(columns=todas_colunas)
                                    
                                    # Combinar
                                    df_consolidado_final = pd.concat([df_historico_agrupado, df_forecast_linhas], ignore_index=True)
                                    
                                    # 6. Salvar arquivos na pasta dados\historico_consolidado
                                    try:
                                        pasta_historico_consolidado = os.path.join("dados", "historico_consolidado")
                                        
                                        # Fazer c√≥pia do arquivo original ANTES de atualizar (df_final_historico.parquet)
                                        # Isso preserva o estado anterior antes de adicionar os dados de forecast
                                        caminho_forecast = os.path.join(pasta_historico_consolidado, "df_final_historico_forecast.parquet")
                                        import shutil
                                        
                                        # Sempre fazer c√≥pia se o arquivo original existir
                                        if os.path.exists(caminho_historico_consolidado):
                                            shutil.copy2(caminho_historico_consolidado, caminho_forecast)
                                            st.info(f"üì¶ Arquivo forecast criado: {os.path.basename(caminho_forecast)}")
                                            
                                            # Gerar tamb√©m em Excel
                                            caminho_forecast_excel = caminho_forecast.replace('.parquet', '.xlsx')
                                            try:
                                                df_historico_completo.to_excel(caminho_forecast_excel, index=False, engine='openpyxl')
                                                st.info(f"üìä Arquivo forecast Excel criado: {os.path.basename(caminho_forecast_excel)}")
                                            except Exception as e_forecast_excel:
                                                st.warning(f"‚ö†Ô∏è Erro ao criar arquivo forecast Excel: {str(e_forecast_excel)}")
                                        else:
                                            # Se o arquivo original n√£o existir, criar o forecast a partir do consolidado
                                            df_consolidado_final.to_parquet(caminho_forecast, index=False, engine='pyarrow')
                                            st.info(f"üì¶ Arquivo forecast criado (novo): {os.path.basename(caminho_forecast)}")
                                            
                                            # Gerar tamb√©m em Excel
                                            caminho_forecast_excel = caminho_forecast.replace('.parquet', '.xlsx')
                                            try:
                                                df_consolidado_final.to_excel(caminho_forecast_excel, index=False, engine='openpyxl')
                                                st.info(f"üìä Arquivo forecast Excel criado: {os.path.basename(caminho_forecast_excel)}")
                                            except Exception as e_forecast_excel:
                                                st.warning(f"‚ö†Ô∏è Erro ao criar arquivo forecast Excel: {str(e_forecast_excel)}")
                                        
                                        # SEMPRE salvar/substituir df_final_historico.parquet (arquivo consolidado com hist√≥rico + forecast)
                                        # Criar pasta se n√£o existir
                                        if not os.path.exists(pasta_historico_consolidado):
                                            os.makedirs(pasta_historico_consolidado)
                                        
                                        df_consolidado_final.to_parquet(caminho_historico_consolidado, index=False, engine='pyarrow')
                                        st.success(f"‚úÖ Arquivo consolidado salvo/substitu√≠do: {os.path.basename(caminho_historico_consolidado)}")
                                        st.info(f"üìä Total de linhas: {len(df_consolidado_final):,} (Hist√≥rico: {len(df_historico_agrupado):,} + Forecast: {len(df_forecast_linhas):,})")
                                        
                                        # Gerar df_ke5z_historico.parquet
                                        # Este arquivo deve conter dados agrupados por KE5Z (se houver coluna relacionada)
                                        # Por enquanto, vamos criar uma vers√£o agrupada do df_consolidado_final
                                        # Se n√£o houver coluna espec√≠fica para KE5Z, vamos usar uma agrega√ß√£o similar
                                        caminho_ke5z = os.path.join(pasta_historico_consolidado, "df_ke5z_historico.parquet")
                                        
                                        # Verificar se h√° colunas relacionadas a KE5Z ou agrupar por chave √∫nica
                                        # Por padr√£o, vamos agrupar por Oficina, Ve√≠culo, Per√≠odo, Ano (se existir)
                                        colunas_agrupamento_ke5z = ['Oficina', 'Ve√≠culo', 'Per√≠odo']
                                        if 'Ano' in df_consolidado_final.columns:
                                            colunas_agrupamento_ke5z.insert(2, 'Ano')
                                        if 'Tipo_Custo' in df_consolidado_final.columns:
                                            colunas_agrupamento_ke5z.append('Tipo_Custo')
                                        
                                        # Filtrar apenas colunas que existem
                                        colunas_agrupamento_ke5z = [col for col in colunas_agrupamento_ke5z if col in df_consolidado_final.columns]
                                        
                                        # Agrupar e somar valores num√©ricos
                                        colunas_numericas_ke5z = ['Total']
                                        if 'Volume' in df_consolidado_final.columns:
                                            colunas_numericas_ke5z.append('Volume')
                                        
                                        df_ke5z_historico = df_consolidado_final.groupby(
                                            colunas_agrupamento_ke5z,
                                            as_index=False
                                        )[colunas_numericas_ke5z].sum()
                                        
                                        # Manter outras colunas importantes (primeiro valor de cada grupo)
                                        colunas_manter_ke5z = [col for col in df_consolidado_final.columns 
                                                               if col not in colunas_agrupamento_ke5z and col not in colunas_numericas_ke5z]
                                        if colunas_manter_ke5z:
                                            df_ke5z_historico = df_ke5z_historico.merge(
                                                df_consolidado_final[colunas_agrupamento_ke5z + colunas_manter_ke5z].drop_duplicates(
                                                    subset=colunas_agrupamento_ke5z
                                                ),
                                                on=colunas_agrupamento_ke5z,
                                                how='left'
                                            )
                                        
                                        # Salvar df_ke5z_historico.parquet
                                        df_ke5z_historico.to_parquet(caminho_ke5z, index=False, engine='pyarrow')
                                        st.success(f"‚úÖ Arquivo KE5Z salvo: {os.path.basename(caminho_ke5z)}")
                                        st.info(f"üìä Total de linhas KE5Z: {len(df_ke5z_historico):,}")
                                        
                                    except Exception as e_salvar:
                                        st.error(f"‚ùå Erro ao salvar arquivos consolidados: {str(e_salvar)}")
                                        import traceback
                                        st.error(f"Detalhes: {traceback.format_exc()}")
                                else:
                                    st.warning("‚ö†Ô∏è Nenhuma linha de forecast foi criada.")
                    except Exception as e_consolidado:
                        st.error(f"‚ùå Erro ao consolidar hist√≥rico + forecast: {str(e_consolidado)}")
                        import traceback
                        st.error(f"Detalhes: {traceback.format_exc()}")
                    
                    # Limpar flag
                    st.session_state.gerar_tabela_completa_forecast = False
                    
        except Exception as e:
            st.error(f"‚ùå Erro ao gerar tabela completa: {str(e)}")
            import traceback
            st.error(f"Detalhes: {traceback.format_exc()}")
            st.session_state.gerar_tabela_completa_forecast = False
    
    # N√£o h√° ajustes manuais: o c√°lculo linha a linha garante que os valores est√£o corretos
    # Total_Forecast ser√° calculado depois que colunas_meses for definido
    
    # Fun√ß√£o para processar e formatar tabela com cache
    @st.cache_data(ttl=3600, max_entries=10, show_spinner=False)
    def processar_tabela_forecast(df_forecast_cache, colunas_adicionais_cache, meses_restantes_cache):
        """Processa e formata a tabela de forecast com cache"""
        # Reordenar colunas
        colunas_ordenadas = ['Oficina', 'Ve√≠culo'] + colunas_adicionais_cache + ['Tipo_Custo', 'M√©dia_Mensal_Hist√≥rica'] + meses_restantes_cache
        colunas_existentes = [col for col in colunas_ordenadas if col in df_forecast_cache.columns]
        df_forecast_processado = df_forecast_cache[colunas_existentes].copy()
        
        # Verificar duplicatas ANTES do agrupamento
        colunas_chave_antes_agrupamento = ['Oficina', 'Ve√≠culo'] + [col for col in colunas_adicionais_cache if col in df_forecast_processado.columns] + ['Tipo_Custo']
        if 'Ano' in df_forecast_processado.columns:
            colunas_chave_antes_agrupamento.insert(2, 'Ano')
        colunas_chave_antes_existentes = [col for col in colunas_chave_antes_agrupamento if col in df_forecast_processado.columns]
        
        if len(colunas_chave_antes_existentes) > 0 and len(df_forecast_processado) > 0:
            duplicatas_antes = df_forecast_processado.duplicated(subset=colunas_chave_antes_existentes, keep=False)
            num_duplicatas_antes = duplicatas_antes.sum()
            if num_duplicatas_antes > 0:
                st.sidebar.error(f"‚ùå PROBLEMA CR√çTICO: {num_duplicatas_antes} linhas duplicadas ANTES do agrupamento!")
                # Mostrar exemplo de duplicatas
                linhas_dup = df_forecast_processado[duplicatas_antes]
                if len(linhas_dup) > 0:
                    exemplo_dup = linhas_dup.iloc[0]
                    mask_exemplo = True
                    for col in colunas_chave_antes_existentes:
                        mask_exemplo = mask_exemplo & (df_forecast_processado[col] == exemplo_dup[col])
                    linhas_exemplo = df_forecast_processado[mask_exemplo]
                    if len(linhas_exemplo) > 1:
                        st.sidebar.write(f"**Exemplo:** {len(linhas_exemplo)} linhas com mesma chave:")
                        for idx, row in linhas_exemplo.head(3).iterrows():
                            valores_meses = [row[col] for col in meses_restantes_cache if col in row.index]
                            soma_meses_exemplo = sum([v for v in valores_meses if isinstance(v, (int, float))])
                            st.sidebar.write(f"  - Linha {idx}: soma meses = {soma_meses_exemplo:,.2f}")
        
        # Calcular total por linha e identificar colunas de meses
        colunas_meses = [col for col in meses_restantes_cache if col in df_forecast_processado.columns]
        if colunas_meses:
            df_forecast_processado['Total_Forecast'] = df_forecast_processado[colunas_meses].sum(axis=1)
        
        # Agrupar linhas iguais (mesma combina√ß√£o de Oficina+Ve√≠culo+Type+Tipo_Custo)
        # üîß CORRE√á√ÉO CR√çTICA: Se houver coluna 'Ano', inclu√≠-la no agrupamento para evitar
        # agrupar linhas de anos diferentes (ex: 2024 e 2025) que devem ser tratadas separadamente
        colunas_agrupamento = ['Oficina', 'Ve√≠culo'] + [col for col in colunas_adicionais_cache if col in df_forecast_processado.columns] + ['Tipo_Custo']
        # Incluir 'Ano' no agrupamento se existir (evita agrupar dados de 2024 com 2025)
        if 'Ano' in df_forecast_processado.columns:
            colunas_agrupamento.append('Ano')
        colunas_agrupamento_existentes = [col for col in colunas_agrupamento if col in df_forecast_processado.columns]
        
        if len(colunas_agrupamento_existentes) > 0:
            # Agrupar: somar valores num√©ricos (forecasts), somar M√©dia_Mensal_Hist√≥rica tamb√©m
            # N√ÉO somar Total_Forecast aqui, vamos recalcular depois
            agg_dict_grupo = {}
            for col in df_forecast_processado.columns:
                if col not in colunas_agrupamento_existentes:
                    if col == 'M√©dia_Mensal_Hist√≥rica':
                        # üîß CORRE√á√ÉO: Ao agrupar, somar as m√©dias hist√≥ricas (n√£o usar 'first')
                        # porque linhas duplicadas devem ter suas m√©dias somadas para manter a consist√™ncia
                        # com a m√©dia hist√≥rica total padronizada
                        agg_dict_grupo[col] = 'sum'  # Somar m√©dias hist√≥ricas ao agrupar
                    elif col in colunas_meses:
                        agg_dict_grupo[col] = 'sum'  # Somar forecasts dos meses
                    elif col == 'Total_Forecast':
                        # N√£o incluir Total_Forecast no agrupamento, vamos recalcular
                        pass
                    else:
                        agg_dict_grupo[col] = 'first'
            df_forecast_processado = df_forecast_processado.groupby(
                colunas_agrupamento_existentes, as_index=False
            ).agg(agg_dict_grupo).reset_index()
            
            # Recalcular Total_Forecast ap√≥s agrupamento (soma dos meses agrupados)
            if colunas_meses:
                df_forecast_processado['Total_Forecast'] = df_forecast_processado[colunas_meses].sum(axis=1)
        
        # Remover linhas com valores zero
        if colunas_meses:
            soma_meses = df_forecast_processado[colunas_meses].sum(axis=1)
            df_forecast_processado = df_forecast_processado[soma_meses > 0.01].copy()
        
        # Ordenar
        colunas_ordenacao = ['Oficina', 'Ve√≠culo'] + [col for col in colunas_adicionais_cache if col in df_forecast_processado.columns] + ['Tipo_Custo']
        df_forecast_processado = df_forecast_processado.sort_values(colunas_ordenacao)
        
        return df_forecast_processado, colunas_meses

    # Processar tabela com cache (precisa ser feito antes dos gr√°ficos)
    # IMPORTANTE: df_forecast_bruto j√° foi criado ANTES deste processamento, ent√£o cont√©m todas as linhas
    df_forecast, colunas_meses = processar_tabela_forecast(df_forecast, colunas_adicionais, periodos_restantes)
    
    # ====================================================================
    
    # üîß CORRE√á√ÉO CR√çTICA: Calcular Total_Forecast no df_forecast_bruto DEPOIS de ter colunas_meses
    # Isso garante que os totais sejam calculados corretamente somando todas as linhas individuais
    # O df_forecast_bruto cont√©m todas as linhas ANTES do agrupamento
    if colunas_meses and all(mes in df_forecast_bruto.columns for mes in colunas_meses):
        df_forecast_bruto['Total_Forecast'] = df_forecast_bruto[colunas_meses].sum(axis=1)
    
    
    # N√£o h√° ajustes manuais: o c√°lculo linha a linha garante que os valores est√£o corretos
    # O agrupamento na fun√ß√£o processar_tabela_forecast soma as m√©dias hist√≥ricas corretamente
    
    # Gr√°ficos e tabelas removidos - apenas c√°lculos s√£o mantidos
    # Todos os gr√°ficos e tabelas foram removidos conforme solicitado
    # Apenas os c√°lculos e a gera√ß√£o de arquivos s√£o mantidos
    
    # ====================================================================
    # üìä GR√ÅFICO "SOMA DO VALOR POR PER√çODO" - USANDO DADOS DA PASTA FORECAST
    # Este gr√°fico aparece SEMPRE que houver dados na pasta Forecast
    # ====================================================================
    st.markdown("---")
    st.markdown("### üìä Soma do Valor por Per√≠odo (Dados do Forecast)")
    
    # Fun√ß√£o para ordenar por m√™s (mesma do TC_Ext)
    ORDEM_MESES_GRAFICO_FINAL = ['janeiro', 'fevereiro', 'mar√ßo', 'abril', 'maio', 'junho',
                                  'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro']
    
    def ordenar_por_mes_forecast_final(df, coluna_periodo='Per√≠odo'):
        """Ordena DataFrame por ordem cronol√≥gica dos meses, considerando ano se dispon√≠vel"""
        df_copy = df.copy()
        
        # Se houver coluna "Ano" e m√∫ltiplos anos, ordenar por ano e m√™s
        if 'Ano' in df_copy.columns and df_copy['Ano'].nunique() > 1:
            # Criar coluna de ordena√ß√£o: ano primeiro, depois m√™s
            df_copy['_ordem_ano'] = df_copy['Ano']
            df_copy['_ordem_mes'] = df_copy[coluna_periodo].astype(str).str.lower().map(
                {mes: idx for idx, mes in enumerate(ORDEM_MESES_GRAFICO_FINAL)}
            ).fillna(999)
            df_copy = df_copy.sort_values(['_ordem_ano', '_ordem_mes'])
            df_copy = df_copy.drop(columns=['_ordem_ano', '_ordem_mes'])
        else:
            # Ordena√ß√£o simples por m√™s
            df_copy['_ordem_mes'] = df_copy[coluna_periodo].astype(str).str.lower().map(
                {mes: idx for idx, mes in enumerate(ORDEM_MESES_GRAFICO_FINAL)}
            ).fillna(999)
            df_copy = df_copy.sort_values('_ordem_mes')
            df_copy = df_copy.drop(columns=['_ordem_mes'])
        
        return df_copy
    
    try:
        # Carregar dados do arquivo forecast gerado na pasta Forecast
        caminho_forecast_grafico = os.path.join("dados", "Forecast", "forecast_completo.parquet")
        if os.path.exists(caminho_forecast_grafico):
            df_forecast_grafico = pd.read_parquet(caminho_forecast_grafico)
            
            # Aplicar filtros (Oficina, Ve√≠culo, USI) mas N√ÉO filtrar por Per√≠odo
            # As vari√°veis j√° est√£o definidas no escopo global
            if 'Oficina' in df_forecast_grafico.columns:
                if oficina_selecionadas and "Todos" not in oficina_selecionadas:
                    df_forecast_grafico = df_forecast_grafico[
                        df_forecast_grafico['Oficina'].astype(str).isin(oficina_selecionadas)
                    ].copy()
            
            if 'Ve√≠culo' in df_forecast_grafico.columns:
                if veiculo_selecionados and "Todos" not in veiculo_selecionados:
                    df_forecast_grafico = df_forecast_grafico[
                        df_forecast_grafico['Ve√≠culo'].astype(str).isin(veiculo_selecionados)
                    ].copy()
            
            if 'USI' in df_forecast_grafico.columns:
                if usi_selecionada and "Todos" not in usi_selecionada:
                    df_forecast_grafico = df_forecast_grafico[
                        df_forecast_grafico['USI'].astype(str).isin(usi_selecionada)
                    ].copy()
            
            # Verificar se h√° coluna Total
            if 'Total' in df_forecast_grafico.columns and 'Per√≠odo' in df_forecast_grafico.columns:
                # Verificar se h√° m√∫ltiplos anos
                tem_multiplos_anos = 'Ano' in df_forecast_grafico.columns and df_forecast_grafico['Ano'].nunique() > 1
                
                # Converter Total para num√©rico caso seja categ√≥rico
                if 'Total' in df_forecast_grafico.columns:
                    df_forecast_grafico['Total'] = pd.to_numeric(df_forecast_grafico['Total'], errors='coerce')
                
                if tem_multiplos_anos:
                    # Agrupar por Ano e Per√≠odo
                    chart_data = df_forecast_grafico.groupby(['Ano', 'Per√≠odo'])['Total'].sum().reset_index()
                    
                    # Criar coluna combinada para o r√≥tulo do gr√°fico
                    chart_data['Per√≠odo_Completo'] = chart_data['Per√≠odo'].astype(str) + ' ' + chart_data['Ano'].astype(str)
                    
                    # Ordenar por ano e m√™s (usar fun√ß√£o similar ao TC_Ext)
                    chart_data = ordenar_por_mes_forecast_final(chart_data, 'Per√≠odo')
                    ordem_periodos = chart_data['Per√≠odo_Completo'].tolist()
                    coluna_periodo_grafico = 'Per√≠odo_Completo'
                else:
                    # Agrupar apenas por Per√≠odo
                    chart_data = df_forecast_grafico.groupby('Per√≠odo')['Total'].sum().reset_index()
                    
                    # Ordenar por m√™s
                    chart_data = ordenar_por_mes_forecast_final(chart_data, 'Per√≠odo')
                    ordem_periodos = chart_data['Per√≠odo'].tolist()
                    coluna_periodo_grafico = 'Per√≠odo'
                
                # Criar gr√°fico (mesma l√≥gica do TC_Ext)
                grafico_barras = alt.Chart(chart_data).mark_bar().encode(
                    x=alt.X(
                        f'{coluna_periodo_grafico}:N',
                        title='Per√≠odo',
                        sort=ordem_periodos
                    ),
                    y=alt.Y('Total:Q', title='Soma do Valor (R$)'),
                    color=alt.Color(
                        'Total:Q',
                        title='Total',
                        scale=alt.Scale(scheme='blues')
                    ),
                    tooltip=[
                        alt.Tooltip(f'{coluna_periodo_grafico}:N', title='Per√≠odo'),
                        alt.Tooltip('Total:Q', title='Soma do Valor', format=',.2f')
                    ]
                ).properties(
                    title='Soma do Valor por Per√≠odo',
                    height=400
                )
                
                # Adicionar r√≥tulos com valores nas barras
                rotulos = grafico_barras.mark_text(
                    align='center',
                    baseline='middle',
                    dy=-10,
                    color='white',
                    fontSize=11
                ).encode(
                    text=alt.Text('Total:Q', format=',.2f')
                )
                
                grafico_final = grafico_barras + rotulos
                st.altair_chart(grafico_final, use_container_width=True)
                
                # Mostrar resumo
                total_geral = chart_data['Total'].sum()
                st.info(f"üìä **Total Geral:** R$ {total_geral:,.2f}")
            else:
                st.warning("‚ö†Ô∏è Colunas 'Total' ou 'Per√≠odo' n√£o encontradas no arquivo forecast.")
        else:
            st.warning(f"‚ö†Ô∏è Arquivo n√£o encontrado: {caminho_forecast_grafico}")
            st.info("‚ÑπÔ∏è O arquivo ser√° gerado quando voc√™ clicar em 'Aplicar Configura√ß√µes do Forecast'.")
    except Exception as e:
        st.error(f"‚ùå Erro ao criar gr√°fico 'Soma do Valor por Per√≠odo': {str(e)}")
        import traceback
        st.error(f"Detalhes: {traceback.format_exc()}")

# ====================================================================
# üìä GR√ÅFICO "SOMA DO VALOR POR PER√çODO" - USANDO DADOS DA PASTA FORECAST
# Este gr√°fico aparece SEMPRE que houver dados na pasta Forecast
# ====================================================================
st.markdown("---")
st.markdown("### üìä Soma do Valor por Per√≠odo (Dados do Forecast)")

# Fun√ß√£o para ordenar por m√™s (mesma do TC_Ext)
ORDEM_MESES_GRAFICO = ['janeiro', 'fevereiro', 'mar√ßo', 'abril', 'maio', 'junho',
                       'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro']

def ordenar_por_mes_forecast(df, coluna_periodo='Per√≠odo'):
    """Ordena DataFrame por ordem cronol√≥gica dos meses, considerando ano se dispon√≠vel"""
    df_copy = df.copy()
    
    # Se houver coluna "Ano" e m√∫ltiplos anos, ordenar por ano e m√™s
    if 'Ano' in df_copy.columns and df_copy['Ano'].nunique() > 1:
        # Criar coluna de ordena√ß√£o: ano primeiro, depois m√™s
        df_copy['_ordem_ano'] = df_copy['Ano']
        df_copy['_ordem_mes'] = df_copy[coluna_periodo].astype(str).str.lower().map(
            {mes: idx for idx, mes in enumerate(ORDEM_MESES_GRAFICO)}
        ).fillna(999)
        df_copy = df_copy.sort_values(['_ordem_ano', '_ordem_mes'])
        df_copy = df_copy.drop(columns=['_ordem_ano', '_ordem_mes'])
    else:
        # Ordena√ß√£o simples por m√™s
        df_copy['_ordem_mes'] = df_copy[coluna_periodo].astype(str).str.lower().map(
            {mes: idx for idx, mes in enumerate(ORDEM_MESES_GRAFICO)}
        ).fillna(999)
        df_copy = df_copy.sort_values('_ordem_mes')
        df_copy = df_copy.drop(columns=['_ordem_mes'])
    
    return df_copy

try:
    # Carregar dados do arquivo forecast gerado na pasta Forecast
    caminho_forecast_grafico = os.path.join("dados", "Forecast", "forecast_completo.parquet")
    if os.path.exists(caminho_forecast_grafico):
        df_forecast_grafico = pd.read_parquet(caminho_forecast_grafico)
        
        # Aplicar filtros (Oficina, Ve√≠culo, USI) mas N√ÉO filtrar por Per√≠odo
        # As vari√°veis j√° est√£o definidas no escopo global
        if 'Oficina' in df_forecast_grafico.columns:
            if oficina_selecionadas and "Todos" not in oficina_selecionadas:
                df_forecast_grafico = df_forecast_grafico[
                    df_forecast_grafico['Oficina'].astype(str).isin(oficina_selecionadas)
                ].copy()
        
        if 'Ve√≠culo' in df_forecast_grafico.columns:
            if veiculo_selecionados and "Todos" not in veiculo_selecionados:
                df_forecast_grafico = df_forecast_grafico[
                    df_forecast_grafico['Ve√≠culo'].astype(str).isin(veiculo_selecionados)
                ].copy()
        
        if 'USI' in df_forecast_grafico.columns:
            if usi_selecionada and "Todos" not in usi_selecionada:
                df_forecast_grafico = df_forecast_grafico[
                    df_forecast_grafico['USI'].astype(str).isin(usi_selecionada)
                ].copy()
        
        # Verificar se h√° coluna Total
        if 'Total' in df_forecast_grafico.columns and 'Per√≠odo' in df_forecast_grafico.columns:
            # Converter Total para num√©rico caso seja categ√≥rico
            df_forecast_grafico['Total'] = pd.to_numeric(df_forecast_grafico['Total'], errors='coerce')
            
            # Verificar se h√° m√∫ltiplos anos
            tem_multiplos_anos = 'Ano' in df_forecast_grafico.columns and df_forecast_grafico['Ano'].nunique() > 1
            
            if tem_multiplos_anos:
                # Agrupar por Ano e Per√≠odo
                chart_data = df_forecast_grafico.groupby(['Ano', 'Per√≠odo'])['Total'].sum().reset_index()
                
                # Criar coluna combinada para o r√≥tulo do gr√°fico
                chart_data['Per√≠odo_Completo'] = chart_data['Per√≠odo'].astype(str) + ' ' + chart_data['Ano'].astype(str)
                
                # Ordenar por ano e m√™s (usar fun√ß√£o similar ao TC_Ext)
                chart_data = ordenar_por_mes_forecast(chart_data, 'Per√≠odo')
                ordem_periodos = chart_data['Per√≠odo_Completo'].tolist()
                coluna_periodo_grafico = 'Per√≠odo_Completo'
            else:
                # Agrupar apenas por Per√≠odo
                chart_data = df_forecast_grafico.groupby('Per√≠odo')['Total'].sum().reset_index()
                
                # Ordenar por m√™s
                chart_data = ordenar_por_mes_forecast(chart_data, 'Per√≠odo')
                ordem_periodos = chart_data['Per√≠odo'].tolist()
                coluna_periodo_grafico = 'Per√≠odo'
            
            # Criar gr√°fico (mesma l√≥gica do TC_Ext)
            grafico_barras = alt.Chart(chart_data).mark_bar().encode(
                x=alt.X(
                    f'{coluna_periodo_grafico}:N',
                    title='Per√≠odo',
                    sort=ordem_periodos
                ),
                y=alt.Y('Total:Q', title='Soma do Valor (R$)'),
                color=alt.Color(
                    'Total:Q',
                    title='Total',
                    scale=alt.Scale(scheme='blues')
                ),
                tooltip=[
                    alt.Tooltip(f'{coluna_periodo_grafico}:N', title='Per√≠odo'),
                    alt.Tooltip('Total:Q', title='Soma do Valor', format=',.2f')
                ]
            ).properties(
                title='Soma do Valor por Per√≠odo',
                height=400
            )
            
            # Adicionar r√≥tulos com valores nas barras
            rotulos = grafico_barras.mark_text(
                align='center',
                baseline='middle',
                dy=-10,
                color='white',
                fontSize=11
            ).encode(
                text=alt.Text('Total:Q', format=',.2f')
            )
            
            grafico_final = grafico_barras + rotulos
            st.altair_chart(grafico_final, use_container_width=True)
            
            # Mostrar resumo
            total_geral = chart_data['Total'].sum()
            st.info(f"üìä **Total Geral:** R$ {total_geral:,.2f}")
        else:
            st.warning("‚ö†Ô∏è Colunas 'Total' ou 'Per√≠odo' n√£o encontradas no arquivo forecast.")
    else:
        st.warning(f"‚ö†Ô∏è Arquivo n√£o encontrado: {caminho_forecast_grafico}")
        st.info("‚ÑπÔ∏è O arquivo ser√° gerado quando voc√™ clicar em 'Aplicar Configura√ß√µes do Forecast'.")
except Exception as e:
    st.error(f"‚ùå Erro ao criar gr√°fico 'Soma do Valor por Per√≠odo': {str(e)}")
    import traceback
    st.error(f"Detalhes: {traceback.format_exc()}")

# Footer
st.markdown("---")
st.info("üí° Forecast TC - An√°lise preditiva e previs√µes")

